---
title: "Related Work"
metaTitle: "Related Work"
metaDescription: "Related Work"
slug: "/research/4-related-work"
---

While formal AI incident research is relatively new, a number of people have been collecting what could be considered incidents. These include,

* [Awesome Machine Learning Interpretability: AI Incident Tracker](https://github.com/jphall663/awesome-machine-learning-interpretability/blob/master/README.md#ai-incident-tracker)
* [AI and Algorithimic Incidents and Controversies of Charlie Pownall](https://charliepownall.com/ai-algorithimic-incident-controversy-database/)
* [Map of Helpful and Harmful AI](https://map.ai-global.org/)

If you have an incident resource that could be added here, please [contact](/contact) us.

The following publications have been [indexed by Google scholar as referencing the database itself](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3482645389524246185), rather than solely individual incidents. Please [contact](/contact) us if your reference is missing.

## Responsible AI Collaborative Research

Where needed to serve the broader safety and fairness communities, the Collab produces and sponsors research. Works to date include the following.

* The original research publication released at the public announcement of the AI Incident Database. All citations of this work will be added to this page.   
[McGregor, Sean. "Preventing repeated real world AI failures by cataloging incidents: The AI incident database." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 17. 2021.](https://ojs.aaai.org/index.php/AAAI/article/download/17817/17624)
* A major update to the incident definitions and criteria as presented at the [2022 NeurIPS Workshop on Human-Centered AI.](https://nips.cc/virtual/2022/workshop/50008)  
[McGregor, Sean, Kevin Paeth, and Khoa Lam. "Indexing AI Risks with Incidents, Issues, and Variants." arXiv preprint arXiv:2211.10384 (2022).](https://arxiv.org/pdf/2211.10384)
* Our approach to reducing the uncertainty of incident causes when analyzing open source incident reports. Presented at [SafeAI](https://safeai.webs.upv.es/).  
[Pittaras, Nikiforos, and Sean McGregor. "A taxonomic system for failure cause analysis of open source AI incidents." arXiv preprint arXiv:2211.07280 (2022).](https://arxiv.org/pdf/2211.07280)
* Important lessons learned from editing AI incidents, focusing on issues related to their temporal ambiguity, multiplicity, large-scale exposure harms, and inherent uncertainty in reporting. Submitted to the [2025 Conference on Innovative Applications of Artificial Intelligence (IAAI-25).](https://aaai.org/conference/aaai/aaai-25/iaai-25-call/)  
[Paeth, Kevin, Daniel Atherton, Nikiforos Pittaras, Heather Frase, Sean McGregor. "Lessons for Editors of AI Incidents from the AI Incident Database." arXiv preprint arXiv:2409.16425 (2024)](https://arxiv.org/abs/2409.16425) 

## 2024

* [Abercrombie, Gavin, Djalel Benbouzid, Paolo Giudici, Delaram Golpayegani, Julio Hernandez, Pierre Noro, Harshvardhan Pandit, Eva Paraschou, Charlie Pownall, Jyoti Prajapati, Mark A. Sayre, Ushnish Sengupta, Arthit Suriyawongkul, Ruby Thelot, Sofia Vei, and Laura Waltersdorfer. "A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation Harms." *arXiv*, last revised November 9, 2024.](https://doi.org/10.48550/arXiv.2407.01294)
* [Abu Zaid, Faried, Daniel Neider, and Mustafa Yalçıner. "VeriFlow: Modeling Distributions for Neural Network Verification." *arXiv*, June 20, 2024.](https://doi.org/10.48550/arXiv.2406.14265)
* [Agarwal, Avinash, and Manisha J. Nene. "Addressing AI Risks in Critical Infrastructure: Formalising the AI Incident Reporting Process." Paper presented at the *2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)*, Bangalore, India, July 12--14, 2024. Published September 20, 2024.](https://doi.org/10.1109/CONECCT62155.2024.10677312)
* [Agarwal, Avinash, and Manisha J. Nene. "Standardised Schema and Taxonomy for AI Incident Databases in Critical Digital Infrastructure." Paper presented at the *2024 IEEE Pune Section International Conference (PuneCon)*, Pune, India, December 13--15, 2024. Published February 27, 2025.](https://doi.org/10.1109/PuneCon63413.2024.10895867)
* [Allaham, Mowafak, and Nicholas Diakopoulos. "Evaluating the Capabilities of LLMs for Supporting Anticipatory Impact Assessment." *arXiv*, May 20, 2024.](https://doi.org/10.48550/arXiv.2401.18028)
* [All Party Parliamentary Group for Fair Elections. *Free But Not Fair: British Elections and How to Restore Trust in Politics.* November 25, 2024.](https://www.fairelections.uk/wp-content/uploads/2024/11/fbnf-web-final.pdf)
* [Anandayuvaraj, Dharun, Matthew Campbell, Arav Tewari, and James C. Davis. "FAIL: Analyzing Software Failures from the News Using LLMs." In *Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE '24)*, 506--18. New York: Association for Computing Machinery, 2024.](https://doi.org/10.1145/3691620.3695022)
* [Bach, Tita A., Jenny K. Kristiansen, Aleksandar Babic, and Alon Jacovi. "Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review." *IEEE Access* 12 (August 1, 2024): 106385--106414.](https://doi.org/10.1109/ACCESS.2024.3437190)
* [Baeza-Yates, Ricardo, and Usama M. Fayyad. "Responsible AI: An Urgent Mandate." *IEEE Intelligent Systems* 39, no. 1 (January-February 2024): 12--17.](https://doi.org/10.1109/MIS.2023.3343488)
* [Batool, Amna, Didar Zowghi, and Muneera Bano. "AI Governance: A Systematic Literature Review." *Research Square*, July 24, 2024.](https://doi.org/10.21203/rs.3.rs-4784792/v1)
* [Bender, Emily M., and Alvin Grissom II. "Power Shift: Toward Inclusive Natural Language Processing." In *Inclusion in Linguistics*, edited by Anne H. Charity Hudley, Christine Mallinson, and Mary Bucholtz, 199--221. Oxford: Oxford University Press, 2024.](https://www.google.com/books/edition/Inclusion_in_Linguistics/nrjuEAAAQBAJ?hl=en)
* [Bérastégui, Pierre. *Artificial Intelligence in Industry 4.0: Implications for Occupational Safety and Health.* Report 2024.01. Brussels: European Trade Union Institute (ETUI), January 2024.](https://www.etui.org/sites/default/files/2024-05/Artificial%20intelligence%20in%20Industry%204.0-Implications%20for%20occupational%20safety%20and%20health_2024.pdf)
* [Biecek, Przemyslaw, and Wojciech Samek. "Position: Explain to Question Not to Justify." *arXiv*, June 28, 2024.](https://doi.org/10.48550/arXiv.2402.13914)
* [Bieringer, Lukas, Kevin Paeth, Jochen Stängler, Andreas Wespi, Alexandre Alahi, and Kathrin Grosse. *Position: A Taxonomy for Reporting and Describing AI Security Incidents*. First submitted December 19, 2024. Revised February 26, 2025. arXiv preprint arXiv:2412.14855 [cs.CR].](https://doi.org/10.48550/arXiv.2412.14855)
* [Bikkasani, Dileesh Chandra. "Navigating Artificial General Intelligence (AGI): Societal Implications, Ethical Considerations, and Governance Strategies." *AI and Ethics*, published December 17, 2024.](https://doi.org/10.1007/s43681-024-00642-z)
* [Birkstedt, Teemu. *Governing Artificial Intelligence: From Ethical Principles Toward Organizational AI Governance Practices*. Doctoral diss., University of Turku, Turku School of Economics, 2024. *Annales Universitatis Turkuensis*, Ser. E, Oeconomica, Tom. 124.](https://www.utupub.fi/bitstream/handle/10024/179166/Annales%20E%20124%20Birkstedt%20DISS.pdf)
* [Blösser, Myrthe, and Andrea Weihrauch. "A Consumer Perspective of AI Certification: The Current Certification Landscape, Consumer Approval, and Directions for Future Research." *European Journal of Marketing* 58, no. 2 (February 8, 2024).](https://doi.org/10.1108/EJM-01-2023-0009)
* [Bogucka, Edyta, Marios Constantinides, Julia De Miguel Velazquez, Sanja Šćepanović, Daniele Quercia, and Andrés Gvirtz. "The Atlas of AI Incidents in Mobile Computing: Visualizing the Risks and Benefits of AI Gone Mobile." *arXiv*, July 22, 2024.](https://doi.org/10.48550/arXiv.2407.15685)
* [Bogucka, Edyta, Marios Constantinides, Sanja Šćepanović, and Daniele Quercia. "AI Design: A Responsible AI Framework for Impact Assessment Reports." *IEEE Internet Computing* (Early Access), September 2, 2024.](https://doi.org/10.1109/MIC.2024.3451351)
* [Bogucka, Edyta, Sanja Šćepanović, and Daniele Quercia. "Atlas of AI Risks: Enhancing Public Understanding of AI Risks." *Proceedings of the AAAI Conference on Human Computation and Crowdsourcing* 12, no. 1 (October 14, 2024): 33--43.](https://doi.org/10.1609/hcomp.v12i1.31598)
* [Bolboli Qadikolaei, Somayeh, and Hamid Parsania. 2024. "The Concept of Human-Centricity in Sociological Studies of Artificial Intelligence." *Quarterly of Social Studies and Research in Iran* 13, no. 3 (September): 425--449.](https://doi.org/10.22059/jisr.2024.376963.1509)
* [Bommasani, Rishi, Kevin Klyman, Shayne Longpre, Sayash Kapoor, Nestor Maslej, Betty Xiong, Daniel Zhang, and Percy Liang. "The 2023 Foundation Model Transparency Index." *Transactions on Machine Learning Research*, February 2025.](https://openreview.net/forum?id=x6fXnsM9Ez)
* [Brandt, Aniek. 2024. *Evaluating the Epistemic Condition of Responsibility for AI*. Master's thesis, Utrecht University.](https://studenttheses.uu.nl/handle/20.500.12932/48023)
* [Bylykbashi, Anxhela, and Lana Gavranović. *Mitigating Non-Consumer AI Malfunctions: Response Strategies of Retail Organizations.* Master's thesis, Jönköping International Business School, Jönköping University, 2024.](https://urn.kb.se/resolve?urn=urn:nbn:se:hj:diva-64938)
* [Byrd, Don. "A+AI: Threats to Society, Remedies, and Governance." *arXiv*, September 3, 2024.](https://doi.org/10.48550/arXiv.2409.02219)
* [Cao, Hongpeng, Yanbing Mao, Lui Sha, and Marco Caccamo. *Physics-model-guided Worst-case Sampling for Safe Reinforcement Learning*. arXiv preprint arXiv:2412.13224, submitted December 17, 2024.](https://doi.org/10.48550/arXiv.2412.13224)
* [Cao, Hongpeng, Yanbing Mao, Yihao Cai, Lui Sha, and Marco Caccamo. *Runtime Learning Machine*. Preprint submitted to *International Conference on Learning Representations* (ICLR 2025), September 17, 2024. Last modified February 5, 2025.](https://openreview.net/forum?id=KCTHM2Ffh3)
* [Cao, Hongpeng, Yanbing Mao, Yihao Cai, Lui Sha, and Marco Caccamo. "Simplex-Enabled Safe Continual Learning Machine." *arXiv* (preprint), last revised October 6, 2024.](https://doi.org/10.48550/arXiv.2409.05898)
* [Cattell, Sven, Avijit Ghosh, and Lucie-Aimée Kaffee. "Coordinated Flaw Disclosure for AI: Beyond Security Vulnerabilities." *arXiv*, July 26, 2024.](https://doi.org/10.48550/arXiv.2402.07039)
* [Chakraborti, Mahasweta, Bert Joseph Prestoza, Nicholas Vincent, and Seth Frey. *Responsible AI in Open Ecosystems: Reconciling Innovation with Risk Assessment and Disclosure*. arXiv, September 27, 2024.](https://doi.org/10.48550/arXiv.2409.19104)
* [Chen, Chuan, Yu Feng, Mengyi Wei, Peng Luo, Shengkai Wang, and Liqiu Meng. "A Hyper-Knowledge Graph System for Research on AI Ethics Cases." *Heliyon* 10, no. 7 (April 15, 2024): e29048.](https://doi.org/10.1016/j.heliyon.2024.e29048)
* [Chen, Hao, Bhiksha Raj, Xing Xie, and Jindong Wang. "On Catastrophic Inheritance of Large Foundation Models." *arXiv*, February 2, 2024.](https://doi.org/10.48550/arXiv.2402.01909)
* [Cheong, Ben Chester. "Transparency and Accountability in AI Systems: Safeguarding Well-Being in the Age of Algorithmic Decision-Making." *Frontiers in Human Dynamics* 6 (July 2, 2024).](https://doi.org/10.3389/fhumd.2024.1421273)
* [Chmielinski, Kasia, Sarah Newman, Chris N. Kranzinger, Michael Hind, Jennifer Wortman Vaughan, Margaret Mitchell, Julia Stoyanovich, Angelina McMillan-Major, Emily McReynolds, Kathleen Esfahany, Mary L. Gray, Audrey Chang, and Maui Hudson. *The CLeAR Documentation Framework for AI Transparency: Recommendations for Practitioners & Context for Policymakers.* Harvard Kennedy School Shorenstein Center on Media, Politics and Public Policy, May 21, 2024.](https://shorensteincenter.org/clear-documentation-framework-ai-transparency-recommendations-practitioners-context-policymakers/)
* [Cho, Deun-Sol, Jae-Min Cho, and Won-Tae Kim. "A Generative Digital Twin for Continually Enhancing the Intended Functional Safety of Cyber--Physical Systems." *IEEE Transactions on Reliability* (Early Access), October 8, 2024.](https://doi.org/10.1109/TR.2024.3434606)
* [Corrêa, Nicholas Kluge. "Dynamic Normativity: Necessary and Sufficient Conditions for Value Alignment." *arXiv* (preprint), June 18, 2024.](https://doi.org/10.48550/arXiv.2406.11039)
* [Cox, Andrew. "11 Ethics Case Studies of Artificial Intelligence for Library and Information Professionals." In *New Horizons in Artificial Intelligence in Libraries*, edited by Edmund Balnaves, Leda Bultrini, Andrew Cox, and Raymond Uzwyshyn, 156--168. IFLA Publications 185. Berlin: De Gruyter Saur, 2025.](https://doi.org/10.1515/9783111336435-012)
* [Daniels, Owen J., and Dewey Murdick. *Enabling Principles for AI Governance.* Washington, DC: Center for Security and Emerging Technology, July 2024.](https://cset.georgetown.edu/wp-content/uploads/CSET-Enabling-Principles-for-AI-Governance.pdf)
* [Daugherty, Paul, Jeremy Jurgens, John Granger, and Cathy Li. *AI Governance Alliance: Briefing Paper Series.* World Economic Forum, January 18, 2024.](https://www3.weforum.org/docs/WEF_AI_Governance_Alliance_Briefing_Paper_Series_2024.pdf)
* [David, Tom, and Nicolas Miailhe. "Assessing the Safety and Robustness of Advanced AI." *Politique étrangère* 243, no. 3 (2024): 51--65.](https://doi.org/10.3917/pe.243.0051)
* [De Miguel Velázquez, Julia, Sanja Šćepanović, Andrés Gvirtz, and Daniele Quercia. "Decoding Real-World Artificial Intelligence Incidents." *Computer* 57, no. 11 (November 2024): 71--81.](https://doi.org/10.1109/MC.2024.3432492)
* [DeVrio, Alicia, Motahhare Eslami, and Kenneth Holstein. "Building, Shifting, & Employing Power: A Taxonomy of Responses From Below to Algorithmic Harm." In *Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency* (FAccT '24), 1093--1106. June 5, 2024.](https://doi.org/10.1145/3630106.3658958)
* [Dixon, Ren Bin Lee, and Heather Frase. *An Argument for Hybrid AI Incident Reporting: Lessons Learned from Other Incident Reporting Systems.* Issue Brief. Center for Security and Emerging Technology, March 2024.](https://cset.georgetown.edu/wp-content/uploads/CSET-An-Argument-for-Hybrid-AI-Incident-Reporting.pdf)
* Drage, Eleanor, Kerry McInerney, and Rosi Braidotti, eds. 2024. *The Good Robot: Why Technology Needs Feminism*. London: Bloomsbury Academic.
* [Duarte, Daniel Edler. "Tecnopolíticas da Falha: Dispositivos de Crítica e Resistência a Novas Ferramentas Punitivas [Technopolitics of Failure: Modes of Critique and Resistance to New Punitive Tools]." *Revista Brasileira de Ciências Sociais* 39 (2024).](https://doi.org/10.1590/39017/2024)
* [Dutu, Andrei. "Uniunea Europeană: Instituirea unui Regim Comun de Răspundere Extracontractuală (Delictuală) în Materie de Prejudiciu Causat de Inteligenţa Artificială \[Propunere de directivă a Parlamentului European și a Consiliului privind adaptarea normelor în materie de răspundere civilă extracontractuală la inteligența artificială (Directiva privind răspunderea în materie de IA)\]." *Pandectele Române*, no. 4 (April 2024): 211--218.](https://www.proquest.com/scholarly-journals/uniunea-europeană-instituirea-unui-regim-comun-de/docview/3160633440/se-2).
* [Expósito Jiménez, Víctor J., Georg Macher, Daniel Watzenig, and Eugen Brenner. "Safety of the Intended Functionality Validation for Automated Driving Systems by Using Perception Performance Insufficiencies Injection." *Vehicles* 6, no. 3 (July 4, 2024): 1164--1184.](https://doi.org/10.3390/vehicles6030055)
* [Faulhaber, Ella, and Charles Chaffin. "Artificial Intelligence in Accounting, Medicine, and Law with Potential Implications for Financial Planning: A Review of Literature." *Financial Services Review* 32, no. 4 (2024): 1--11.](https://doi.org/10.61190/fsr.v32i4.4017)
* [Gagnon, Paul, Misha Benjamin, Justine Gauthier, Catherine Regis, Jenny Lee, and Alexei Nordell-Markovits. "On the Modification and Revocation of Open Source Licences." *arXiv*, May 29, 2024.](https://doi.org/10.48550/arXiv.2407.13064)
* [Goldkind, Lauri, Joy Ming, and Alex Fink. "AI in the Nonprofit Human Services: Distinguishing Between Hype, Harm, and Hope." *Human Service Organizations: Management, Leadership & Governance*, published online December 3, 2024.](https://doi.org/10.1080/23303131.2024.2427459)
* [Golpayegani, Delaram. *Semantic Frameworks to Support the EU AI Act's Risk Management and Documentation*. PhD diss., Trinity College Dublin, University of Dublin, 2024.](https://osf.io/vzt7s/download)
* [González Mendoza, Juan Pablo, Felipe Trujillo-Romero, and Juan José Cárdenas Cornejo. *Detección de objetos 3D con PointNet para la conducción autónoma* [3D Object Detection with PointNet for Autonomous Driving]. Congreso Estudiantil de Inteligencia Artificial Aplicada a la Ingeniería y Tecnología, UNAM, FESC, Estado de México, 2024.](https://virtual.cuautitlan.unam.mx/intar/memoriasceiaait/wp-content/uploads/sites/19/2024/12/66-Deteccion-de-objetos-3D-con-PointNet-para-la-%C2%B4__conduccion-aut-%C2%B4-onoma-EDITADO.pdf)
* Gray, Douglas, and Evan Shellshear. *Why Data Science Projects Fail: The Harsh Realities of Implementing AI and Analytics, Without the Hype.* Boca Raton, FL: CRC Press, 2024.
* [Greenberg, Ariel M. "A Schema for Harms-Sensitive Reasoning, and an Approach to Populate Its Ontology by Human Annotation." In *Putting AI in the Critical Loop: Assured Trust and Autonomy in Human-Machine Teams*, edited by Prithviraj Dasgupta, James Llinas, Tony Gillespie, Scott Fouse, William Lawless, Ranjeev Mittu, and Donald Sofge, 265--278. London: Academic Press, 2024.](https://doi.org/10.1016/B978-0-443-15988-6.00006-6)
* [Gross, Nicole. "A Powerful Potion for a Potent Problem: Transformative Justice for Generative AI in Healthcare." *AI and Ethics* (July 31, 2024).](https://doi.org/10.1007/s43681-024-00519-1)
* [Grosse, Kathrin, Lukas Bieringer, Tarek R. Besold, Battista Biggio, and Alexandre Alahi. "When Your AI Becomes a Target: AI Security Incidents and Best Practices." In *Proceedings of the AAAI Conference on Artificial Intelligence*, vol. 38, no. 21 (March 24, 2024): 23041--23046.](https://doi.org/10.1609/aaai.v38i21.30347)
* [Henman, Paul W. Fay. 2024. "Just AI: Using Socio-Legal Studies of Fairness to Inform Ethical AI in Government." In *Socio-Legal Generation: Essays in Honour of Michael Adler*, edited by Sharon Cowan and Simon Halliday, 37--54. Palgrave Socio-Legal Studies. Cham: Palgrave Macmillan.](https://doi.org/10.1007/978-3-031-67244-6_3)
* [Hollanek, Tomasz, and Indira Ganesh. "Easy Wins and Low Hanging Fruit: Blueprints, Toolkits, and Playbooks to Advance Diversity and Inclusion in AI." In *In/Convenience: Inhabiting the Logistical Surround*, edited by Joshua Neves and Marc Steinberg, 162--175. Amsterdam: Institute of Network Cultures, 2024.](https://doi.org/10.17863/CAM.113869)
* [Hossain, Mahmood, Hamad Khalid, Avent Prakasa Rao, Mohammad Lootah, Salah Salim Khalaf Al-Mohammedi, and Salih Rashid Majeed. "Comprehensive Review of AI, IoT, and ML in Enhancing Urban Mobility and Reducing Carbon Footprints." Paper presented at the *2024 Third International Conference on Sustainable Mobility Applications, Renewables and Technology (SMART)*, Dubai, United Arab Emirates, November 22--24, 2024. IEEE.](https://doi.org/10.1109/SMART63170.2024.10815521)
* [Householder, Allen, Vijay Sarvepalli, Jeff Havrilla, Matthew Churilla, Lena Pons, Shing-hon Lau, Nathan VanHoudnos, Andrew Kompanek, and Lauren McIlvenny. *Lessons Learned in Coordinated Disclosure for Artificial Intelligence and Machine Learning Systems.* Pittsburgh, PA: Carnegie Mellon University, Software Engineering Institute, August 2024.](https://doi.org/10.1184/R1/26867038.V1)
* [Howell, Bronwyn E. "WEIRD? Institutions and Consumers' Perceptions of Artificial Intelligence in 31 Countries." July 23, 2024. *SSRN*.](https://ssrn.com/abstract=4902254)
* [Hundt, Andrew, Julia Schuller, and Severin Kacianka. "Towards Equitable Agile Research and Development of AI and Robotics." *arXiv*, February 13, 2024.](https://doi.org/10.48550/arXiv.2402.08242)
* [Hussain, Muhammad, Ioanna Iacovides, Tom Lawton, Vishal Sharma, Zoe Porter, Alice Cunningham, Ibrahim Habli, Shireen Hickey, Yan Jia, Phillip Morgan, and Nee Ling Wong. "Development and Translation of Human-AI Interaction Models into Working Prototypes for Clinical Decision-Making." In *Proceedings of the 2024 ACM Designing Interactive Systems Conference* (DIS '24), 1607--1619. July 1, 2024.](https://doi.org/10.1145/3643834.3660697)
* [Hutiri, Wiebke, Orestis Papakyriakopoulos, and Alice Xiang. "Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators." In *Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency* (FAccT '24), 359--376. June 5, 2024.](https://doi.org/10.1145/3630106.3658911)
* [Kiviharju, Mikko. "On the Cybersecurity of Logistics in the Age of Artificial Intelligence." In *Artificial Intelligence for Security: Enhancing Protection in a Changing World*, edited by Tuomo Sipola, Janne Alatalo, Monika Wolfmayr, and Tero Kokkonen, 189--219. Cham: Springer, 2024.](https://doi.org/10.1007/978-3-031-57452-8_9)
* [Klingbeil, Artur, Cassandra Grützner, and Philipp Schreck. "Trust and Reliance on AI---An Experimental Study on the Extent and Costs of Overreliance on AI." *Computers in Human Behavior* 160 (November 2024): 108352.](https://doi.org/10.1016/j.chb.2024.108352)
* [Kloza, Dariusz, Thibaut D'hulst, and Malik Aouadi. "What Could Possibly Go Wrong? On Risks to the Rights and Freedoms of Natural Persons in EU Data Protection Law, Their Typologies and Their Identification." *Technology and Regulation* (2024): 309--329.](https://doi.org/10.26116/techreg.2024.022)
* [Knight, Simon, Cormac McGrath, Olga Viberg, and Teresa Cerratto Pargman. "Learning about AI Ethics from Cases: A Scoping Review of AI Incident Repositories and Cases." *Research Square*, August 23, 2024.](https://doi.org/10.21203/rs.3.rs-4844649/v1)
* [Knoll, Alessandra, ed. *Desafios do Direito Frente às Novas Tecnologias*. 1st ed. Vol. 1. Guarujá-SP: Editora Científica Digital, June 28, 2024.](https://doi.org/10.37885/978-65-5360-668-5)
* [Koh, Benjamin. "Seeking the Golden Thread in the Black Box: Artificial Intelligence and Personal Injury Law." *Precedent* (Sydney, N.S.W.), no. 183 (July 2024): 46--50. Sydney: Australian Lawyers Alliance.](https://search.informit.org/doi/abs/10.3316/informit.T2024082200016591870913932)
* [Kowald, Dominik, Sebastian Scher, Viktoria Pammer-Schindler, Peter Müllner, Kerstin Waxnegger, Lea Demelius, Angela Fessl, Maximilian Toller, Inti Gabriel Mendoza Estrada, Ilija Šimić, Vedran Sabol, Andreas Trügler, Eduardo Veas, Roman Kern, Tomislav Nad, and Simone Kopeinik. "Establishing and Evaluating Trustworthy AI: Overview and Research Challenges." *Frontiers in Big Data* 7 (November 28, 2024).](https://doi.org/10.3389/fdata.2024.1467222)
* [Kox, Esther S., and Beatrice Beretta. "Evaluating Generative AI Incidents: An Exploratory Vignette Study on the Role of Trust, Attitude, and AI Literacy." In *HHAI 2024: Hybrid Human AI Systems for the Social Good*, 188--198. Vol. 386 of *Frontiers in Artificial Intelligence and Applications*. Amsterdam: IOS Press, 2024.](https://doi.org/10.3233/FAIA240194)
* [Kuilman, Sietze Kai, Luciano Cavalcante Siebert, Stefan Buijsman, and Catholijn M. Jonker. "How to Gain Control and Influence Algorithms: Contesting AI to Find Relevant Reasons." *AI and Ethics* (June 5, 2024).](https://doi.org/10.1007/s43681-024-00500-y)
* [Laczi, Szandra Anna, and Valéria Póser. "Impact of Deepfake Technology on Children: Risks and Consequences." In *Proceedings of the 2024 IEEE 22nd Jubilee International Symposium on Intelligent Systems and Informatics (SISY)*, Pula, Croatia, September 19--21, 2024. IEEE, 2024.](https://doi.org/10.1109/SISY62279.2024.10737593)
* [Lanamäki, Arto, Karin Väyrynen, Heidi Hietala, Elena Parmiggiani, and Polyxeni Vasilakopoulou. 2024. "Not Inevitable: Navigating Labor Displacement and Reinstatement in the Pursuit of AI for Social Good." *Communications of the Association for Information Systems* 55: 831--845.](https://doi.org/10.17705/1CAIS.05531)
* [Lawrence, Neil D., and Jessica Montgomery. "Accelerating AI for Science: Open Data Science for Science." *Royal Society Open Science* 11, no. 8 (August 21, 2024).](https://doi.org/10.1098/rsos.231130)
* [Lee, Hao-Ping (Hank), Yu-Ju Yang, Thomas Serban Von Davier, Jodi Forlizzi, and Sauvik Das. "Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks." In *Proceedings of the CHI Conference on Human Factors in Computing Systems* (CHI '24), Article 775, 1--19. May 11, 2024.](https://doi.org/10.1145/3613904.3642116)
* [Lee, Sung Une, Harsha Perera, Boming Xia, Yue Liu, Qinghua Lu, and Liming Zhu. "QB4AIRA: A Question Bank for Responsible AI Risk Assessment." *IEEE Software* (Early Access), December 9, 2024.](https://doi.org/10.1109/MS.2024.3512577)
* [Lee, Sung Une, Harsha Perera, Yue Liu, Boming Xia, Qinghua Lu, and Liming Zhu. "Responsible AI Question Bank: A Comprehensive Tool for AI Risk Assessment." *arXiv*, August 2, 2024.](https://doi.org/10.48550/arXiv.2408.11820)
* [Leibowicz, Claire R., and Christian H. Cardona. "From Principles to Practices: Lessons Learned from Applying Partnership on AI's (PAI) Synthetic Media Framework to 11 Use Cases." *arXiv*, July 19, 2024.](https://doi.org/10.48550/arXiv.2407.13025)
* [Lu, You, Yifan Tian, Dingji Wang, Bihuan Chen, and Xin Peng. "AdvFuzz: Finding More Violations Caused by the EGO Vehicle in Simulation Testing by Adversarial NPC Vehicles." *arXiv* (preprint), November 29, 2024.](https://doi.org/10.48550/arXiv.2411.19567)
* [Lu, You, Yifan Tian, Yuyang Bi, Bihuan Chen, and Xin Peng. "DiaVio: LLM-Empowered Diagnosis of Safety Violations in ADS Simulation Testing." In *Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2024)*, 376--388. New York: Association for Computing Machinery, 2024.](https://doi.org/10.1145/3650212.3652135)
* [Maitra, Suvradip, Lyndal Sleep, Suzanna Fay, and Paul Henman. *Building a Trauma-Informed Algorithmic Assessment Toolkit.* ARC Centre of Excellence for Automated Decision-Making and Society, August 26, 2024.](https://dx.doi.org/10.60836/f01c-4a18)
* [Manheim, David. "Building a Culture of Safety for AI: Comparisons and Challenges." *SSRN*, July 10, 2024.](https://doi.org/10.2139/ssrn.4890287)
* [Mansyl, Vieri, and Windy Gambetta. "A Novel Approach to Explainable AI: Leveraging Ripple Down Rules Algorithm for Knowledge-Based Explanations." In *Proceedings of the 2024 11th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)*, Singapore, September 28--30, 2024. IEEE, 2024.](https://doi.org/10.1109/ICAICTA63815.2024.10763357)
* [Markovitch, Dmitri G., Rusty A. Stough, and Dongling Huang. "Consumer Reactions to Chatbot Versus Human Service: An Investigation in the Role of Outcome Valence and Perceived Empathy." *Journal of Retailing and Consumer Services* 79 (July 2024): 103847.](https://doi.org/10.1016/j.jretconser.2024.103847)
* [May, Richard, Jacob Krüger, and Thomas Leich. "SoK: How Artificial-Intelligence Incidents Can Jeopardize Safety and Security." In *Proceedings of the 19th International Conference on Availability, Reliability and Security* (ARES '24), Article 44, 1--12. July 30, 2024.](https://doi.org/10.1145/3664476.3664510)
* [McGrath, Quintin. "Responding to the Sharp Rise in AI in the 2023 SIM IT Trends Survey." *MIS Quarterly Executive* 23, no. 1 (March 2024): Article 8.](https://aisel.aisnet.org/misqe/vol23/iss1/8)
* [McGrath, Quintin, Alan R. Hevner, and Gert-Jan de Vreede. "Managing Ethical Risks of Artificial Intelligence in Business Applications." *TechRxiv*, February 27, 2024.](https://doi.org/10.36227/techrxiv.170905835.50964792/v1)
* [McGregor, Sean. "Open Digital Safety." *Computer* 57, no. 4 (April 2, 2024): 99--103.](https://doi.org/10.1109/MC.2023.3315028)
* [McGregor, Sean, Allyson Ettinger, Nick Judd, Paul Albee, Liwei Jiang, Kavel Rao, Will Smith, Shayne Longpre, Avijit Ghosh, Christopher Fiorelli, Michelle Hoang, Sven Cattell, and Nouha Dziri. "To Err Is AI: A Case Study Informing LLM Flaw Reporting Practices." *arXiv* (preprint), October 15, 2024.](https://doi.org/10.48550/arXiv.2410.12104)
* [Michałkiewicz-Kądziela, Ewa. "Deepfakes: New Challenges for Law and Democracy." In *Artificial Intelligence and International Human Rights Law*, edited by Michał Balcerzak and Julia Kapelańska-Pręgowska, 145--157. Cheltenham, UK: Edward Elgar Publishing, 2024.](https://doi.org/10.4337/9781035337934.00016)
* [Mishra, Saurabh, Anand Rao, Ramayya Krishnan, Bilal Ayyub, Amin Aria, and Enrico Zio. "Reliability, Resilience and Human Factors Engineering for Trustworthy AI Systems." *arXiv* (preprint), November 13, 2024.](https://doi.org/10.48550/arXiv.2411.08981)
* [Morales, Sergio, Robert Clarisó, and Jordi Cabot. "A DSL for Testing LLMs for Fairness and Bias." In *Proceedings of the ACM/IEEE 2024 International Conference on Model Driven Engineering Languages and Systems (MODELS '24)*, Linz, Austria, September 22--27, 2024.](https://modeling-languages.com/wp-content/uploads/2024/07/A_DSL_for_Testing_LLMs_for_Fairness_and_Bias-MODELS24.pdf)
* [National Institute of Standards and Technology (NIST). *Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile.* NIST AI 600-1. July 2024.](https://doi.org/10.6028/NIST.AI.600-1)
* [Nedzhvetskaya, Nataliya, and JS Tan. "No Simple Fix: How AI Harms Reflect Power and Jurisdiction in the Workplace." In *Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency* (FAccT '24), 422--432. June 5, 2024.](https://doi.org/10.1145/3630106.3658915)
* [Neogi, Trisha. *Protecting People with Disabilities: A Guide for Non-Technical Committee Members in Understanding the Regulations Needed to Design Ethical AI.* Master's Research Project, OCAD University, May 1, 2024.](https://openresearch.ocadu.ca/id/eprint/4370)
* [Palomba, Fabio, Andrea Di Sorbo, Davide Di Ruscio, Filomena Ferrucci, Gemma Catolino, Giammaria Giordano, Dario Di Dario, Gianmario Voria, Viviana Pentangelo, Maria Tortorella, et al. "FRINGE: Context-Aware FaiRness EngineerING in Complex Software Systems." In *Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM '24)*, 608--12. New York: Association for Computing Machinery, 2024.](https://doi.org/10.1145/3674805.3695394)
* [Paeth, Kevin, Daniel Atherton, Nikiforos Pittaras, Heather Frase, and Sean McGregor. *Lessons for Editors of AI Incidents from the AI Incident Database*. September 24, 2024. arXiv.](https://doi.org/10.48550/arXiv.2409.16425)
* [Perez-de-Viñaspre, Olatz, Olatz Arregi, and Itziar Irigoien. "Adimen artifizialeko alborapena ulertzen (Understanding Artificial Intelligence Bias)." *Ekaia: Zientzia eta Teknologia Aldizkaria*, in press (2025).](https://doi.org/10.1387/ekaia.26823)
* [Pérez-Ugena Coromina, María. "Sesgo de Género (en IA)." *EUNOMÍA. Revista en Cultura de la Legalidad* 26 (March 14, 2024): 311--330.](https://doi.org/10.20318/eunomia.2024.8515)
* [O'Connor, Mary I. "Equity360: Gender, Race, and Ethnicity---The Power of AI to Improve or Worsen Health Disparities." *Clinical Orthopaedics and Related Research* 482, no. 4 (April 2024): 591--594.](https://doi.org/10.1097/CORR.0000000000002986)
* [Ortega-Bolaños, Ricardo, Joshua Bernal-Salcedo, Mariana Germán Ortiz, Julian Galeano Sarmiento, Gonzalo A. Ruz, and Reinel Tabares-Soto. "Applying the Ethics of AI: A Systematic Review of Tools for Developing and Assessing AI-Based Systems." *Artificial Intelligence Review* 57 (April 5, 2024): 110.](https://doi.org/10.1007/s10462-024-10740-3)
* [Rauh, Maribeth, Nahema Marchal, Arianna Manzini, Lisa Anne Hendricks, Ramona Comanescu, Canfer Akbulut, Tom Stepleton, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Griffin, Ben Bariach, Iason Gabriel, Verena Rieser, William Isaac, and Laura Weidinger. "Gaps in the Safety Evaluation of Generative AI." *Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society* 7, no. 1 (2024): 1200--1217.](https://doi.org/10.1609/aies.v7i1.31717)
* [Raus, Rachele, Francesca Bisiani, Maria Margherita Mattioda, and Michela Tonti, eds. *Multilinguisme européen et IA entre droit, traduction et didactique des langues / Multilinguismo europeo e IA tra diritto, traduzione e didattica delle lingue / European Multilingualism and Artificial Intelligence: The Impacts on Law, Translation and Language Teaching*. Turin: Università di Torino, 2024.](https://www.collane.unito.it/oa/items/show/195)
* [Rémy, Nicolas, Frédéric Deschamps, and Stéphane Kreckelbergh. "Construire la confiance des ChatBots à base de LLM." Paper presented at *Congrès Lambda Mu 24: Les métiers du risque : clés de la réindustrialisation et de la transition écologique*, Institut pour la Maîtrise des Risques (IMdR), Bourges, France, October 2024.](https://hal.science/hal-04893287)
* [Rommetveit, Kjetil, and Ingrid Foss Ballo. *D 5.1: Case Study Co-Creation Methodology Report. (How) Can You Build Morality into Artificially Intelligent Systems?* SUPER MoRRI -- Scientific Understanding and Provision of an Enhanced and Robust Monitoring System for RRI, Version 2. June 14, 2023.](https://promise4era.eu/wp-content/uploads/2024/03/EthicalAI.pdf)
* [Rupe, Jason, and Chris LaPlante. "Introducing the Reliability Society Failure Database." *IEEE Reliability Magazine* 1, no. 1 (March 2024): 5--9.](https://doi.org/10.1109/MRL.2024.3353701)
* [Salvador, Cole. "Certified Safe: A Schematic for Approval Regulation of Frontier AI." *arXiv*, August 12, 2024.](https://doi.org/10.48550/arXiv.2408.06210)
* [Saran, Samir, Anulekha Nandi, and Sameer Patil. *'Moving Horizons': A Responsive and Risk-Based Regulatory Framework for A.I.* Special Report. Observer Research Foundation, June 28, 2024.](https://www.orfonline.org/research/moving-horizons-a-responsive-and-risk-based-regulatory-framework-for-a-i)
* [Sengupta, Ushnish. "Black Box Algorithmic Decision-Making and Transparency Challenges in Policing Practice: Lessons from Implementation of New Technologies by the Toronto Police Service." In *Policing and Intelligence in the Global Big Data Era, Volume II: New Global Perspectives on the Politics and Ethics of Knowledge*, edited by Tereza Østbø Kuldova, Helene Oppen Ingebrigtsen Gundhus, and Christin Thea Wathne, 195--233. Palgrave's Critical Policing Studies. Cham: Palgrave Macmillan, 2024.](https://doi.org/10.1007/978-3-031-68298-8)
* [Sharma, Chinmayi. "AI's Hippocratic Oath." *Washington University Law Review*, forthcoming. *Yale Law & Economics Research Paper*. March 14, 2024.](https://ssrn.com/abstract=4759742)
* [Sharma, Kavita, and Padmavati Manchikanti. "Artificial Intelligence and Policy in Healthcare Industry." In *Artificial Intelligence in Drug Development: Patenting and Regulatory Aspects*, 117--144. Frontiers of Artificial Intelligence, Ethics and Multidisciplinary Applications. Singapore: Springer, 2024.](https://doi.org/10.1007/978-981-97-2954-8_4)
* [Shams, Rifat Ara, Didar Zowghi, and Muneera Bano. "AI for All: Identifying AI Incidents Related to Diversity and Inclusion." *arXiv*, July 19, 2024.](https://doi.org/10.48550/arXiv.2408.01438)
* [Shane, Tommy Shaffer. *AI Incident Reporting: Addressing a Gap in the UK's Regulation of AI*. The Centre for Long-Term Resilience, June 2024.](https://www.longtermresilience.org/wp-content/uploads/2024/06/AI-incident-reporting_-Addressing-a-gap-in-the-UKs-regulation-of-AI-1.pdf)
* [Sharma, Kavita, and Padmavati Manchikanti. "Artificial Intelligence and Policy in Healthcare Industry." In *Artificial Intelligence in Drug Development*, 117--144. *Frontiers of Artificial Intelligence, Ethics and Multidisciplinary Applications.* Singapore: Springer, 2024.](https://doi.org/10.1007/978-981-97-2954-8_4)
* [Shoker, Ali, Rehana Yasmin, and Paulo Esteves-Verissimo. 2024. "WIP: *Savvy*: A Trustworthy Autonomous Vehicles Architecture." *Symposium on Vehicles Security and Privacy (VehicleSec) 2024*, San Diego, CA, February 26, 2024.](https://dx.doi.org/10.14722/vehiclesec.2024.23058)
* [Shoker, Ali, Rehana Yasmin, and Paulo Esteves-Verissimo. "Savvy: Trustworthy Autonomous Vehicles Architecture." *arXiv*, February 8, 2024.](https://doi.org/10.48550/arXiv.2402.14580)
* [Siqueira de Cerqueira, José Antonio, Mamia Agbese, Rebekah Rousi, Nannan Xi, Juho Hamari, and Pekka Abrahamsson. "Can We Trust AI Agents? An Experimental Study Towards Trustworthy LLM-Based Multi-Agent Systems for AI Ethics." *arXiv* preprint arXiv:2411.08881 [cs.CY], October 25, 2024.](https://doi.org/10.48550/arXiv.2411.08881)
* [Škoro, Ivana Emily. "Blockchain Art Activism: Examining Four Blockchain-Based Artworks for Social, Political, and Environmental Good." Master's thesis, Aalborg University and Media Arts Cultures Consortium, June 7, 2024.](https://vbn.aau.dk/ws/files/719468092/FINAL_MA_THESIS.pdf)
* [Spinner, Thilo, Daniel Fürst, and Mennatallah El-Assady. "iNNspector: Visual, Interactive Deep Model Debugging." *arXiv*, July 25, 2024.](https://doi.org/10.48550/arXiv.2407.17998)
* [Soudi, Marwa Samih, and Merja Bauters. "AI Guidelines and Ethical Readiness Inside SMEs: A Review and Recommendations." *Digital Society* 3 (January 31, 2024): Article 3.](https://doi.org/10.1007/s44206-024-00087-1)
* [Stanley, Jeff, and Hannah Lettie. *Emerging Risks and Mitigations for Public Chatbots: LILAC v1*. MTR240382. McLean, VA: The MITRE Corporation, September 2024.](https://www.mitre.org/sites/default/files/2024-10/PR-24-2767-Emerging-Risks-Mitigations-Public-Chatbots-LILAC-v1.pdf)
* [Torkamaan, Helma, Mohammad Tahaei, Stefan Buijsman, Ziang Xiao, Daricia Wilkinson, and Bart P. Knijnenburg. "The Role of Human-Centered AI in User Modeling, Adaptation, and Personalization---Models, Frameworks, and Paradigms." In *A Human-Centered Perspective of Intelligent Personalized Environments and Systems*, edited by Bruce Ferwerda, Mark Graus, Panagiotis Germanakos, and Marko Tkalčič, 43--84. Human--Computer Interaction Series. Cham: Springer, 2024.](https://doi.org/10.1007/978-3-031-55109-3_2)
* [Tran, Michelle, and Casey Fiesler. "'It's Not Exactly Meant to Be Realistic': Student Perspectives on the Role of Ethics in Computing Group Projects." In *Proceedings of the 2024 ACM Conference on International Computing Education Research* (ICER '24), 517--526. August 12, 2024.](https://doi.org/10.1145/3632620.3671109)
* [Tuovinen, Lauri, and Kimmo Halunen. "What Is an AI Vulnerability, and Why Should We Care? Unpacking the Relationship Between AI Security and AI Ethics." In *Proceedings of the Conference on Technology Ethics 2024 (Tethics 2024)*, edited by Thomas Olsson et al., 30--41. CEUR Workshop Proceedings 3901. RWTH Aachen, November 7, 2024.](https://ceur-ws.org/Vol-3901/paper_3.pdf)
* [Tyukin, Ivan Y., Tatiana Tyukina, Daniël P. van Helden, Zedong Zheng, Evgeny M. Mirkes, Oliver J. Sutton, Qinghua Zhou, Alexander N. Gorban, and Penelope Allison. "Coping with AI Errors with Provable Guarantees." *Information Sciences* 678 (September 2024): 120856.](https://doi.org/10.1016/j.ins.2024.120856)
* [Tyukin, Ivan Y., Tatiana Tyukina, Daniël P. van Helden, Zedong Zheng, Evgeny M. Mirkes, Oliver J. Sutton, Qinghua Zhou, Alexander N. Gorban, and Penelope Allison. "Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees." *arXiv*, February 13, 2024.](https://doi.org/10.48550/arXiv.2402.00899)
* [Uzwyshyn, Raymond. "Building Library Artificial Intelligence Capacity: Research Data Repositories and Scholarly Ecosystems." In *New Horizons in Artificial Intelligence in Libraries*, edited by Andrew Cox, Edmund Balnaves, Leda Bultrini, and Raymond Uzwyshyn, 121--140. Berlin: De Gruyter, 2024.](https://doi.org/10.1515/9783111336435-010)
* [Verma, Karishma. "Digital Deception: The Impact of Deepfakes on Privacy Rights." *Lex Scientia Law Review* 8, no. 2 (2024): 859--896.](https://doi.org/10.15294/lslr.v8i2.13749)
* [Vidgen, Bertie, Adarsh Agrawal, Ahmed M. Ahmed, Victor Akinwande, Namir Al-Nuaimi, Najla Alfaraj, Elie Alhajjar, Lora Aroyo, Trupti Bavalatti, Max Bartolo, Borhane Blili-Hamelin, Kurt Bollacker, Rishi Bomassani, Marisa Ferrara Boston, Siméon Campos, Kal Chakra, Canyu Chen, Cody Coleman, Zacharie Delpierre Coudert, Leon Derczynski, Debojyoti Dutta, Ian Eisenberg, James Ezick, Heather Frase, Brian Fuller, Ram Gandikota, Agasthya Gangavarapu, Ananya Gangavarapu, James Gealy, Rajat Ghosh, James Goel, Usman Gohar, Sujata Goswami, Scott A. Hale, Wiebke Hutiri, Joseph Marvin Imperial, Surgan Jandial, Nick Judd, Felix Juefei-Xu, Foutse Khomh, Bhavya Kailkhura, Hannah Rose Kirk, Kevin Klyman, Chris Knotz, Michael Kuchnik, Shachi H. Kumar, Srijan Kumar, Chris Lengerich, Bo Li, Zeyi Liao, Eileen Peters Long, Victor Lu, Sarah Luger, Yifan Mai, Priyanka Mary Mammen, Kelvin Manyeki, Sean McGregor, Virendra Mehta, Shafee Mohammed, Emanuel Moss, Lama Nachman, Dinesh Jinenhally Naganna, Amin Nikanjam, Besmira Nushi, Luis Oala, Iftach Orr, Alicia Parrish, Cigdem Patlak, William Pietri, Forough Poursabzi-Sangdeh, Eleonora Presani, Fabrizio Puletti, Paul Röttger, Saurav Sahay, Tim Santos, Nino Scherrer, Alice Schoenauer Sebag, Patrick Schramowski, Abolfazl Shahbazi, Vin Sharma, Xudong Shen, Vamsi Sistla, Leonard Tang, Davide Testuggine, Vithursan Thangarasa, Elizabeth Anne Watkins, Rebecca Weiss, Chris Welty, Tyler Wilbers, Adina Williams, Carole-Jean Wu, Poonam Yadav, Xianjun Yang, Yi Zeng, Wenhui Zhang, Fedor Zhdanov, Jiacheng Zhu, Percy Liang, Peter Mattson, and Joaquin Vanschoren. "Introducing v0.5 of the AI Safety Benchmark from MLCommons." *arXiv*, May 13, 2024.](https://doi.org/10.48550/arXiv.2404.12241)
* [Viureanu, Andrei, and Bogdan Ionescu. "AI Vulnerabilities." Paper presented at the *1st Workshop on Artificial Intelligence for Multimedia*, AI Multimedia Lab, CAMPUS Research Institute, POLITEHNICA Bucharest, Bucharest, Romania, November 8, 2024.](https://www.aimultimedialab.ro/1st-Workshop-on-Artificial-Intelligence-for-Multimedia/Andrei_Vizureanu_AI_Vulnerabilities.pdf)
* [Volkova, Svetlana. "The Dark Side of Deepfakes: Fraud and Cybercrime." In *Deepfake Technology Applications and Societal Implications*, edited by Gaurav Gupta, Kapil Pandla, Raj K. Kovid, and Sailaja Bohara, 221--242. Hershey, PA: IGI Global, 2024.](https://doi.org/10.4018/979-8-3693-6890-9.ch010)
* [Wang, Runfeng. *Examining Algorithmic Bias Toward Racial Minorities in New Media*. Syracuse University, 2024. Renée Crown University Honors Thesis Projects.](https://surface.syr.edu/honors_capstone/1574)
* [Warren, Sarah Egan. "Navigating the Changes That AI Is Bringing to Higher Education." *UNC System Learning and Technology Journal* 2, no. 1 (August 26, 2024): Special Issue - Exploring the Transformative Impact of Artificial Intelligence in Higher Education: Challenges, Opportunities, and Ethical Considerations.](https://journals.charlotte.edu/ltj/article/view/1778)
* [Wei, Mengyi, Chenjing Jiao, Chenyu Zuo, Lorenz Hurni, and Liqiu Meng. "How Generative AI Supports Understanding of an Ethically Sensitive AI-Induced Event." *Abstracts of the International Cartographic Association* 8 (2024): 26. Presented at the 2024 ICA Workshop on AI, Geovisualization, and Analytical Reasoning -- CartoVis24, University of Warsaw, Poland, September 7, 2024.](https://doi.org/10.5194/ica-abs-8-26-2024)
* [Wodi, Alex. "Artificial Intelligence (AI) Governance: An Overview." May 24, 2024. *SSRN*.](https://ssrn.com/abstract=4840769)
* [World Economic Forum. *Generative AI Governance: Shaping a Collective Global Future in Collaboration with Accenture.* AI Governance Alliance Briefing Paper Series, January 18, 2024.](https://www3.weforum.org/docs/WEF_Generative_AI_Governance_2024.pdf)
* [Worth, Sophia, Ben Snaith, Arunav Das, Gefion Thuermer, and Elena Simperl. "AI Data Transparency: An Exploration through the Lens of AI Incidents." *arXiv*, September 5, 2024.](https://doi.org/10.48550/arXiv.2409.03307)
* [Xi, Ran. 2024. "A Systems Approach to Shedding Sunlight on AI Black Boxes." *Hofstra Law Review* 53 (3), forthcoming 2025.](https://ssrn.com/abstract=4966957)
* [Xu, Wei, Zaifeng Gao, and Marvin Dainoff. "An HCAI Methodological Framework (HCAI-MF): Putting It Into Action to Enable Human-Centered AI." *arXiv*, originally submitted November 27, 2023, last revised December 21, 2024.](https://doi.org/10.48550/arXiv.2311.16027)
* [Xu, Wei. "A New Design Philosophy: Human-Centered Artificial Intelligence." In *Human-AI Interaction: Enabling Human-Centered AI*. Beijing: Tsinghua University Press, forthcoming 2024.](https://www.researchgate.net/profile/Wei-Xu-151/publication/379035384_Chapter_1_A_New_Design_Philosophy_Human-Centered_Artificial_Intelligence/links/66010e31a8baf573a1d69dc0/Chapter-1-A-New-Design-Philosophy-Human-Centered-Artificial-Intelligence.pdf)
* [Xu, Wei. "A 'User Experience 3.0 (UX 3.0)' Paradigm Framework: User Experience Design for Human-Centered AI Systems." *arXiv*, March 7, 2024.](https://doi.org/10.48550/arXiv.2403.01609)
* [Xu, Wei, and Zaifeng Gao. "An Intelligent Sociotechnical Systems (iSTS) Concept: Toward a Sociotechnically-Based Hierarchical Human-Centered AI Approach." *arXiv*, July 22, 2024.](https://doi.org/10.48550/arXiv.2401.03223)
* [Xu, Wei, and Zaifeng Gao. "Enabling Human-Centered AI: A Methodological Perspective." In *2024 IEEE 4th International Conference on Human-Machine Systems (ICHMS)*, Toronto, ON, May 15--17, 2024. IEEE, June 19, 2024.](https://doi.org/10.1109/ICHMS59971.2024.10555771)
* [Xu, Wei, Zaifeng Gao, and Liezhong Ge. "New Research Paradigms and Agenda of Human Factors Science in the Intelligence Era." *Acta Psychologica Sinica* 56, no. 3 (2024): 363--382.](https://doi.org/10.3724/SP.J.1041.2024.00363)
* [Yang, Khoo Wei. *Data Relationality: Privacy in the AI Age*. Kuala Lumpur: Khazanah Research Institute, October 24, 2024.](https://www.krinstitute.org/assets/contentMS/img/template/editor/Views_Data%20Relationality_v3_upload.pdf)
* [Yeung, Karen. "Beyond 'AI Boosterism.'" *IPPR Progressive Review* 31, no. 2 (2024): 114--20.](https://doi.org/10.1111/newe.12400)
* [Ződi, Zsolt. "The Conflict of the Engineering and the Legal Mindset in the Artificial Intelligence Act." *SSRN*, last revised November 6, 2024.](https://doi.org/10.2139/ssrn.4928715)

## 2023

#### Citations in peer-reviewed journal articles, book chapters, and preprints
* [Ali, S. A., Khan, R., & Ali, S. N. (2023). The Promises and Perils of Artificial Intelligence: An Ethical and Social Analysis. In S. Chakraborty (Ed.), Investigating the Impact of AI on Ethics and Spirituality (pp. 1-24). IGI Global.](https://doi.org/10.4018/978-1-6684-9196-6.ch001)
* [Apruzzese, G., Anderson, H. S., Dambra, S., Freeman, D., Pierazzi, F., & Roundy, K. (2023). "Real attackers don't compute gradients": Bridging the gap between adversarial ML research and practice. In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) (pp. 1-10). IEEE. ](https://doi.org/10.1109/SaTML54575.2023.00031)
* [Bach, T. A., Kristiansen, J. K., Babic, A., & Jacovi, A. (2023). Unpacking human-AI interaction in safety-critical industries: A systematic literature review. arXiv.](https://doi.org/10.48550/arXiv.2310.03392)
* [Baeza-Yates, R. (2023). An introduction to responsible AI. European Review, 31(4), 406-421.](https://doi.org/10.1017/S1062798723000145)
* [Batool, A., Zowghi, D., & Bano, M. (2023). Responsible AI governance: A systematic literature review. arXiv.](https://doi.org/10.48550/arXiv.2401.10896)
* [Bommasani, R., Klyman, K., Longpre, S., Kapoor, S., Maslej, N., Xiong, B., Zhang, D., & Liang, P. (2023). The Foundation Model Transparency Index. arXiv.](https://doi.org/10.48550/arXiv.2310.12941)
* [Bondi-Kelly, E., Hartvigsen, T., Sanneman, L. M., Sankaranarayanan, S., Harned, Z., Wickerson, G., Gichoya, J. W., Oakden-Rayner, L., Celi, L. A., Lungren, M. P., Shah, J. A., & Ghassemi, M. (2023). Taking off with AI: Lessons from aviation for healthcare. In EAAMO '23: Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (Article No. 4, pp. 1-14). ACM.](https://doi.org/10.1145/3617694.3623224)
* [Chatterjee, R. (2023). The scope of roboethics in business ethics. 3D... IBA Journal of Management & Leadership, 14(2), 22-27.](https://iba.ac.in/wp-content/uploads/2023/06/3D-IBA-Journal-of-Management-Leadership_-January-June-2023-Volume-14-%E2%80%93-Issue-2.pdf#page=22)
* [Chen, P.-Y., & Liu, S. (2024). Holistic adversarial robustness of deep learning models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(13), 15411-15420.](https://doi.org/10.1609/aaai.v37i13.26797)
* [Di Mascio, T., Caruso, F., & Peretti, S. (2023). How to make an artificial intelligence algorithm "ecological"? Insights from a holistic perspective. In CHItaly '23: Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter (Article No. 21, pp. 1-7). ACM.](https://doi.org/10.1145/3605390.3605398)
* [Faivre, J. (2023). The AI Act: Towards global effects? SSRN.](http://dx.doi.org/10.2139/ssrn.4514993)
* [Feffer, M., Martelaro, N., & Heidari, H. (2023). The AI Incident Database as an educational tool to raise awareness of AI harms: A classroom exploration of efficacy, limitations, & future improvements. EAAMO '23: Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (Article No. 3, pp. 1-11).](https://doi.org/10.1145/3617694.3623223)
* [Greser, J. (2023). Kilka uwag o cyberbezpieczeństwie medycznej AI. In A. Szczęsna & M. Stachoń (Eds.), Cyberbezpieczeństwo AI. AI w cyberbezpieczeństwie (pp. 73-81). NASK - Państwowy Instytut Badawczy. ISBN 978-83-65448-55-2.](https://cyberpolicy.nask.pl/cyberbezpieczenstwo-ai-ai-w-cyberbezpieczenstwie/)
* [Groza, A., & Marginean, A. (2023). Brave new world: AI in teaching and learning. In ICERI2023 Proceedings (pp. 8706-8713). Technical University of Cluj-Napoca.](https://doi.org/10.21125/iceri.2023.2221)
* [Groza, A., & Marginean, A. (2023). Brave new world: Artificial intelligence in teaching and learning. arXiv.](https://doi.org/10.48550/arXiv.2310.06856)
* [Hadshar, R. (2023). A review of the evidence for existential risk from AI via misaligned power-seeking. arXiv.](https://doi.org/10.48550/arXiv.2310.18244)
* [Hong, Y., Lian, J., Xu, L., Min, J., Wang, Y., & Freeman, L. J. (2023). Statistical perspectives on reliability of artificial intelligence systems. Quality Engineering, 35(1), 56-78.](https://doi.org/10.1080/08982112.2022.2089854)
* [Huang, R., Holzapfel, A., Sturm, B., & Kaila, A.-K. (2023). Beyond diverse datasets: Responsible MIR, interdisciplinarity, and the fractured worlds of music. Transactions of the International Society for Music Information Retrieval, 6(1), 43-59.](https://doi.org/10.5334/tismir.141)
* [Inoue, S., Nguyen, M.-T., Mizokuchi, H., Nguyen, T.-A. D., Nguyen, H.-H., & Le, D. T. (2023). Towards safer operations: An expert-involved dataset of high-pressure gas incidents for preventing future failures. arXiv.](https://doi.org/10.48550/arXiv.2310.12074)
* [Kanade, A., Bhoite, S., Kanade, S., & Jain, N. (2023). Artificial Intelligence and Morality: A Social Responsibility. Journal of Intelligence Studies in Business, 13(1).](https://doi.org/10.37380/jisib.v13i1.992)
* [Kilhoffer, Z., Nlkolich, A., Sanfilippo, M. R., & Zhou, Z. (2023). AI accountability policy. School of Information Sciences, University of Illinois at Urbana-Champaign.](https://hdl.handle.net/2142/118127)
* [Larsonneur, C. (2023). L'algorithme sert-il les traducteurs ? Conditions et contexte de travail avec les outils de traduction neuronale. In O. Guillon & S. Pickford (Eds.), Approches socio-économiques de la traduction littéraire (Vol. 35, Issue 2, pp. 90-103). Parallèles.](https://hal.science/hal-04560757)
* [Lupo, G. (2023). Risky artificial intelligence: The role of incidents in the path to AI regulation. Law, Technology and Humans, 5(1), 133-152. Faculty of Law, Queensland University of Technology.](https://doi.org/2652-4074)
* [Marres, N., & Sormani, P. (2023). Testing 'AI': Do we have a situation? A conversation. Universität Siegen.](https://doi.org/10.25819/ubsi/10332)
* [McConvey, K., Guha, S., & Kuzminykh, A. (2023). A human-centered review of algorithms in decision-making in higher education. In CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (Article No. 223, pp. 1-15). ACM.](https://doi.org/10.1145/3544548.3580658)
* [McGregor, S. (2023). A scaled multiyear responsible artificial intelligence impact assessment. Computer, 56(8), 20-27.](https://doi.org/10.1109/MC.2022.3231551)
* [McGregor, S., & Hostetler, J. (2023). Data-centric governance. arXiv.](https://doi.org/10.48550/arXiv.2302.07872)
* [Morgan, P. (2023). Tort liability and autonomous systems accidents: Challenges and future developments. In P. Morgan (Ed.), Tort liability and autonomous systems accidents (pp. 1-26). Edward Elgar Publishing.](https://doi.org/10.4337/9781802203844)
* [Pan, C., Gao, Y., & Gu, A. (2023). Modeling operational profile for AI systems: A case study on UAV systems. In 2023 4th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI) (pp. 1-8). IEEE.](https://doi.org/10.1109/ICHCI58871.2023.10277723)
* [Pletcher, S. N. (2023, September 1). Starting Slowly to Go Fast Deep Dive in the Context of AI Pilot Projects.](https://doi.org/10.31219/osf.io/8jqzu)
* [Pletcher, S. (2023). Visual privacy: Current and emerging regulations around unconsented video analytics in retail. arXiv.](https://doi.org/10.48550/arXiv.2302.12935)
* [Rodrigues, R., Resseguier, A., & Santiago, N. (2023). When artificial intelligence fails: The emerging role of incident databases. Public Governance, Administration and Finances Law Review, 8(2), 17-28.](https://doi.org/10.53116/pgaflr.7030)
* [Rousi, R., Samani, H., Mäkitalo, N., Vakkuri, V., Linkola, S., Kemell, K.-K., Daubaris, P., Fronza, I., Mikkonen, T., & Abrahamsson, P. (2024). Business and ethical concerns in domestic conversational generative AI-empowered multi-robot systems. In S. Hyrynsalmi, J. Münch, K. Smolander, & J. Melegati (Eds.), Software Business: 14th International Conference, ICSOB 2023, Lahti, Finland, November 27--29, 2023, Proceedings (pp. 173-189). Springer.](https://doi.org/10.1007/978-3-031-53227-6_13)
* [Schloetzer, J. D., & Yoshinaga, K. (2023). Algorithmic hiring systems: Implications and recommendations for organisations and policymakers. In YSEC Yearbook of Socio-Economic Constitutions 2023: Law and the governance of artificial intelligence (pp. 213-246). Springer.](https://doi.org/10.1007/16495_2023_61>)
* [Schloetzer, J. D., & Yoshinaga, K. (2023). Algorithmic hiring systems: Implications and recommendations for organisations and policymakers. Law and the Governance of Artificial Intelligence, Yearbook of Socio-Economic Constitutions. Springer, Cham.](http://dx.doi.org/10.2139/ssrn.4638864)
* [Shaffer Shane, T. (2023). AI incidents and 'networked trouble': The case for a research agenda. Big Data & Society, 10(2).](https://doi.org/10.1177/20539517231215360)
* [Shoker, S., Reddie, A., Barrington, S., Booth, R., Brundage, M., Chahal, H., Depp, M., Drexel, B., Gupta, R., Favaro, M., Hecla, J., Hickey, A., Konaev, M., Kumar, K., Lambert, N., Lohn, A., O'Keefe, C., Rajani, N., Sellitto, M., Trager, R., Walker, L., Wehsener, A., & Young, J. (2023). Confidence-building measures for artificial intelligence: Workshop proceedings. arXiv.](https://doi.org/10.48550/arXiv.2308.00862)
* [Silicki, K. (2023). Cyberbezpieczeństwo systemów wykorzystujących sztuczną inteligencję w świetle raportów ENISA. In A. Szczęsna & M. Stachoń (Eds.), Cyberbezpieczeństwo AI. AI w cyberbezpieczeństwie (pp. 10-21). NASK - Państwowy Instytut Badawczy.](https://repo.pw.edu.pl/docstore/download/WUT6449aa5e4ab942499d2e14307e321ce2/Cyberbezpieczenstwo-AI.-AI-w-cyberbezpieczenstwie-1.pdf)
* [Sood, S., & Kim, A. (2023). The golden age of the big data audit: Agile practices and innovations for e-commerce, post-quantum cryptography, psychosocial hazards, artificial intelligence algorithm audits, and deepfakes. International Journal of Innovation and Economic Development, 9(2), 7-23.](http://hdl.handle.net/10453/179305)
* [Stoica, A.-A., & Pica, Ș. (2023). Drones and the ethical politics of public monitoring. Challenges of the Knowledge Society. Public Law, 337-345.](https://www.proquest.com/scholarly-journals/drones-ethical-politics-public-monitoring/docview/2834505455/se-2)
* [Turri, V., & Dzombak, R. (2023). Why we need to know more: Exploring the state of AI incident documentation practices. AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society, 576-583.](https://doi.org/10.1145/3600211.3604700)
* [Velichkovska, B., Denkovski, D., Gjoreski, H., Kalendar, M., & Osmani, V. (2023). A Survey of Bias in Healthcare: Pitfalls of Using Biased Datasets and Applications. In Artificial Intelligence Application in Networks and Systems (CSOC 2023) (pp. 570-584). Lecture Notes in Networks and Systems, volume 724. Springer.](https://doi.org/10.1007/978-3-031-35314-7_50)
* [Watson, E., Viana, T., & Zhang, S. (2023). Augmented behavioral annotation tools, with application to multimodal datasets and models: A systematic review. AI, 4(1), 128-171.](https://doi.org/10.3390/ai4010007)
* [Winter, C., Hollman, N., & Manheim, D. (2023). Value Alignment for Advanced Artificial Judicial Intelligence. American Philosophical Quarterly, 60(2), 187-203.](https://doi.org/10.5406/21521123.60.2.06)
* Wright, L. S. (2023). Artificial intelligence: Why we need it and why we need to be cautious. In M. Lovell, O. S. Moghraby, & R. Waller (Eds.), Digital Mental Health: From Theory to Practice (pp. 60-71). Cambridge University Press.
* [Wu, W., & Liu, S. (2023). A comprehensive review and systematic analysis of artificial intelligence regulation policies. arXiv.](https://doi.org/10.48550/arXiv.2307.12218)
* [Xia, B., Lu, Q., Perera, H., Zhu, L., Xing, Z., Liu, Y., & Whittle, J. (2023). Towards concrete and connected AI risk assessment (C2AIRA): A systematic mapping study. In 2023 IEEE/ACM 2nd International Conference on AI Engineering -- Software Engineering for AI (CAIN) (pp. 27-34). IEEE.](https://doi.org/10.1109/CAIN58948.2023.00027)
* [Xia, B., Lu, Q., Perera, H., Zhu, L., Xing, Z., Liu, Y., & Whittle, J. (2023). Towards concrete and connected AI risk assessment (C2AIRA): A systematic mapping study. arXiv.](https://doi.org/10.48550/arXiv.2301.11616)
* [Xu, W. (2023). User-centered design (IX): A "user experience 3.0" paradigm framework in the intelligence era. arXiv.](https://doi.org/10.48550/arXiv.2302.06681)
* [Xu, W., & Dainoff, M. (2023). Enabling human-centered AI: A new junction and shared journey between AI and HCI communities. Interactions, 30(1), 42-47.](https://doi.org/10.1145/3571883)
* [Xu, W., & Dainoff, M. (2023). Enabling human-centered AI: A new junction and shared journey between AI and HCI communities. arXiv.](https://doi.org/10.48550/arXiv.2111.08460)
* [Xu, W., Dainoff, M. J., Ge, L., & Gao, Z. (2023). Transitioning to human interaction with AI systems: New challenges and opportunities for HCI professionals to enable human-centered AI. International Journal of Human--Computer Interaction, 39(3), 494-518.](https://doi.org/10.1080/10447318.2022.2041900)
* [Zhan, X., Sun, H., & Miranda, S. M. (2023). How does AI fail us? A typological theorization of AI failures. In ICIS 2023 Proceedings: AI in Business and Society.](https://aisel.aisnet.org/icis2023/aiinbus/aiinbus/25/)
* [Zhou, L., Moreno-Casares, P. A., Martínez-Plumed, F., Burden, J., Burnell, R., Cheke, L., Ferri, C., Marcoci, A., Mehrbakhsh, B., Moros-Daval, Y., Ó hÉigeartaigh, S., Rutar, D., Schellaert, W., Voudouris, K., & Hernández-Orallo, J. (2023). Predictable artificial intelligence. arXiv.](https://doi.org/10.48550/arXiv.2310.06167)
* [Zhu, Y. (Zhu Yu 朱禹), Chen, G. (Chen Guanze 陈关泽), Lu, Y. (Lu Yongrong 陆泳溶), & Fan, W. (Fan Wei 樊伟). (2023). Generative Artificial Intelligence Governance Action Framework: Content Analysis Based on AIGC Incident Report Texts. 图书情报知识 (Library and Information Knowledge), 40(4), 41-51.](https://doi.org/10.13366/j.dik.2023.04.041)
* [Žunić, L., Đukanović, G., & Popović, G. (2023). Rizici vještačke inteligencije: Analiza i implikacije. In 15th International Conference "Information Technology and Application" (ITeO 2023) (Vol. 15, pp. 29-40). Banja Luka, Bosnia and Herzegovina.](https://www.researchgate.net/publication/374170040_ANALIZA_JAVNE_UPRAVE_BIH_U_DOMENU_UPRAVLJANJA_I_ZAPOSLJAVANJA_IT_KADROVA_I_VEZA_SA_AGENDOM_2030_-_ANALYSIS_OF_BIH_PUBLIC_ADMINISTRATION_IN_THE_DOMAIN_OF_MANAGEMENT_I_RECRUITMENT_OF_IT_PERSONNEL_AND_CO)

#### Citations in briefs, theses, white papers, and mixed genres

* [Acion, L., Rajngewerc, M., Randall, G., & Etcheverry, L. (2023). Generative AI poses ethical challenges for open science. Nature Human Behaviour, 7(1800--1801).](https://doi.org/10.1038/s41562-023-01740-4)
* [Antunović, J. (2023). Sigurnost komunikacije u kritičnoj infrastrukturi [Undergraduate thesis, Sveučilište u Zagrebu, Fakultet prometnih znanosti]. Repozitorij Fakulteta prometnih znanosti.](https://urn.nsk.hr/urn:nbn:hr:119:293126)
* [Agnew, W. (2023). AI ethics and critique for robotics (Publication No. 30636400) [Doctoral dissertation, University of Washington]. ProQuest Dissertations & Theses Global.](https://www.proquest.com/dissertations-theses/ai-ethics-critique-robotics/docview/2863738398/se-2?accountid=11091)
* [Attard-Frost, B., & Widder, D. G. (2023). The Ethics of AI Value Chains. arXiv.](https://doi.org/10.48550/arXiv.2307.16787)
* [Bogusz, I. C., & Johnson, D. (2023). AI for the benefit of society: Progress with trust and transparency. Uppsala University, Disciplinary Domain of Humanities and Social Sciences, Faculty of Social Sciences, Department of Informatics and Media. Stockholm: Fores. ](https://fores.se/wp-content/uploads/2023/11/AI-for-the-benefit-of-society-fores-policy-2023.pdf)
* [D'Albergo, E., Fasciani, T., & Giovanelli, G. (2023, January 19-21). Social Powers and Governance of Artificial Intelligence in Urban Security Policies: Video Surveillance in Turin. Paper presented at Re-assembling the social. Re(i)stituting the social. 40 years of AIS, Naples, Italy.](https://hdl.handle.net/11573/1680495)
* [Desouza, K. C., & Dawson, G. S. (2023). Pathways to trusted progress with artificial intelligence. IBM Center for The Business of Government.](https://www.dmi-ida.org/download-pdf/pdf/Pathways%20to%20Trusted%20Progress%20with%20AI.pdf)
* [Duarte, A. B. F. (2023). Enhancing portuguese public services: Prototype of a mobile application with a digital assistant [Trabalho de projeto de mestrado, Escola Superior de Comunicação Social]. Instituto Politécnico de Lisboa, Escola Superior de Comunicação Social.](http://hdl.handle.net/10400.21/16926)
* [Giannini, A. (2023). Criminal behavior and accountability of artificial intelligence systems (Doctoral dissertation, University of Florence and Maastricht University).](https://hdl.handle.net/2158/1345544)
* [Hoffmann, M., & Frase, H. (2023). Adding structure to AI harm: An introduction to CSET's AI harm framework. Center for Security and Emerging Technology.](https://doi.org/10.51593/20230022)
* [Isbell, C., Littman, M. L., & Norvig, P. (2023). Viewpoint: Software Engineering of Machine Learning Systems. Communications of the ACM, 66(2), 35-37. ](https://doi.org/10.1145/3539783)
* [Knight, S., Heggart, K., Dickson-Deane, C., Ford, H., Hunter, J., Johns, A., Kitto, K., Cetindamar Kozanoglu, D., Maher, D., & Narayan, B. (2023). Submission in response to the House Standing Committee on Employment, Education and Training's inquiry into the use of generative artificial intelligence in the Australian education system. House Standing Committee on Employment, Education and Training's inquiry into the use of generative artificial intelligence in the Australian education system.](https://opus.lib.uts.edu.au/bitstream/10453/171583/2/Sub019%20-%20University%20of%20Technology%20Sydney%20%28UTS%29%2C%20Centre%20for%20Research%20on%20Education%20in%20a%20Digital%20Society%20%28CREDS%29.pdf)
* [Kutz, J., Göbels, V. P., Brajovic, D., Fresz, B., Renner, N., Omri, S., Neuhüttler, J., Huber, M., & Bienzeisler, B. (2023). KI-Zertifizierung und Absicherung im Kontext des EU AI Act: Herausforderungen und Bedürfnisse aus Sicht von Unternehmen. Fraunhofer IAO. ](https://doi.org/10.24406/publica-1875)
* [Longstaff, T. (2023). SEI Thoughts on AI T and E and Related Topics. (Technical Report). Carnegie-Mellon University, Pittsburgh, PA. Air Force Life Cycle Management Center, Hanscom AFB, MA. Retrieved from Accession Number: AD1199686.](https://apps.dtic.mil/sti/citations/trecms/AD1199686)
* [Massei, G. (2023). Algorithmic Trading: An Overview and Evaluation of Its Impact on Financial Markets [Master's thesis, Università Ca' Foscari Venezia].](http://hdl.handle.net/10579/23509)
* [Musser, M., Lohn, A., Dempsey, J. X., Spring, J., Kumar, R. S. S., Leong, B., Liaghati, C., Martinez, C., Grant, C. D., Rohrer, D., Frase, H., Bansemer, J., Rodriguez, M., Regan, M., Chowdhury, R., & Hermanek, S. (2023). Adversarial machine learning and cybersecurity: Risks, challenges, and legal implications. Center for Security and Emerging Technology.](https://doi.org/10.51593/2022CA003)
* [Narayanan, M., Seymour, A., Frase, H., & Elmgren, K. (2023). Repurposing the wheel: Lessons for AI standards (Workshop Report). Center for Security and Emerging Technology.](https://doi.org/10.51593/20230021)
* [NIST. Risk Management Playbook. 2023](https://pages.nist.gov/AIRMF/)
* [Sharma, A. (2023). Testing of machine learning algorithms and models (PhD dissertation). Universität Oldenburg.](https://oops.uni-oldenburg.de/id/eprint/5927)
* [Shneiderman, B. (2023). ACM TechBrief: Safer algorithmic systems (Issue 6). Association for Computing Machinery.](https://doi.org/10.1145/3582277)
* [Sivakumaran, A. (2023). Investigating consumer perception and speculative AI labels for creative AI usage in media (Master's thesis, KTH, School of Electrical Engineering and Computer Science).](https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-342955)
* [Toner, H., Ji, J., Bansemer, J., Lim, L., Painter, C., Corley, C., Whittlestone, J., Botvinick, M., Rodriguez, M., & Kumar, R. S. S. (2023). Skating to where the puck is going: Anticipating and managing risks from frontier AI systems. Center for Security and Emerging Technology.](https://doi.org/10.51593/2023CA004)
* [Wang, L. (2023). An urgency for inclusivity: Redesigning datasets for improved representation of LGBTQ+ identity terms in artificial intelligence (A.I.). HSS4 - The Modern Context: Queer Theory and Politics, Professor Barnick.](https://laniwang.com/LaniWangFinalPaper.CORRECTFORMATTING.pdf)
* [Zhang, J. (2023). Evaluating Artificial Neural Network Robustness for Safety-Critical Systems [Ph.D. dissertation, Technical University of Denmark]. Kgs. Lyngby: Technical University of Denmark.](https://orbit.dtu.dk/en/publications/evaluating-artificial-neural-network-robustness-for-safety-critic)

## 2022 

* [Macrae, Carl. "Learning from the failure of autonomous and intelligent systems: Accidents, safety, and sociotechnical sources of risk." Risk analysis 42.9 (2022): 1999-2025.](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/risa.13850)
* [Felländer, Anna, et al. "Achieving a Data-driven Risk Assessment Methodology for Ethical AI." Digital Society 1.2 (2022): 13.](https://link.springer.com/article/10.1007/s44206-022-00016-0)
* [Apruzzese, Giovanni, et al. "" Real Attackers Don't Compute Gradients": Bridging the Gap Between Adversarial ML Research and Practice." arXiv preprint arXiv:2212.14315 (2022).](https://arxiv.org/pdf/2212.14315)
* [Petersen, Eike, et al. "Responsible and regulatory conform machine learning for medicine: A survey of challenges and solutions." IEEE Access 10 (2022): 58375-58418.](https://ieeexplore.ieee.org/iel7/6287639/9668973/09783196.pdf)
* [Schuett, Jonas. "Three lines of defense against risks from AI." arXiv preprint arXiv:2212.08364 (2022).](https://arxiv.org/pdf/2212.08364)
* [Schiff, Daniel S. "Looking through a policy window with tinted glasses: Setting the agenda for US AI policy." Review of Policy Research.](https://onlinelibrary.wiley.com/doi/abs/10.1111/ropr.12535)
* [Neretin, Oleksii, and Vyacheslav Kharchenko. "Model for Describing Processes of AI Systems Vulnerabilities Collection and Analysis using Big Data Tools." 2022 12th International Conference on Dependable Systems, Services and Technologies (DESSERT). IEEE, 2022.](https://ieeexplore.ieee.org/abstract/document/10018811/)
* [Durso, Francis, et al. "Analyzing Failures in Artificial Intelligent Learning Systems (FAILS)." 2022 IEEE 29th Annual Software Technology Conference (STC). IEEE, 2022.](https://ieeexplore.ieee.org/abstract/document/9951011/)
* [Kassab, Mohamad, Joanna DeFranco, and Phillip Laplante. "Investigating Bugs in AI-Infused Systems: Analysis and Proposed Taxonomy." 2022 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW). IEEE, 2022.](https://ieeexplore.ieee.org/abstract/document/9985178/)
* [Braga, Juliao, et al. "Projeto para o desenvolvimento de um artigo sobre governança de algoritmos e dados." (2022).](https://osf.io/xcpsd/download)
* [Secchi, Carlo, and Alessandro Gili. "Digitalisation for sustainable infrastructure: the road ahead." Digitalisation for sustainable infrastructure (2022): 1-326.](https://www.torrossa.com/it/resources/an/5394879)
* [Groza, Adrian, et al. "Elaborarea cadrului strategic nat, ional în domeniul inteligent, ei artificiale."](https://www.adr.gov.ro/wp-content/uploads/2022/03/Analiza-reglementarilor-pentru-domeniul-inteligentei-artificiale.pdf)
* [Braga, Juliao, et al. "Project for the Development of a Paper on Algorithm and Data Governance." (2022).](https://osf.io/sr7kt/download) ([Original Portuguese](https://osf.io/xcpsd/download)).
* [NIST. Risk Management Playbook. 2022](https://pages.nist.gov/AIRMF/)
* [Shneiderman, Ben. Human-Centered AI. Oxford University Press, 2022.](https://www.amazon.com/Human-Centered-AI-Ben-Shneiderman/dp/0192845292)  
* [Schwartz, Reva, et al. "Towards a Standard for Identifying and Managing Bias in Artificial Intelligence." (2022).](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=934464)  
* [McGrath, Quintin et al. An Enterprise Risk Management Framework to Design Pro-Ethical AI Solutions." University of South Florida. (2022](https://www.usf.edu/business/documents/desrist/paper_65.pdf)).  
* [Nor, Ahmad Kamal Mohd, et al. "Abnormality Detection and Failure Prediction Using Explainable Bayesian Deep Learning: Methodology and Case Study of Real-World Gas Turbine Anomalies." (2022).](https://www.mdpi.com/2227-7390/10/4/554/pdf)  
* [Xie, Xuan, Kristian Kersting, and Daniel Neider. "Neuro-Symbolic Verification of Deep Neural Networks." arXiv preprint arXiv:2203.00938 (2022).](https://arxiv.org/pdf/2203.00938)  
* [Hundt, Andrew, et al. "Robots Enact Malignant Stereotypes." 2022 ACM Conference on Fairness, Accountability, and Transparency. 2022.](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533138)  
* [Tidjon, Lionel Nganyewou, and Foutse Khomh. "Threat Assessment in Machine Learning based Systems." arXiv preprint arXiv:2207.00091 (2022).](https://arxiv.org/pdf/2207.00091)  
* [Naja, Iman, et al. "Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information." IEEE Access 10 (2022): 74383-74411.](https://ieeexplore.ieee.org/iel7/6287639/9668973/09815594.pdf)  
* [Cinà, Antonio Emanuele, et al. "Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning." arXiv preprint arXiv:2205.01992 (2022).](https://arxiv.org/pdf/2205.01992)  
* [Schröder, Tim, and Michael Schulz. "Monitoring machine learning models: A categorization of challenges and methods." Data Science and Management (2022).](https://www.sciencedirect.com/science/article/pii/S2666764922000303)  
* [Corea, Francesco, et al. "A principle-based approach to AI: the case for European Union and Italy." AI & SOCIETY (2022): 1-15.](https://link.springer.com/article/10.1007/s00146-022-01453-8)  
* [Carmichael, Zachariah, and Walter J. Scheirer. "Unfooling Perturbation-Based Post Hoc Explainers." arXiv preprint arXiv:2205.14772 (2022).](https://arxiv.org/pdf/2205.14772)  
* [Wei, Mengyi, and Zhixuan Zhou. "AI Ethics Issues in Real World: Evidence from AI Incident Database." arXiv preprint arXiv:2206.07635 (2022).](https://arxiv.org/pdf/2206.07635)  
* [Petersen, Eike, et al. "Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Challenges and Solutions." IEEE Access (2022).](https://ieeexplore.ieee.org/iel7/6287639/9668973/09783196.pdf)  
* [Karunagaran, Surya, Ana Lucic, and Christine Custis. "XAI Toolsheet: Towards A Documentation Framework for XAI Tools."](https://a-lucic.github.io/talks/xai_pai_toolsheets.pdf)  
* [Paudel, Shreyasha, and Aatiz Ghimire. "AI Ethics Survey in Nepal."](https://www.naamii.org.np/wp-content/uploads/2021/11/AI-Ethics-Survey-Report.pdf)  
* [Ferguson, Ryan. "Transform Your Risk Processes Using Neural Networks."](https://www.firm.fm/wp-content/uploads/2022/05/Papers-Round-Table-AI-April-2022.pdf)  
* [Fujitsu Corporation. "AI Ethics Impact Assessment Casebook," 2022](https://www.fujitsu.com/global/documents/about/research/technology/aiethics/fujitsu-AIethics-case_en.pdf)  
* [Shneiderman, Ben and Du, Mengnan. "Human-Centered AI: Tools" 2022](https://hcai.site/tools/)  
* [Salih, Salih. "Understanding Machine Learning Interpretability." Medium. 2022](https://towardsdatascience.com/understanding-machine-learning-interpretability-168fd7562a1a)  
* [Garner, Carrie. "Creating Transformative and Trustworthy AI Systems Requires a Community Effort." Software Engineering Institute. 2022](https://insights.sei.cmu.edu/blog/creating-transformative-and-trustworthy-ai-systems-requires-a-community-effort/)  
* [Weissinger, Laurin, AI, Complexity, and Regulation (February 14, 2022). The Oxford Handbook of AI Governance](https://academic.oup.com/edited-volume/41989)

## 2021

* [Arnold, Z., Toner, H., CSET Policy. "AI Accidents: An Emerging Threat." (2021).](https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Accidents-An-Emerging-Threat.pdf)  
* [Aliman, Nadisha-Marie, Leon Kester, and Roman Yampolskiy. "Transdisciplinary AI Observatory—Retrospective Analyses and Future-Oriented Contradistinctions." Philosophies 6.1 (2021): 6.](https://www.mdpi.com/2409-9287/6/1/6/pdf)  
* [Falco, Gregory, and Leilani H. Gilpin. "A stress testing framework for autonomous system verification and validation (v&v)." 2021 IEEE International Conference on Autonomous Systems (ICAS). IEEE, 2021.](https://www.researchgate.net/profile/Gregory-Falco/publication/352930787_A_Stress_Testing_Framework_For_Autonomous_System_Verification_And_Validation_VV/links/60e911fcb8c0d5588ce64ec5/A-Stress-Testing-Framework-For-Autonomous-System-Verification-And-Validation-V-V.pdf)  
* [Petersen, Eike, et al. "Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Technical Challenges and Solutions." arXiv preprint arXiv:2107.09546 (2021).](https://arxiv.org/pdf/2107.09546)  
* [John-Mathews, Jean-Marie. AI ethics in practice, challenges and limitations. Diss. Université Paris-Saclay, 2021.](https://tel.archives-ouvertes.fr/tel-03527232/document)  
* [Macrae, Carl. "Learning from the Failure of Autonomous and Intelligent Systems: Accidents, Safety and Sociotechnical Sources of Risk." Safety and Sociotechnical Sources of Risk (June 4, 2021) (2021).](https://nottingham-repository.worktribe.com/OutputFile/7164920)  
* [Hong, Matthew K., et al. "Planning for Natural Language Failures with the AI Playbook." Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 2021.](https://www.adamfourney.com/papers/hong_chi2021.pdf)  
* [Ruohonen, Jukka. "A Review of Product Safety Regulations in the European Union." arXiv preprint arXiv:2102.03679 (2021).](https://arxiv.org/pdf/2102.03679)  
* [Kalin, Josh, David Noever, and Matthew Ciolino. "A Modified Drake Equation for Assessing Adversarial Risk to Machine Learning Models." arXiv preprint arXiv:2103.02718 (2021).](https://arxiv.org/pdf/2103.02718)  
* [Aliman, Nadisha Marie, and Leon Kester. "Epistemic defenses against scientific and empirical adversarial AI attacks." CEUR Workshop Proceedings. Vol. 2916. CEUR WS, 2021.](https://dspace.library.uu.nl/bitstream/handle/1874/413353/paper_1.pdf?sequence=1)  
* [John-Mathews, Jean-Marie. L’Éthique de l’Intelligence Artificielle en Pratique. Enjeux et Limites. Diss. université Paris-Saclay, 2021.](https://www.theses.fr/2021UPASI015.pdf)  
* [Smith, Catherine. "Automating intellectual freedom: Artificial intelligence, bias, and the information landscape." IFLA Journal (2021): 03400352211057145](https://journals.sagepub.com/doi/abs/10.1177/03400352211057145)


If you have a scholarly work that should be added here, please [contact](/contact) us.
