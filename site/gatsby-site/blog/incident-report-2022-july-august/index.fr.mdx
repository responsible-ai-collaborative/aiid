---
title: "Rapport d'incident d'IA pour juillet et août 2022"
metaTitle: "Rapport d'incident d'IA pour juillet et août 2022"
metaDescription: "Cette compilation d'incidents d'IA publiée en juillet et août 2022 met en évidence les incidents émergents et fournit un résumé des ajouts récents à la base de données."
date: '2022-09-12'
image: './images/aiid-july-august.png'
author: 'Janet Schwartz'
slug: '/blog/incident-report-2022-july-august'
aiTranslated: true
---


*La base de données sur les incidents d'intelligence artificielle (AIID) contient une multitude d'exemples historiques de dommages causés par l'IA, fournissant des informations sur le développement et le déploiement futurs de l'intelligence artificielle. Cette compilation d'incidents d'IA publiée en juillet et août 2022 met en évidence les incidents émergents et fournit un résumé des ajouts récents à la base de données.*

Des préjugés troublants et des préoccupations de censure aux blessures physiques, juillet et août ont vu une variété de gros titres d'incidents émergents dans l'IA. Les chatbots ont fait des déclarations [offensantes](/cite/278) et [accusatrices](/cite/313), tandis qu'un robot s'est notoirement [cassé le doigt d'un enfant](/cite/241) lors d'un match devant la caméra. Les logiciels de traduction et de rendu d'images ont fait des vagues avec un contenu offensant.

Une analyse plus approfondie de la base de données à partir du [flux](/rss.xml) de juillet et août révèle une plus grande variété d'incidents. Avec l'augmentation des déploiements et de la concurrence dans le domaine des véhicules autonomes, le nombre de signalements reçus des routes américaines a augmenté. Les grandes entreprises technologiques comme Google et les réseaux sociaux continuent de faire l'actualité avec des algorithmes qui tournent mal. À cela s'ajoutent une variété de nouveaux rapports sur le maintien de l'ordre et l'application de la loi dans le monde réel montrant une variété de préjugés et d'atteintes à la sécurité.

## Incidents émergents

*Incidents survenus en juillet/août.*

18/07/2022 : [Incident 285](/cite/285) : la fonction de traduction de l'appareil photo de Google Lens a fourni une mauvaise traduction offensante d'un titre de livre en coréen

21/07/2022 : [Incident 241](/cite/241) : Un robot d'échecs a cassé le doigt d'un enfant en Russie (5 rapports)

24/07/2022 : [Incident 271](/cite/271) : Tesla Model 3 Sedan sur pilote automatique a tué un motocycliste dans une collision arrière dans l'Utah

08/07/2022 : [Incident 278](/cite/278) : La démo de chatbot BlenderBot 3 de Meta a fait des commentaires antisémites offensants, reconnus par les développeurs comme des erreurs occasionnelles

17/08/2022 : [Incident 314](/cite/314) : Diffusion stable abusée par les utilisateurs de 4chan pour Deepfake Celebrity Porn

21/08/2022 : [Incident 303](/cite/303) : la détection automatique de la maltraitance des enfants de Google a signalé à tort la photo nue d'un parent de son enfant

25/08/2022 : [Incident 313](/cite/313) : BlenderBot 3 a cité un politicien néerlandais comme un terroriste

> Comment retrouver cette collection dans la base de données :

Allez dans « [Table](/apps/incidents/) [View](/apps/incidents/) » dans le menu de l'AIID et tapez 2022 pour les incidents survenus en juillet et 2022 pour les incidents survenus en août.

## Nouveaux incidents dans la base de données

*Un résumé de tous les incidents d'IA ajoutés à la base de données en juillet/août.*

Les incidents suivants sont nouveaux pour l'AIID, mais il s'agit de soumissions d'incidents survenus avant les deux derniers mois.

### AI blessure physique ou risque de blessure pour les humains

[Incident 241](/cite/241) : Un robot d'échecs a cassé le doigt d'un enfant en Russie

[Incident 242](/cite/242) : Une panne de robot de fabrication a causé la mort d'un ouvrier d'usine en Inde

[Incident 252](/cite/252) : Drones Taser télécommandés proposés par le fabricant de Taser comme moyen de défense contre les fusillades dans les écoles aux États-Unis

[Incident 261](/cite/261) : un robot déployé par un refuge pour animaux pour patrouiller les trottoirs devant son bureau, éloignant les sans-abri de San Francisco

[Incident 279](/cite/279) : L'algorithme "For You" de TikTok a exposé les jeunes utilisateurs au contenu Pro Disorder

[Incident 281](/cite/281) : Les algorithmes de YouTube n'ont pas réussi à supprimer le contenu non autorisé lié au suicide et à soi-même

[Incident 286](/cite/286) : Le système de recommandation de TikTok est allégué dans un procès pour avoir poussé et incité deux jeunes filles à participer au défi "Blackout", entraînant leur mort

[Incident 290](/cite/290) : Faux négatifs pour les fermetures de plages liées à la qualité de l'eau

### Problèmes liés aux véhicules autonomes

[Incident 253](/cite/253) : les voitures autonomes de Cruise auraient perdu la connexion à leur serveur, provoquant des blocages de trafic à San Francisco

[Incident 271](/cite/271) : La berline Tesla Model 3 sur pilote automatique a tué un motocycliste dans une collision arrière dans l'Utah

[Incident 289](/cite/289) : Un robot de livraison de vaisseau spatial a éraflé le pare-chocs de la voiture d'un résident au Texas, refusant prétendument de diffuser des images de l'accident

[Incident 291](/cite/291) : Tesla aurait induit les clients en erreur au sujet des capacités du pilote automatique et du FSD

[Incident 292](/cite/292) : les AV d'Apple auraient eu du mal à naviguer dans les rues de la Silicon Valley Test Drives

[Incident 293](/cite/293) : la voiture autonome de Cruise impliquée dans une collision multiple à une intersection de San Francisco

[Incident 294](/cite/294) : Le pilote automatique de Tesla aurait mal fonctionné lors d'une non-collision en Grèce

[Incident 297](/cite/297) : EasyMile Self Shuttle s'est arrêté de manière inattendue à mi-chemin, blessant un passager

[Incident 304](/cite/304) : Tesla sur FSD aurait conduit dans la mauvaise voie en Californie

[Incident 306](/cite/306) : Tesla sur le pilote automatique TACC s'est écrasé dans une camionnette sur l'autoroute européenne

[Incident 319](/cite/319) : Tesla sur pilote automatique s'écrase mortellement sur un camion de pompiers stationné dans l'Indiana

[Incident 320](/cite/320) : Tesla sur pilote automatique est entré en collision avec un camion de pompiers stationné sur l'autoroute de Californie

[Incident 321](/cite/321) : Tesla Model X sur pilote automatique s'est écrasé dans la barrière de l'autoroute de Californie, tuant le conducteur

[Incident 322](/cite/322) : Tesla Model 3 s'est écrasé dans une voiture de patrouille de police sur l'autoroute du Connecticut

[Incident 323](/cite/323) : Tesla sur pilote automatique s'est écrasé dans une voiture de police garée en Californie

### Pratiques policières utilisant l'IA

[Incident 244](/cite/244): Le lecteur de plaque d'immatriculation automatisé (ALPR) de la police du Colorado a fait correspondre la plaque d'une fourgonnette familiale à celle d'un véhicule volé, ce qui aurait entraîné une détention sous la menace d'une arme

[Incident 245](/cite/245) : Une erreur de lecture non vérifiée par un lecteur de plaque automatisé a conduit à l'arrêt de la circulation et à la retenue d'une personne innocente à Gunpoint en Californie

[Incident 246](/cite/246) : lecture erronée d'un lecteur de plaque d'immatriculation automatisé (ALPR) non vérifiée par la police, entraînant un arrêt de la circulation dans le Missouri

[Incident 248](/cite/248) : Une caméra de plaque d'immatriculation automatisée a informé la police d'une voiture de location précédemment volée qui a été restituée, entraînant la détention d'une personne innocente à Gunpoint en Californie

[Incident 255](/cite/255) : L'audio de détection de coups de feu capté par les algorithmes de ShotSpotter précédemment admis comme preuve de condamnation dans une affaire de meurtre à Chicago est maintenant rejeté en raison de rapports de manque de fiabilité

[Incident 256](/cite/256) : Une affaire d'arrestation pour conduite avec facultés affaiblies à Chicago alléguée dans un procès comme étant basée uniquement sur une alerte de ShotSpotter, citant des préoccupations de manque de fiabilité

[Incident 257](/cite/257) : les services de police auraient déployé des capteurs de détection de coups de feu de manière disproportionnée dans les quartiers noirs et bruns

[Incident 260](/cite/260) : Le logiciel d'immigration opaque du Département américain de la sécurité intérieure (DHS) critiqué par des groupes de défense pour s'appuyer prétendument sur des données médiocres et cibler les immigrants via des informations sensibles

[Incident 264](/cite/264) : L'application d'estimation de la vitesse des véhicules par IA dénoncée par les conducteurs britanniques comme une technologie de surveillance

[Incident 268](/cite/268) : La suppression permanente du contenu des médias sociaux via des outils automatisés aurait empêché les efforts d'enquête

[Incident 288](/cite/288) : La police du New Jersey a mal identifié un homme noir innocent par reconnaissance faciale, ce qui a entraîné une arrestation injustifiée et une violation présumée des droits civils

[Incident 295](/cite/295) : Tentative d'arrestation injustifiée pour vol dans un Apple Store en raison d'une erreur d'identification faciale du NYPD

[Incident 309](/cite/309) : Le procès FRT de la police britannique s'est mal déroulé au carnaval de Notting Hill

[Incident 310](/cite/310) : taux élevé de faux positifs dû à l'utilisation de la reconnaissance faciale de SWP lors de la finale de la Ligue des champions

### Biais de l'IA

[Incident 259](/cite/259) : YouTuber a construit, rendu public et publié un modèle formé sur des publications toxiques de 4chan en tant que farce

[Incident 262](/cite/262) : DALL Mini aurait renforcé ou exacerbé les préjugés sociétaux dans ses résultats en tant que stéréotypes sexistes et raciaux

[Incident 265](/cite/265) : Un chauffeur-livreur noir aurait été discriminé par Uber Eats pour des contrôles de vérification de photo faciale excessifs et renvoyé sur la base de faux résultats de reconnaissance faciale

[Incident 275](/cite/275) : L'algorithme de modération de contenu de Facebook a interdit à tort des utilisateurs pour une photo d'hommes autochtones enchaînés comme preuve historique de l'esclavage

[Incident 278](/cite/278) : La démo de chatbot BlenderBot 3 de Meta a fait des commentaires antisémites offensants

[Incident 280](/cite/280) : Le café rencontre l'algorithme de Bagel signalé par des utilisateurs leur montrant de manière disproportionnée des correspondances de leurs propres ethnies malgré la sélection de "Aucune préférence"

[Incident 300](/cite/300) : L'algorithme "For You" de TikTok aurait été abusé par une personnalité en ligne pour promouvoir la lutte contre la haine

[Incident 312](/cite/312) : l'IA de traduction d'accent d'une startup dénoncée comme renforçant les préjugés raciaux

### Problèmes de reconnaissance faciale

[Incident 254](/cite/254) : La fonction de regroupement des visages de Google aurait recueilli et analysé la structure faciale des utilisateurs sans consentement ni préavis, en violation directe de la loi sur la confidentialité des informations biométriques de l'Illinois

[Incident 258](/cite/258) : des détaillants australiens auraient capturé des empreintes faciales de leurs clients sans leur consentement, potentiellement en violation de la loi australienne sur la protection de la vie privée

[Incident 267](/cite/267) : L'algorithme de Clearview AI construit à partir de photos extraites de profils de médias sociaux sans consentement

[Incident 273](/cite/273) : FaceApp a détecté différents sexes pour des photos d'utilisateurs similaires avec une légère variation de l'épaisseur des sourcils

[Incident 276](/cite/276) : L'utilisation par le gouvernement local sud-coréen de l'analyse des images de vidéosurveillance via la reconnaissance faciale pour suivre les cas de COVID a soulevé des inquiétudes concernant la confidentialité, la conservation et les abus potentiels

[Incident 298](/cite/298) : L'application de reconnaissance faciale des étudiants a soulevé des préoccupations éthiques

[Incident 307](/cite/307) : l'iPhone Face ID n'a pas réussi à reconnaître les visages matinaux des utilisateurs

[Incident 315](/cite/315) : Un service de reconnaissance faciale utilisé pour cibler des actrices pornos russes

### Algorithmes nuisibles

[Incident 250](/cite/250) : Valeur de la maison défendue par le tribunal municipal néerlandais générée par l'algorithme noir

[Incident 251](/cite/251) : Amazon aurait modifié l'algorithme de recherche pour booster ses propres produits

[Incident 263](/cite/263) : Les systèmes de recommandation de contenu de YouTube impliqués dans la radicalisation politique extrême d'un utilisateur

[Incident 270](/cite/270) : Apple a modifié les algorithmes de classement de l'App Store, ce qui aurait entraîné la rétrogradation d'applications locales en Chine

[Incident 272](/cite/272) : Saisissez un algorithme de mise en relation modifié, offrant un traitement préférentiel aux conducteurs enregistrés auprès d'un service de location de voitures affilié

[Incident 274](/cite/274) : L'utilisation par les tribunaux de Virginie de l'évaluation algorithmique des risques non violents n'a pas abouti à une baisse des taux d'incarcération ou de condamnation et n'a ni augmenté ni diminué les préjugés raciaux historiques dans la détermination de la peine

[Incident 282](/cite/282) : L'algorithme de Facebook a confondu une publicité d'oignons avec du contenu suggestif à caractère sexuel

[Incident 296](/cite/296) : Le système de recommandation de Twitter a amplifié les bons tweets

[Incident 302](/cite/302) : Des étudiants auraient été accusés à tort de tricherie via le logiciel interne de la faculté de médecine

[Incident 305](/cite/305) : L'algorithme de recommandation de YouTube aurait fait la promotion de contenus de désinformation sur le climat

[Incident 316](/cite/316) : L'algorithme publicitaire de Facebook aurait manqué des publicités frauduleuses via de simples vérifications d'URL

[Incident 318](/cite/318) : Annonces d'équipement militaire recommandées par Facebook malgré la pause sur les annonces d'accessoires d'armes

### Problèmes de censure

[Incident 283](/cite/283) : L'outil de modération de contenu automatisé de Facebook a signalé par erreur une publication contenant des parties de la déclaration d'indépendance comme discours de haine

[Incident 284](/cite/284) : la suppression par Facebook de contenus contenant des œuvres d'art et leurs publicités présentant de la nudité via une modération automatisée et humaine est dénoncée comme de la censure

[Incident 303](/cite/303) : La détection automatique de la maltraitance des enfants de Google a signalé à tort la photo nue d'un parent de son enfant

[Incident 311](/cite/311) : YouTube Auto a interdit par erreur les femmes de la conférence Sex Tech

[Incident 317](/cite/317) : Un bogue dans l'anti-filtre de Facebook aurait bloqué les publications légitimes sur le COVID

### Problèmes de contrefaçon profonde

[Incident 299](/cite/299) : porno japonais dépixelisé par un homme utilisant Deepfake

[Incident 314](/cite/314) : Diffusion stable abusée par les utilisateurs de 4chan pour Deepfake Celebrity Porn

### Autres incidents

[Incident 243](/cite/243) : les bots auraient constitué environ la moitié des comptes Twitter dans les discussions entourant les problèmes liés au COVID

[Incident 249](/cite/249) : Le gouvernement a déployé des technologies de surveillance extrême pour surveiller et cibler les minorités musulmanes au Xinjiang

[Incident 266](/cite/266) : les partenaires IA créés par l'application Chatbot Replika sont abusés par ses utilisateurs
[Incident 277](/cite/277) : Voix créées via l'application de génération d'IA accessible au public 15.ai volées et revendues en tant que NFT sans accusé de réception

[Incident 285](/cite/285) : la fonction de traduction de l'appareil photo de Google Lens a fourni une erreur de traduction offensante d'un titre de livre en coréen

[Incident 287](/cite/287) : Le GPT d'OpenAI signalé par une société de soins de santé comme non viable dans les tâches médicales en raison de sa nature erratique et générale

[Incident 308](/cite/308) : Le robot Atlas est tombé de la scène lors d'une conférence

[Incident 313](/cite/313) : BlenderBot 3 a cité un politicien néerlandais comme un terroriste

> Comment retrouver cette collection dans la base de données :

Accédez à « [Table View](/apps/incidents/) » dans le menu de l'AIID et affichez les ID d'incident après #241.

## Soutenez nos efforts :

*Vous lisez encore ? Aidez-nous à changer le monde pour le mieux ! [Soumettre](/apps/soumettre) de nouveaux incidents à la base de données, [contribuer](https://github.com/responsible/aiid) à l'élaboration des fonctionnalités de la base de données et entamer une conversation avec nous sur [LinkedIn](https : //www.linkedin.com/company/responsible), [Facebook](https://www.facebook.com/IncidentsDB) ou [Twitter](https://twitter.com/IncidentsDB).*

