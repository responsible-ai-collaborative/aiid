---
title: "Defining an “AI Incident”"
metaTitle: "Defining an “AI Incident”"
metaDescription: "What are the reasons incident reports are or are not accepted into the AI Incident Database?"
slug: "/research/1-criteria"
---

The commercial air travel industry owes much of its increasing safety to systematically analyzing and archiving past accidents and incidents within a shared database. In aviation, an accident is a case where substantial damage or loss of life occurs. Incidents are cases where the risk of an accident substantially increases. For example, when a small fire is quickly extinguished in a cockpit it is an "incident" but if the fire burns crew members in the course of being extinguished it is an "accident." The FAA [aviation database](https://www.faa.gov/data_research/accident_incident/) indexes flight log data and subsequent expert investigations into comprehensive examinations of both technological and human factors. In part due to this continual self-examination, air travel is one of the safest forms of travel. Decades of iterative improvements to safety systems and training have decreased fatalities [81 fold](https://theblogbyjavier.com/2020/01/02/aviation-safety-evolution-2019-update/) since 1970 when normalized for passenger miles.

Where the aviation industry has clear definitions, computer scientists and philosophers have long debated foundational definitions of artificial intelligence. In the absence of clear lines differentiating algorithms, intelligence, and the harms they may directly or indirectly cause, this database adopts an adaptive criteria for ingesting "incidents" where reports are accepted or rejected on the basis of a growing rule set defined in the [Editor's Guide](/editors-guide).
