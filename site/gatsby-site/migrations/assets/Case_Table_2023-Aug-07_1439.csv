"id","Record_Number","Caption","Brief_Description","Area_of_Application_List","Area_of_Application_Text","Cause_of_Action_List","Cause_of_Action_Text","Issue_List","Issue_Text","Name_of_Algorithm_List","Name_of_Algorithm_Text","Class_Action_list","Class_Action","Organizations_involved","Jurisdiction_Filed","Date_Action_Filed","Published_Opinions","Published_Opinions_binary","Status_Disposition","Date_Added","Last_Update","Progress_Notes","Researcher","Summary_of_Significance","Summary_Facts_Activity_to_Date","Most_Recent_Activity","Most_Recent_Activity_Date","Keyword"
"9","9","Parsa et al v. Google L.L.C. et al","AI Foundation brought suit against Big Tech companies and notable political figures for ""developing code, algorithms, and ecosystems"" to polarize hate among political parties, supply biometric information and algorithms that have resulted in and perpetuate mass genocide, and making it difficult for the AI Foundation to spread awareness of the dangers of AI, dismissed for failure to show cause","'Crimes Against Humanity','Genocide','Nuremberg Laws','Social Media'","Crimes Against Humanity; Genocide; Nuremberg Laws; Social Media","'18 U.S.C. §1038 False Information and Hoaxes','22 U.S.C. §2551','CECPA','CFAA','FTC Act','Genocide Convention','Negligence'","Negligence; 18
U.S.C.  §1038 False Information and Hoaxes; FTC Act; Genocide Convention; CFAA; CECPA; 22 U.S.C.  §2551","'Facial Recognition','Hate Speech','Misinformation','Misuse of AI'","Misuse of AI; Hate Speech; Misinformation; Facial Recognition","","","","","AI Foundation; Google; Facebook","Federal: US Dist. Ct S.D. California","12/16/2019","Yes","-1","Inactive: Dismissed for failure to prosecute","2/2/2021","3/14/2021","RA Done","Jenna","While the court dismissed on procedural grounds so the judge did not consider the claims, the claims included misuse of artificial intelligence, endangering of the human race by building AI systems, treason, complicit in genocide, transfer of bio weapon to China in violation of Biological Weapons Anti Terrorism Act, social engineering, brain washing, breach of implied good faith and fair dealing, defamation, intentional infliction of emotional distress, cultural genocide with the use of AI, negligent creation of technology, fraud and deceit, negligent misrepresentation, breach of privacy, and preventing Parsa from saving the public from AI and bio tech.

The majority of the complaint focuses on providing the Chinese government and Chinese companies with AI, facial recognition, and biotechnology relating to the deaths of Uyghurs and democracy journalists and lawyers, as well as all minorities in China, as well as data on Americans to the Chinese. The negligence claim was negligence in algorithm fairness that allowed ""hate speech, misinformation and slander"" from Google for masking posts about the genocide in China. The complaint poses the question: can big tech companies be charged under Article 3 of the Genocide Convention?

The complaint requested relief of $4 Trillion, with the individual persons named to forfeit assets and spend the rest of their lives in jail, with companies submitting public apologies, explanatory corrective statements, and dedicating years of public service to the alleged victims.

These claims are popular among conspiracy theorists, and could be the first of many to bring these theories to a court, of which it would be interesting to see how many survive on substantive claims.","In response to current events, namely the role of algorithms in the 2016 election, facial recognition software in China, the genocide of Uighurs, the general dominance of Google, Facebook, and Big Tech, and the blocking of Parsa's book on the dangers of artificial intelligence, Parsa filed a complaint in December 2019, amending in February of 2020. Parsa is the President of The AI Organization, and filed this complaint on behalf of "" Christians, Cyrus A. Parsa, Falun Dafa Practitioners, John Does 1-Unlimited, Lawyers, Judges, Journalists killed in China, The AI Organization, Inc, Tibetans, Uyghurs, and Victims of Persecution, Rape, Torture, Concentration Camps, Sex, Human, and Organ Trafficking and Organ Harvesting in China, Hong Kong, America and Around the World.

The case was brought against Google L.L.C., Barack Hussein Obama, Joe Biden, Hunter Biden, Hillary Clinton, Eric Schmidt, Nancy Pelosi, John 0. Brennon, James Corney, Andrew
McCabe, James Clapper, Facebook, Inc, DeepMind Inc, Alphabet Inc, The World Bank, Neuralink Inc, 20 Tesla Inc, Larry Page, Sergey Brin, Sundar Pichai, Mark Zuckerberg, Elon Musk, Amazon, Jeff Bezos, Microsoft. Bill Gates, CISON PR NewsWire. CNN Cable News Network. Anderson Cooper. Don Lemon. MSNBC, Rachel Maddow. James Clapper, Washington Post. New York Times. Time Magazine. Massachusetts Institute of Technology, Harvard. Adam Schiff, Wyss Institute, Daroer, Qualcomm. George Soros, Soros Fund Management. Open Societv 25 Foundations. University of Vermont. Joshua Bongard and Sam Kriegman. Rockefeller Foundation. Huawei, Boston Dynamics. Hanson Robotics. Didi Chuxing, Megvii Face++. Alibaba, Sensetime, !Carbon X, Festa, Chinese Communist Party, & John Doe's 1-Unlimited Defendants.

The court ordered on May 5, 2020 for plaintiffs to show cause by May 19 under FRCP rule 4(m) as no other activity had occurred since the amended complaint on February 26. When no such activity occurred, the lawsuit was dismissed without prejudice for failure to prosecute without considering any claims.","Dismissed without prejudice for failure to prosecute","6/6/2020","Parsa et al v. Google L.L.C. et al AI Foundation brought suit against Big Tech companies and notable political figures for ""developing code, algorithms, and ecosystems"" to polarize hate among political parties, supply biometric information and algorithms that have resulted in and perpetuate mass genocide, and making it difficult for the AI Foundation to spread awareness of the dangers of AI, dismissed for failure to show cause While the court dismissed on procedural grounds so the judge did not consider the claims, the claims included misuse of artificial intelligence, endangering of the human race by building AI systems, treason, complicit in genocide, transfer of bio weapon to China in violation of Biological Weapons Anti Terrorism Act, social engineering, brain washing, breach of implied good faith and fair dealing, defamation, intentional infliction of emotional distress, cultural genocide with the use of AI, negligent creation of technology, fraud and deceit, negligent misrepresentation, breach of privacy, and preventing Parsa from saving the public from AI and bio tech.

The majority of the complaint focuses on providing the Chinese government and Chinese companies with AI, facial recognition, and biotechnology relating to the deaths of Uyghurs and democracy journalists and lawyers, as well as all minorities in China, as well as data on Americans to the Chinese. The negligence claim was negligence in algorithm fairness that allowed ""hate speech, misinformation and slander"" from Google for masking posts about the genocide in China. The complaint poses the question: can big tech companies be charged under Article 3 of the Genocide Convention?

The complaint requested relief of $4 Trillion, with the individual persons named to forfeit assets and spend the rest of their lives in jail, with companies submitting public apologies, explanatory corrective statements, and dedicating years of public service to the alleged victims.

These claims are popular among conspiracy theorists, and could be the first of many to bring these theories to a court, of which it would be interesting to see how many survive on substantive claims. In response to current events, namely the role of algorithms in the 2016 election, facial recognition software in China, the genocide of Uighurs, the general dominance of Google, Facebook, and Big Tech, and the blocking of Parsa's book on the dangers of artificial intelligence, Parsa filed a complaint in December 2019, amending in February of 2020. Parsa is the President of The AI Organization, and filed this complaint on behalf of "" Christians, Cyrus A. Parsa, Falun Dafa Practitioners, John Does 1-Unlimited, Lawyers, Judges, Journalists killed in China, The AI Organization, Inc, Tibetans, Uyghurs, and Victims of Persecution, Rape, Torture, Concentration Camps, Sex, Human, and Organ Trafficking and Organ Harvesting in China, Hong Kong, America and Around the World.

The case was brought against Google L.L.C., Barack Hussein Obama, Joe Biden, Hunter Biden, Hillary Clinton, Eric Schmidt, Nancy Pelosi, John 0. Brennon, James Corney, Andrew
McCabe, James Clapper, Facebook, Inc, DeepMind Inc, Alphabet Inc, The World Bank, Neuralink Inc, 20 Tesla Inc, Larry Page, Sergey Brin, Sundar Pichai, Mark Zuckerberg, Elon Musk, Amazon, Jeff Bezos, Microsoft. Bill Gates, CISON PR NewsWire. CNN Cable News Network. Anderson Cooper. Don Lemon. MSNBC, Rachel Maddow. James Clapper, Washington Post. New York Times. Time Magazine. Massachusetts Institute of Technology, Harvard. Adam Schiff, Wyss Institute, Daroer, Qualcomm. George Soros, Soros Fund Management. Open Societv 25 Foundations. University of Vermont. Joshua Bongard and Sam Kriegman. Rockefeller Foundation. Huawei, Boston Dynamics. Hanson Robotics. Didi Chuxing, Megvii Face++. Alibaba, Sensetime, !Carbon X, Festa, Chinese Communist Party, & John Doe's 1-Unlimited Defendants.

The court ordered on May 5, 2020 for plaintiffs to show cause by May 19 under FRCP rule 4(m) as no other activity had occurred since the amended complaint on February 26. When no such activity occurred, the lawsuit was dismissed without prejudice for failure to prosecute without considering any claims. AI Foundation; Google; Facebook  Crimes Against Humanity; Genocide; Nuremberg Laws; Social Media Negligence; 18
U.S.C.  §1038 False Information and Hoaxes; FTC Act; Genocide Convention; CFAA; CECPA; 22 U.S.C.  §2551 Misuse of AI; Hate Speech; Misinformation; Facial Recognition"
"25","25","Umeda v. Tesla, Inc.","Court dismissed suit by estate of Japanese pedestrian killed by Tesla Autopilot operated by Japanese driver because Japan is an adequate alternative, denying plaintiff's motions for judicial notice of articles about Tesla personnel changes and Tesla's forecasts but granting Plaintiff's motion to include congrsesional hearings about autopilot and an article about the specific accident","'Autonomous Vehicles'","Autonomous Vehicles","'Design Defects','Failure to Warn','Loss of Consortium','Negligence','Survival Action','Wrongful Death'","Design Defects; Failure to Warn; Negligence; Wrongful Death; Loss of Consortium; Survival Action","'Product Liability','Underperformance'","Product Liability; Underperformance","'Autopilot'","Autopilot","","No","","Federal: US Dist. Ct. N.D. California","4/28/2020","Yes","-1","Inactive: Dismissed for Forum Non Conveniens","2/12/2021","2/14/2021","","","","","Motion Denied to Reconsider Dismissal for Forum Non Conveniens","1/15/2021","Umeda v. Tesla, Inc. Court dismissed suit by estate of Japanese pedestrian killed by Tesla Autopilot operated by Japanese driver because Japan is an adequate alternative, denying plaintiff's motions for judicial notice of articles about Tesla personnel changes and Tesla's forecasts but granting Plaintiff's motion to include congrsesional hearings about autopilot and an article about the specific accident    Autopilot Autonomous Vehicles Design Defects; Failure to Warn; Negligence; Wrongful Death; Loss of Consortium; Survival Action Product Liability; Underperformance"
"41","41","State of Washington v. Flanigan et al","Defendants Flanigan et al sought discovery from Washington State Patrol for access to the Draeger machine for dynamic testing comparing the software to what the machine actually does as opposed to time-consuming static testing, the court granted discovery of the materials reasonably in possession or in control of by the State Snohomish County Prosecuting Office: two instruments and the software code under a protective order","'Breathalyzer'","Breathalyzer;","'Discovery','Evidence','Protective Order'","Evidence; Discovery; Protective Order","'Admissibility','Transparency/Trade Secrecy'","Admissability; Trade Secrecy / Transparency","'Draeger Alcotest'","Draeger Alcotest","","No","","State: Washington Snohomish County Court, South County","2015","Yes","-1","","2/20/2021","2/27/2021","","","","Need information about the four cases that were consolidated into this case in 2015

In November 2015, the court granted Flanigan et al's discovery for access to two of the Snohomish County's Draeger machines for dynamic testing, as it was material and reasonable evidence.

The Court on December 16th granted Draeger's Motion to Quash Subpoenas as Draeger was categorized as witness and there was no evidence that Flanigan filed appropriate actions for a witness in Texas.

The court on December 17th granted a motion to modify the subpoena ad granted a protective order for the Washington State Patrol: the modified order required WSP to provide the two Draeger Alcotest to defendant experts, and under a protective order provide the software source code to defendant experts","","","State of Washington v. Flanigan et al Defendants Flanigan et al sought discovery from Washington State Patrol for access to the Draeger machine for dynamic testing comparing the software to what the machine actually does as opposed to time-consuming static testing, the court granted discovery of the materials reasonably in possession or in control of by the State Snohomish County Prosecuting Office: two instruments and the software code under a protective order  Need information about the four cases that were consolidated into this case in 2015

In November 2015, the court granted Flanigan et al's discovery for access to two of the Snohomish County's Draeger machines for dynamic testing, as it was material and reasonable evidence.

The Court on December 16th granted Draeger's Motion to Quash Subpoenas as Draeger was categorized as witness and there was no evidence that Flanigan filed appropriate actions for a witness in Texas.

The court on December 17th granted a motion to modify the subpoena ad granted a protective order for the Washington State Patrol: the modified order required WSP to provide the two Draeger Alcotest to defendant experts, and under a protective order provide the software source code to defendant experts  Draeger Alcotest Breathalyzer; Evidence; Discovery; Protective Order Admissability; Trade Secrecy / Transparency"
"58","58","Aerotek, Inc. v. Boyd","Texas Supreme Court rules that e-signatures on new hire paperwork can compel arbitration for a company that was sued for racial discrimination","'Employment','Hiring'","Employment; Hiring","'Contracts','Arbitration'","","'Use of Race'","","","","","","","State: Texas Circuit Court","2018","Yes","-1","Active: On Remand","10/14/2021","11/6/2021","RA Done; Check for New Activity","Jenna","This case concerns electronic hiring application, requiring signatures on multiple documents including a mutual arbitration agreement before continuing with the hiring paperwork. Each applicant had a unique username and password that is tied to each document. The plaintiffs all claimed that they had never seen the arbitration agreement when Aerotek moved to compel arbitration at trial. However, Boyd's unique username and password was date and timestamped as reviewing and accepting the arbitration policy. The Texas Supreme Court found this use of electronic onboarding requiring arbitration polices more common, especially those companies with Texas injury benefit plans.","The plaintiffs were four contractors hired by Aerotek to be placed with client companies. The plaintiffs sued corporation Aerotek for racial discrimination and retaliation after being fired. Aerotek filed a motion to compel arbitration that the plaintiffs allegedly agreed to during electronic onboarding. The trial court ruled that Aerotek had failed to conclusively establish validity of the arbitration agreement. At trial, the Federal Arbitration Act governed, and although Aerotek provided evidence of Boyd's unique ID being used and the date stamp, because Boyd said he has never seen the agreement before, the court followed an El Paso Case that the ""facts"" issue could be resolved by the judge in Boyd's favor. The dissent disagreed, instead arguing that the standard of review should be whether “Aerotek presented evidence that a reasonable fact finder could not disregard establishing appellees’ electronically signed the arbitration agreement at issue despite appellees’ statements that they had not agreed to arbitrate.” The Dallas Court of Appeals on August 27, 2019 affirmed the trial court's finding for the plaintiffs. Aerotek appealed to the Texas Supreme Court, who granted review on February 25, 2020. The court ultimately reversed and remanded, finding that the trial court erred in denying the motion to compel arbitration because there is no way the four could have completed onboarding without signing the agreement and that there was a valid contract. This inability to avoid the arbitration agreement is highlighted by the option to complete the application ni person if the person does not have access to the technology: three of the four completed it online and one completed the application in the office with an administrative assistant, and all four signed the arbitration caluse. The dissent from the Texas Supreme Court","Billing Issued, Reverse and Remanded","7/1/2021","Aerotek, Inc. v. Boyd Texas Supreme Court rules that e-signatures on new hire paperwork can compel arbitration for a company that was sued for racial discrimination This case concerns electronic hiring application, requiring signatures on multiple documents including a mutual arbitration agreement before continuing with the hiring paperwork. Each applicant had a unique username and password that is tied to each document. The plaintiffs all claimed that they had never seen the arbitration agreement when Aerotek moved to compel arbitration at trial. However, Boyd's unique username and password was date and timestamped as reviewing and accepting the arbitration policy. The Texas Supreme Court found this use of electronic onboarding requiring arbitration polices more common, especially those companies with Texas injury benefit plans. The plaintiffs were four contractors hired by Aerotek to be placed with client companies. The plaintiffs sued corporation Aerotek for racial discrimination and retaliation after being fired. Aerotek filed a motion to compel arbitration that the plaintiffs allegedly agreed to during electronic onboarding. The trial court ruled that Aerotek had failed to conclusively establish validity of the arbitration agreement. At trial, the Federal Arbitration Act governed, and although Aerotek provided evidence of Boyd's unique ID being used and the date stamp, because Boyd said he has never seen the agreement before, the court followed an El Paso Case that the ""facts"" issue could be resolved by the judge in Boyd's favor. The dissent disagreed, instead arguing that the standard of review should be whether “Aerotek presented evidence that a reasonable fact finder could not disregard establishing appellees’ electronically signed the arbitration agreement at issue despite appellees’ statements that they had not agreed to arbitrate.” The Dallas Court of Appeals on August 27, 2019 affirmed the trial court's finding for the plaintiffs. Aerotek appealed to the Texas Supreme Court, who granted review on February 25, 2020. The court ultimately reversed and remanded, finding that the trial court erred in denying the motion to compel arbitration because there is no way the four could have completed onboarding without signing the agreement and that there was a valid contract. This inability to avoid the arbitration agreement is highlighted by the option to complete the application ni person if the person does not have access to the technology: three of the four completed it online and one completed the application in the office with an administrative assistant, and all four signed the arbitration caluse. The dissent from the Texas Supreme Court   Employment; Hiring  "
"77","77","Zhang v. Baidu.Com, Inc.,","A group of New York residents who advocate for increased democracy in China sued Baidu for blocking their materials in the United States. The court found that allowing plaintiffs to sue Baidu for its editorial judgements would violate the First Amendment.","'Civil Rights'","Civil Rights","'Civil Rights'","Civil Rights","'Accountability'","Accountability","","","","","","S.D.New York","05.18.2011","","0","Appeal Withdrawn","4/11/2022","4/11/2022","","","It is one of the first courts to decide whether search engines is protected by the First Amendment. It found that 
allowing plaintiffs to sue Baidu for what are in essence editorial judgments about which political ideas to promote would run afoul of the First Amendment.","A group of New York residents who advocate for increased democracy in China sued Baidu, the largest internet search engine in China, for blocking their pro-democracy materials in the United States where Baidu also operates.","","8/1/2014","Zhang v. Baidu.Com, Inc., A group of New York residents who advocate for increased democracy in China sued Baidu for blocking their materials in the United States. The court found that allowing plaintiffs to sue Baidu for its editorial judgements would violate the First Amendment. It is one of the first courts to decide whether search engines is protected by the First Amendment. It found that 
allowing plaintiffs to sue Baidu for what are in essence editorial judgments about which political ideas to promote would run afoul of the First Amendment. A group of New York residents who advocate for increased democracy in China sued Baidu, the largest internet search engine in China, for blocking their pro-democracy materials in the United States where Baidu also operates.   Civil Rights Civil Rights Accountability"
"93","93","P.M. v. OpenAI LP","Anonymous plaintiffs sue OpenAI and Microsoft alleging theft of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in a variety of privacy and property-based claims.","'Generative AI'","Generative AI","'Conversion','Failure to Warn','Illinois Biometric Information Privacy Act','Intrusion Upon Seclusion','Larceny / Receipt of Stolen Property','New York General Business Law','Negligence','Right to Privacy','Unjust Enrichment','Unfair Competition'","Conversion, Failure to Warn, Illinois Biometric Information Privacy Act, Intrusion Upon Seclusion, Larceny / Receipt of Stolen Property, New York General Business Law, Negligence, Right to Privacy, Unjust Enrichment, Unfair Competition","'Privacy'","Privacy","'ChatGPT'","ChatGPT","'Yes'","","OpenAI LP, Microsoft Corporation","Federal: US Dist. Ct. N.D. Ca.","06/28/2023","","0","Active","7/20/2023","7/27/2023","","Bob","","Sixteen anonymous plaintiffs, both adults and minors sue OpenAI and Microsoft alleging misappropriation of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in violations of the Electronic Communications Privacy Act, the Computer Fraud and Abuse Act, California privacy and unfair competition laws, Illinois's Biometric Information Privacy Act, negligence, invasion of privacy, intrusion upon seclusion, larceny, conversion, unjust enrichment, failure to work, and the New York General Business Law.  The complaint seems to be concerned both with collection of data to train GPT models, and ongoing collection of data through interactions with ChatGPT, both directly and through other apps and websites into which it is integrated.","Assignment of case to Judge Trina L. Thompson","7/17/2023","P.M. v. OpenAI LP Anonymous plaintiffs sue OpenAI and Microsoft alleging theft of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in a variety of privacy and property-based claims.  Sixteen anonymous plaintiffs, both adults and minors sue OpenAI and Microsoft alleging misappropriation of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in violations of the Electronic Communications Privacy Act, the Computer Fraud and Abuse Act, California privacy and unfair competition laws, Illinois's Biometric Information Privacy Act, negligence, invasion of privacy, intrusion upon seclusion, larceny, conversion, unjust enrichment, failure to work, and the New York General Business Law.  The complaint seems to be concerned both with collection of data to train GPT models, and ongoing collection of data through interactions with ChatGPT, both directly and through other apps and websites into which it is integrated. OpenAI LP, Microsoft Corporation ChatGPT Generative AI Conversion, Failure to Warn, Illinois Biometric Information Privacy Act, Intrusion Upon Seclusion, Larceny / Receipt of Stolen Property, New York General Business Law, Negligence, Right to Privacy, Unjust Enrichment, Unfair Competition Privacy"
"6","6","In the Matter of [Juvenile Client]","Superior Court granted defendant's motion not to consider SAVRY (Structured Assessment of Violence and Risk in Youth) to calculate sentencing for felony assualt and possession of prohibted weapon because of a lack of research proving efficacy and racially targetted risk factors, declining to set precedent for future cases","'Criminal Justice','Sentencing'","Criminal Justice; Sentencing","'Federal Rule of Evidence 702'","Federal Rule of Evidence 702","'Insufficient Research','Role of Expert Testimony','Socioeconomics Bias','Use of Race','Unreliability/Miscalculationns'","Use of Race; Unreliablility/Misclaculations; Insufficient Research; Socioeconomic Bias; Role of Expert Testimony","'SAVRY'","SAVRY","","No","","State: Dist. of Columbia","9/20/2017","Redacted","0","Inactive: Judgement for D","2/1/2021","3/19/2021","RA Done","Jenna","While the court ultimately decided against using the Violence Risk Assessment algorithm in this juvenile's case, the court declined to rule against the algorithm's use for all future cases, and thus did not result in the discontinuation of the algorithm for future cases. 

Juvenile's team took issue with SAVRY that it was not valid because 1. could not be tested for falsity, noting there was no error rate and therefore no false positive rate for SAVRY, 2. peer review journals did not support the validity of SAVRY, 3. the lack of known error rate and bias leads to racial disparities and misuse of SAVRY when used against lower income children of color, 4. evaluators can rely on empirical data rather than SAVRY, 5. SAVRY is being used for different purpose than it was originally designed, as children are almost always found to be high risk, no matter the factors. 
Juvenile's team also argued that SAVRY was inadmissible evidence because 1. using as a general violence predictor was inconsistent with its intended use for continuous monitoring and prevention, 2. in this case the SAVRY model did not follow best practices as it only used data from an interview with the juvenile's father, his probation officer, and a secret source in Metro PD, 3. it miscalculated and elevated certain factors, and 4. it resulted in subjective and unsubstantiated judgements","On September 20, 2017, the Juvenile was charged with one count each of Assault with Intent to Commit Murder while Armed, Possession of a Prohibited Weapon (knife), Assault with Intent to Kill while Armed, Aggravated Assault while Armed, Felony Assault, and Carrying a Dangerous Weapon (knife). 

On October 30th, the Juvenile entered into a Plea Agreement to One Count Felony Assault, One Count Possession of Prohibited Weapon.

Juvenile's team filed a request for the exclusion of results and testimony related to VRA Violence Risk Assessment based on Dabuert v. Merrel Dow and FRE 702 for being generally unreliable and for racial disparities in the factors. The Court conducted an evidentiary hearing on the Juvenile's motion and statements on March 13, 2018. 

The court ultimately granted in part Juvenile's motion to exclude the Violence Risk Assessment conclusions and recommendations but denied in part to consider the underlying information contained in the Assessment in determining an appropriate disposition in this case.","Exclusion of VRA in sentencing","3/15/2018","In the Matter of [Juvenile Client] Superior Court granted defendant's motion not to consider SAVRY (Structured Assessment of Violence and Risk in Youth) to calculate sentencing for felony assualt and possession of prohibted weapon because of a lack of research proving efficacy and racially targetted risk factors, declining to set precedent for future cases While the court ultimately decided against using the Violence Risk Assessment algorithm in this juvenile's case, the court declined to rule against the algorithm's use for all future cases, and thus did not result in the discontinuation of the algorithm for future cases. 

Juvenile's team took issue with SAVRY that it was not valid because 1. could not be tested for falsity, noting there was no error rate and therefore no false positive rate for SAVRY, 2. peer review journals did not support the validity of SAVRY, 3. the lack of known error rate and bias leads to racial disparities and misuse of SAVRY when used against lower income children of color, 4. evaluators can rely on empirical data rather than SAVRY, 5. SAVRY is being used for different purpose than it was originally designed, as children are almost always found to be high risk, no matter the factors. 
Juvenile's team also argued that SAVRY was inadmissible evidence because 1. using as a general violence predictor was inconsistent with its intended use for continuous monitoring and prevention, 2. in this case the SAVRY model did not follow best practices as it only used data from an interview with the juvenile's father, his probation officer, and a secret source in Metro PD, 3. it miscalculated and elevated certain factors, and 4. it resulted in subjective and unsubstantiated judgements On September 20, 2017, the Juvenile was charged with one count each of Assault with Intent to Commit Murder while Armed, Possession of a Prohibited Weapon (knife), Assault with Intent to Kill while Armed, Aggravated Assault while Armed, Felony Assault, and Carrying a Dangerous Weapon (knife). 

On October 30th, the Juvenile entered into a Plea Agreement to One Count Felony Assault, One Count Possession of Prohibited Weapon.

Juvenile's team filed a request for the exclusion of results and testimony related to VRA Violence Risk Assessment based on Dabuert v. Merrel Dow and FRE 702 for being generally unreliable and for racial disparities in the factors. The Court conducted an evidentiary hearing on the Juvenile's motion and statements on March 13, 2018. 

The court ultimately granted in part Juvenile's motion to exclude the Violence Risk Assessment conclusions and recommendations but denied in part to consider the underlying information contained in the Assessment in determining an appropriate disposition in this case.  SAVRY Criminal Justice; Sentencing Federal Rule of Evidence 702 Use of Race; Unreliablility/Misclaculations; Insufficient Research; Socioeconomic Bias; Role of Expert Testimony"
"22","22","National Fair Housing Alliance v. Facebook","Settlement between Facebook and the National Housing Groups to restructure Facebook's previous advertising settings that allowed advertisers to exclude targeted audiences based on race, gender, or families","'Advertising','Credit','Housing'","Advertising; Housing; Credit","'Fair Housing Act'","Fair Housing Act","'Advertising DIscrimination','Socioeconomics Bias','Use of Race','User of Gender'","Advertising Discrimination; Use of Race; Use of Gender; Socioeconomic Bias","","","","","National Fair Housing Alliance","Federal:  US Dist Ct. S.D. New York","3/27/2018","No","0","Inactive: Settled","2/8/2021","3/26/2021","RA Done","Jenna","Plaintiffs asserted that Facebook's advertising algorithm ""can ensure exclusion and deny access to housing. Facebook’s ability to target groups and promote discrimination so precisely will surely only improve as the company continues to refine its technology."" 

The Amended Complaint further asserts that ""These algorithms automatically designate each Facebook user as falling into the various categories it has determined fit that user’s demographics, interests, and behaviors."" The complaint and amended complaint do not provide an in-depth discussion into the predictive algorithms or use of machine learning, just the discriminatory effects.

The terms of the settlement agreement delineated trainings and verification of implementation of the trainings and programmatic relief for the employment advertisements on Facebook. The training is civil rights training but would apply to Facebook's machine learning team and ranking feature engineers, as well as Facebook's ads teams. To verify the implementation, Facebook will meet with the plaintiffs every six months where they will consider in good faith any recommendations from plaintiffs and share the status of their updates, as well as allow plaintiffs to test ads. 

There have been no news reports on these biannual meetings, or how long they will continue.","The National Fair Housing Alliance filed its complaint against Facebook on March 17, 2018, which alleged discriminatory advertising practices with its use of ""exclude"" and ""include"" characteristics, boosting to certain characteristics, and Facebook's Ad Manager that facilitates this exclusion. The complaint was brought on by Pro Publica's report of discriminatory practices and filed after NFHA conducted its own investigation.

The parties conferenced on May 8, 2018, deciding the defendants must file a motion to transfer or dismiss by June 4 with no pre-motion conference necessary. On June 4, Facebook filed a motion to transfer case or alternatively to dismiss. 

Plaintiffs filed amended complaint on June 25, which noticeably included 15 mentions to Facebook's algorithm, whereas the initial complaint included a mere 3. The revised language focused on ""algorithmically ranked series of stories and advertisements"" on Facebook User News Feeds.

The parties conferenced on June 29, and on July 2, the Judge denied without prejudice the motion to transfer case and denied motion to dismiss as moot. On July 30, Facebook filed a new motion to transfer case or dismiss. The judge granted plaintiffs an extension of time to respond to the motion to transfer on August 31.

On November 26, parties were notified of oral arguments to be held on December 13. The parties submitted a joint motion to continue for February 11 due to the holiday season on December 27. 

Plaintiffs filed the proposed order February 6 that stipulated it was dismissed without costs and prejudice. However, on March 29 the case was reopened and dismissed with prejudice pursuant to the terms of the settlement Exhibit 1. The settlement agreement provided terms for programmatic relief, training, dismissal, monetary payment, and verification of implementation.","Dismissed per the terms of the settlement agreement","3/29/2019","National Fair Housing Alliance v. Facebook Settlement between Facebook and the National Housing Groups to restructure Facebook's previous advertising settings that allowed advertisers to exclude targeted audiences based on race, gender, or families Plaintiffs asserted that Facebook's advertising algorithm ""can ensure exclusion and deny access to housing. Facebook’s ability to target groups and promote discrimination so precisely will surely only improve as the company continues to refine its technology."" 

The Amended Complaint further asserts that ""These algorithms automatically designate each Facebook user as falling into the various categories it has determined fit that user’s demographics, interests, and behaviors."" The complaint and amended complaint do not provide an in-depth discussion into the predictive algorithms or use of machine learning, just the discriminatory effects.

The terms of the settlement agreement delineated trainings and verification of implementation of the trainings and programmatic relief for the employment advertisements on Facebook. The training is civil rights training but would apply to Facebook's machine learning team and ranking feature engineers, as well as Facebook's ads teams. To verify the implementation, Facebook will meet with the plaintiffs every six months where they will consider in good faith any recommendations from plaintiffs and share the status of their updates, as well as allow plaintiffs to test ads. 

There have been no news reports on these biannual meetings, or how long they will continue. The National Fair Housing Alliance filed its complaint against Facebook on March 17, 2018, which alleged discriminatory advertising practices with its use of ""exclude"" and ""include"" characteristics, boosting to certain characteristics, and Facebook's Ad Manager that facilitates this exclusion. The complaint was brought on by Pro Publica's report of discriminatory practices and filed after NFHA conducted its own investigation.

The parties conferenced on May 8, 2018, deciding the defendants must file a motion to transfer or dismiss by June 4 with no pre-motion conference necessary. On June 4, Facebook filed a motion to transfer case or alternatively to dismiss. 

Plaintiffs filed amended complaint on June 25, which noticeably included 15 mentions to Facebook's algorithm, whereas the initial complaint included a mere 3. The revised language focused on ""algorithmically ranked series of stories and advertisements"" on Facebook User News Feeds.

The parties conferenced on June 29, and on July 2, the Judge denied without prejudice the motion to transfer case and denied motion to dismiss as moot. On July 30, Facebook filed a new motion to transfer case or dismiss. The judge granted plaintiffs an extension of time to respond to the motion to transfer on August 31.

On November 26, parties were notified of oral arguments to be held on December 13. The parties submitted a joint motion to continue for February 11 due to the holiday season on December 27. 

Plaintiffs filed the proposed order February 6 that stipulated it was dismissed without costs and prejudice. However, on March 29 the case was reopened and dismissed with prejudice pursuant to the terms of the settlement Exhibit 1. The settlement agreement provided terms for programmatic relief, training, dismissal, monetary payment, and verification of implementation. National Fair Housing Alliance  Advertising; Housing; Credit Fair Housing Act Advertising Discrimination; Use of Race; Use of Gender; Socioeconomic Bias"
"38","38","Hall v. Clearview AI, Inc.","Conversion, violates BIPA, Ill. UDAP; seeking injunctive relief (including deletion of data and compliance monitoring), damages, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA','UDAP'","BIPA; UDAP","'Facial Recognition','Privacy'","Facial Recognition, Privacy","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","2/5/20","","0","Active","2/15/2021","3/16/2022","","","The plaintiff voluntarily dismissed CDW as a defendant, while other similar suits did not. This case is one of three brought in ND Illinois that is consolidated with six SDNY cases, and at the time of the motion to dismiss there were already two Illinois and four SDNY cases on Clearview's radar.","Plaintiff Hall filed complaint on behalf of class action on February 5, just days after the first Clearview case was filed. Hall brought the case against Clearview, Clearview's founders, and CDW as a third party contractor to sell or lease access to
the surveillance database. On July 27, Plaintiff Hall voluntarily dismissed CDW as a defendant.

The claims under BIPA and ICFA revolve around the report in January 2020 by the New York Times and Chicago Tribute that Clearview scraped 3 billion images from social media sites. Hall's action is based on: ""Because Hall has such a widespread and active social media presence, on information and belief, Hall’s biometric information and identifiers and his personal and private information are contained in Clearview’s database."" Hall claims to have experienced stress, anxiety, and emotional distress knowing that his private data was in Clearview's database, and he is at a higher risk for stalking and harassment, and has suffered ""actual damages"" from the loss of control of his biometric data.

Clearview filed a motion to dismiss or transfer venue on April 27. The memorandum in support lists that New York is the Nexus of the cases, and that the plaintiff's claims overlap claims brought by others, four of six of which were brought in SDNY.

The court denied the motion dismiss, and the case was combined into In Re Clearview in ND Illinois in January 2021 as all of the cases share: ""(1) share a common defendant (Clearview) and procedural posture (preanswer); (2) are putative class actions involving a class of Illinois residents; (3) allege that Defendants violated the Illinois Biometric Information Privacy Act (“BIPA”); and (4) seek the same relief"" as stated in the motion to transfer.

Consolidated under Mutnick v. Clearview AI, Inc., still in ND Ill.","MDL Transfer","8/12/2020","Hall v. Clearview AI, Inc. Conversion, violates BIPA, Ill. UDAP; seeking injunctive relief (including deletion of data and compliance monitoring), damages, and litigation costs The plaintiff voluntarily dismissed CDW as a defendant, while other similar suits did not. This case is one of three brought in ND Illinois that is consolidated with six SDNY cases, and at the time of the motion to dismiss there were already two Illinois and four SDNY cases on Clearview's radar. Plaintiff Hall filed complaint on behalf of class action on February 5, just days after the first Clearview case was filed. Hall brought the case against Clearview, Clearview's founders, and CDW as a third party contractor to sell or lease access to
the surveillance database. On July 27, Plaintiff Hall voluntarily dismissed CDW as a defendant.

The claims under BIPA and ICFA revolve around the report in January 2020 by the New York Times and Chicago Tribute that Clearview scraped 3 billion images from social media sites. Hall's action is based on: ""Because Hall has such a widespread and active social media presence, on information and belief, Hall’s biometric information and identifiers and his personal and private information are contained in Clearview’s database."" Hall claims to have experienced stress, anxiety, and emotional distress knowing that his private data was in Clearview's database, and he is at a higher risk for stalking and harassment, and has suffered ""actual damages"" from the loss of control of his biometric data.

Clearview filed a motion to dismiss or transfer venue on April 27. The memorandum in support lists that New York is the Nexus of the cases, and that the plaintiff's claims overlap claims brought by others, four of six of which were brought in SDNY.

The court denied the motion dismiss, and the case was combined into In Re Clearview in ND Illinois in January 2021 as all of the cases share: ""(1) share a common defendant (Clearview) and procedural posture (preanswer); (2) are putative class actions involving a class of Illinois residents; (3) allege that Defendants violated the Illinois Biometric Information Privacy Act (“BIPA”); and (4) seek the same relief"" as stated in the motion to transfer.

Consolidated under Mutnick v. Clearview AI, Inc., still in ND Ill.  Clearview Facial Recognition BIPA; UDAP Facial Recognition, Privacy"
"55","55","People v. H.K","On the heels of People v.Wakefield, the court found that TrueAllele's source code running DNA found at the crime scene against defendant DNA to produce probabilities was not sufficient to make the source code a declarant","'Constitutional Law','Criminal Justice','Sentencing'","","'Biometric Information Privacy Act','6th Amendment'","","'Reliability','Confrontation Clause'","","","TrueAllele","","No","","State: New York Criminal County Bronx","10/28/2018","Yes","-1","Inactive","10/14/2021","10/26/2021","RA Done","Jenna","The court contrasts this case with Wakefield in that the defendant here did not assert that they did not have access to the source code. However, the defense called for a Frye Hearing for admissibility of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele and requested a hearing to ascertain the acceptance within the scientific community. The court overviews the four steps in DNA genotyping:  (1) extraction of the DNA from a sample through heating to isolate; (2) quantifying the amount of DNA,  (3) amplification or copying the DNA; and (4) detection of any usable DNA in the sample.  After this process either a criminologist or an algorithm compare the samples for a probability of matching. An algorithm is used for two or more DNA sources to differentiate the mixing of the DNA into the separate samples, like STRMix. The algorithm assigns a probability for each genotype loci using both biological and mathematical modeling.  When STRmix and the analyst differ in opinion, the analyst reexamines the inputs into the algorithm and rerun the correct parameters.  On cross-examination, the defense questioned the witness on the issues with STRMix, which include: ""stutter, drop-in, drop-out, random walk standard deviation, effective sample size thinning, degradation, saturation burn-in accepts, highest posterior density iterations and duplicate runs."" These are accounted for in the parameters input so that they do not change the probability ratio provided.  The criminologist expert also testified of how the criminalists are trained first to interpret DNA and then exercises showing how STRmix works using assumptions and parameters with samples. STRmix differs from TrueAllele in that the raw data is input directly into TrueAllele whereas STRmix needs an analyst to go through the extraction-quantification process. Finally, the expert witness compared algorithms like STRmix to Google Maps: ""a driver could use a map to get their destination, calculate the mileage and make an approximation about travel time. With Google maps, the driver could see all that information mapped out in front of them—but they would still have to check that they are going to the correct place and verify that they had gotten there.""","The defendant here was a tenant of the victims' grandmother, and on October 28, 2018 entered their bedroom and sexually molested the two victims. The victims informed their family members who called the police. The defendant told the police there was no sexual contact in their interaction. Both victims and the defendant voluntarily gave DNA samples for testing from the touched areas. Defendant was charged with two counts of Forcible touching, one count of Endangering the welfare of a child, two counts of Sexual abuse in the third degree and two counts of Harassment in the second degree. The DNA samples tested from one of the two victim did not have enough DNA to type. However, the DNA sample secretion from the first victim showed over a quadrillion likelihood that the sample came from defendant and the victim and not two unknown parties. The defense called for a Frye Hearing for admissability of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele. At the hearing, the defense did not present any witnesses, and the prosecution presented a criminologist with a background that the court found credible. The criminologist frequently worked with STRMix. The court admitted the evidence, and ruled on the sixth amendment argument found that raw data was not testimonial even if it linked to the accused defendant. The court further held that an analyst that who testifies to the facts that were assisted by an algorithm means the analyst can be meaningfully cross-examined. The STRmix is the tool that the analyst uses, so the motion to deny criminalist testimony was denied.","Trial Court ruling","5/15/2020","People v. H.K On the heels of People v.Wakefield, the court found that TrueAllele's source code running DNA found at the crime scene against defendant DNA to produce probabilities was not sufficient to make the source code a declarant The court contrasts this case with Wakefield in that the defendant here did not assert that they did not have access to the source code. However, the defense called for a Frye Hearing for admissibility of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele and requested a hearing to ascertain the acceptance within the scientific community. The court overviews the four steps in DNA genotyping:  (1) extraction of the DNA from a sample through heating to isolate; (2) quantifying the amount of DNA,  (3) amplification or copying the DNA; and (4) detection of any usable DNA in the sample.  After this process either a criminologist or an algorithm compare the samples for a probability of matching. An algorithm is used for two or more DNA sources to differentiate the mixing of the DNA into the separate samples, like STRMix. The algorithm assigns a probability for each genotype loci using both biological and mathematical modeling.  When STRmix and the analyst differ in opinion, the analyst reexamines the inputs into the algorithm and rerun the correct parameters.  On cross-examination, the defense questioned the witness on the issues with STRMix, which include: ""stutter, drop-in, drop-out, random walk standard deviation, effective sample size thinning, degradation, saturation burn-in accepts, highest posterior density iterations and duplicate runs."" These are accounted for in the parameters input so that they do not change the probability ratio provided.  The criminologist expert also testified of how the criminalists are trained first to interpret DNA and then exercises showing how STRmix works using assumptions and parameters with samples. STRmix differs from TrueAllele in that the raw data is input directly into TrueAllele whereas STRmix needs an analyst to go through the extraction-quantification process. Finally, the expert witness compared algorithms like STRmix to Google Maps: ""a driver could use a map to get their destination, calculate the mileage and make an approximation about travel time. With Google maps, the driver could see all that information mapped out in front of them—but they would still have to check that they are going to the correct place and verify that they had gotten there."" The defendant here was a tenant of the victims' grandmother, and on October 28, 2018 entered their bedroom and sexually molested the two victims. The victims informed their family members who called the police. The defendant told the police there was no sexual contact in their interaction. Both victims and the defendant voluntarily gave DNA samples for testing from the touched areas. Defendant was charged with two counts of Forcible touching, one count of Endangering the welfare of a child, two counts of Sexual abuse in the third degree and two counts of Harassment in the second degree. The DNA samples tested from one of the two victim did not have enough DNA to type. However, the DNA sample secretion from the first victim showed over a quadrillion likelihood that the sample came from defendant and the victim and not two unknown parties. The defense called for a Frye Hearing for admissability of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele. At the hearing, the defense did not present any witnesses, and the prosecution presented a criminologist with a background that the court found credible. The criminologist frequently worked with STRMix. The court admitted the evidence, and ruled on the sixth amendment argument found that raw data was not testimonial even if it linked to the accused defendant. The court further held that an analyst that who testifies to the facts that were assisted by an algorithm means the analyst can be meaningfully cross-examined. The STRmix is the tool that the analyst uses, so the motion to deny criminalist testimony was denied.  TrueAllele   "
"74","74","Patel v. Facebook, Inc.","A plaintiff whose common law privacy rights or biometric privacy rights are violate establishes an injury in fact that is required under Article III standing.","'Biometric Data'","Biometric Data","'Illinois Biometric Information Privacy Act'","Illinois Biometric Information Privacy Act","'Facial Recognition'","Facial Recognition","","","","","","U.S. District Court for Northern California","","","0","","4/4/2022","4/11/2022","","","The collection of an individual’s biometric data in violation of the Illinois Biometric Information Privacy Act is sufficient to establish Article III standing.","Facebook users in Illinois allege that Facebook collected their biometric data without notice or consent through the Tag Suggestions tool. This tool undergoes four steps, one of which is to search the stored “face templates” from users for a match. Facebook collects face templates from users without their consent or notice.","Cert Denied","","Patel v. Facebook, Inc. A plaintiff whose common law privacy rights or biometric privacy rights are violate establishes an injury in fact that is required under Article III standing. The collection of an individual’s biometric data in violation of the Illinois Biometric Information Privacy Act is sufficient to establish Article III standing. Facebook users in Illinois allege that Facebook collected their biometric data without notice or consent through the Tag Suggestions tool. This tool undergoes four steps, one of which is to search the stored “face templates” from users for a match. Facebook collects face templates from users without their consent or notice.   Biometric Data Illinois Biometric Information Privacy Act Facial Recognition"
"90","90","Kadrey v. Meta Platforms, Inc.","Authors Richard Kadrey, Sarah Silverman, and Christopher Golden sue Meta Platforms on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for the LLaMA language models, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.","'Generative AI'","Generative AI","'Copyright Infringement','Unjust Enrichment','Unfair Competition','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information","'Copyright Infringement'","Copyright Infringement","'LLaMA'","LLaMA","'Yes'","","Meta Platforms, Inc.","Federal: US Dist. Ct. N.D. Ca.","07/07/2023","","0","Active","7/27/2023","7/27/2023","","Bob","","Plaintiffs allege that Meta Platforms trained its large language model LLaMA with data that included ""the Books3 section of The Pile,"" which is compiled by an organization called EleutherAI.  Books3 is allegedly derived from a collection of 196,640 books on a website called ""Bibliotik."" That collection includes many books that are still under copyright, including books written by the individual plaintiffs.  Plaintiffs' claims arise out of Meta's use of those books to train LLaMA without the authorization of the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used.  Plaintiffs filed their complaint on July 7, 2023; the case was assigned to Judge Vince Chhabria July 24, 2023","Case reassigned to Judge Vince Chhabria","7/24/2023","Kadrey v. Meta Platforms, Inc. Authors Richard Kadrey, Sarah Silverman, and Christopher Golden sue Meta Platforms on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for the LLaMA language models, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.  Plaintiffs allege that Meta Platforms trained its large language model LLaMA with data that included ""the Books3 section of The Pile,"" which is compiled by an organization called EleutherAI.  Books3 is allegedly derived from a collection of 196,640 books on a website called ""Bibliotik."" That collection includes many books that are still under copyright, including books written by the individual plaintiffs.  Plaintiffs' claims arise out of Meta's use of those books to train LLaMA without the authorization of the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used.  Plaintiffs filed their complaint on July 7, 2023; the case was assigned to Judge Vince Chhabria July 24, 2023 Meta Platforms, Inc. LLaMA Generative AI Copyright Infringement, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information Copyright Infringement"
"8","8","Bauserman v. Unemployment Insurance Agency ;","Class action against Michigan's Unemployment Insurance Agency's use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, resulting in civil penalties including seizure of tax refunds with a limited time to appeal, with claims court lawsuit seeking redress and to make this automated system illegal; lawsuit in federal court against agency officials and system developer","'Agency','Fraud','Unemployment Insurance'","Unemployment Insurance; Fraud; Agency","'Due Process Clause','Negligence'","Due Process; Negligence","'Accountability','Lack of Human Review','Notice','Role of Expert Testimony','Socioeconomics Bias','Use of Race','Miscalculation'","Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy","'MIDAS'","MIDAS","","Yes","","Federal: US Dist. Ct. E. D. Michigan","2013","Yes","-1","Active","2/1/2021","3/5/2021","","","This is one case that was brought after the MiDAS algorithm falsely accused thousands of fraud that resulted in three outcomes: 1. seizure of state or federal income taxes refunds, 2. forced repayment of benefits, or 3. wage garnishments.

The algorithm resulted in the UIA wrongfully accusing thousands of fraud, and notifying the claimants with 10 days to rebut. 

The Court of Appeals and Supreme Court opinions relate to the lack of notice and loss of property followed by the automated decision system spotting the ""suspected fraud"" rather than the use of the automated decision system,","Since August 12, 2012, the class members allege their due process rights of fair and just treatment were violated when the automated decision system MiDAS determined guilt of fraud without providing notice, proving guilt, or affording a way to challenge. Based on the algorithm, the claimants were disqualified or ineligible for unemployment benefits.

The putative class complaint filed on September 9, 2015, stating that the MiDAS deprived the claimants of presenting evidence to ""real people."" This resulted in claimants paying or ""satisfying their debt"" even if they did not owe money. Originally filed by Bauserman, the amended complaint added Broe and Williams.

UIA issued redeterminations of some class members to clear them of fraud, and then moved for summary judgement. One of the arguments the Court of Claims judge denied is that the complaint was not filed within six months of the event happening that gave rise of the cause of action. However, the Court of Appeals reversed on July 18, 2017, concluding that the claims did not accrue when the plaintiffs received the redetermination notices, but the original notice alleging fraudulent conduct. The plaintiffs appealed to the Supreme Court, who had the option to grant the appeal or take action.

Supreme Court took action in April 2019, affirming the judgement for Bauserman and Broe but not for Williams who had not filed within six months of the letter, stating that ""plaintiffs did not incur an "" ‘actionable harm’ "" in their due-process claims until they were deprived of their property when their income tax refunds were seized or their wages were garnished.""

Court of Appeals opinion on remand in December 5, 2019 said that plaintiffs raised cognizable constitutional tort claims and thus did not grant summary disposition.

The UIA appealed to Supreme Court was accepted because there is no case law on how or when a court can award money damages in a case where the plaintiffs allege a violation of their due process rights.""

Michigan's Supreme Court considered the argument on leave from December 5, 2019 for Unemployment Insurance Agency appeal, and ordered oral arguments to be scheduled on November 25, 2020.

No documents have been filed since.","Supreme Court Opinion","11/25/2020","Bauserman v. Unemployment Insurance Agency ; Class action against Michigan's Unemployment Insurance Agency's use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, resulting in civil penalties including seizure of tax refunds with a limited time to appeal, with claims court lawsuit seeking redress and to make this automated system illegal; lawsuit in federal court against agency officials and system developer This is one case that was brought after the MiDAS algorithm falsely accused thousands of fraud that resulted in three outcomes: 1. seizure of state or federal income taxes refunds, 2. forced repayment of benefits, or 3. wage garnishments.

The algorithm resulted in the UIA wrongfully accusing thousands of fraud, and notifying the claimants with 10 days to rebut. 

The Court of Appeals and Supreme Court opinions relate to the lack of notice and loss of property followed by the automated decision system spotting the ""suspected fraud"" rather than the use of the automated decision system, Since August 12, 2012, the class members allege their due process rights of fair and just treatment were violated when the automated decision system MiDAS determined guilt of fraud without providing notice, proving guilt, or affording a way to challenge. Based on the algorithm, the claimants were disqualified or ineligible for unemployment benefits.

The putative class complaint filed on September 9, 2015, stating that the MiDAS deprived the claimants of presenting evidence to ""real people."" This resulted in claimants paying or ""satisfying their debt"" even if they did not owe money. Originally filed by Bauserman, the amended complaint added Broe and Williams.

UIA issued redeterminations of some class members to clear them of fraud, and then moved for summary judgement. One of the arguments the Court of Claims judge denied is that the complaint was not filed within six months of the event happening that gave rise of the cause of action. However, the Court of Appeals reversed on July 18, 2017, concluding that the claims did not accrue when the plaintiffs received the redetermination notices, but the original notice alleging fraudulent conduct. The plaintiffs appealed to the Supreme Court, who had the option to grant the appeal or take action.

Supreme Court took action in April 2019, affirming the judgement for Bauserman and Broe but not for Williams who had not filed within six months of the letter, stating that ""plaintiffs did not incur an "" ‘actionable harm’ "" in their due-process claims until they were deprived of their property when their income tax refunds were seized or their wages were garnished.""

Court of Appeals opinion on remand in December 5, 2019 said that plaintiffs raised cognizable constitutional tort claims and thus did not grant summary disposition.

The UIA appealed to Supreme Court was accepted because there is no case law on how or when a court can award money damages in a case where the plaintiffs allege a violation of their due process rights.""

Michigan's Supreme Court considered the argument on leave from December 5, 2019 for Unemployment Insurance Agency appeal, and ordered oral arguments to be scheduled on November 25, 2020.

No documents have been filed since.  MIDAS Unemployment Insurance; Fraud; Agency Due Process; Negligence Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy"
"24","24","John v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, Cal. UDAP (unfair), Cal. right to publicity, Cal. Const. privacy, interference with K with social media companies, and unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA','Contracts','Right to Privacy','UDAP','Right to Publicity','Unjust Enrichment'","BIPA, UDAP, ight to privacy, right to publicity, contracts, unjust enrichment","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal:  US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","5/4/2020","No","0","Active","2/12/2021","5/1/2022","","","The fifth of the six New York cases consolidated under MDL, this case was brought after Judge McMahon's April 22 Directive regarding Calderon, Broccolino, Burke, and Roberson.

Of the class, there are four subclasses: Nationwide, Illinois, New York, and California. John is from New York, Balfanz is from California, and Jais and the rest of the class are from Illinois. This is the first action where the class is from three or more states.

The complaint emphasizes Clearview's lack of data security on top of its violation of privacy.","The complaint is brought in SDNY against Clearview and its cofounders Hoan Ton-That and Richard Schwartz for violating BIPA. Like other complaints, complaint emphasizes Clearview's marketing of its proprietary facial recognition technology, and its paid contracts with ICE, foreign governments, and fitness, retail and entertainment companies. 

Judge McMahon ordered a statement of relatedness to Calderon, which was filed on May 5, 2020, finding that the SDNY cases and Illinois case 1. concern the same or substantially similar parties, transactions and events, 2. the facts substantially overlap, 3. the parties could get conflicting orders and 4. there would be duplication of effort and expense on the court, parties and witnesses if there is not a determination of relatedness. 

The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.","MDL Transferred out","1/12/2021","John v. Clearview AI, Inc. Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, Cal. UDAP (unfair), Cal. right to publicity, Cal. Const. privacy, interference with K with social media companies, and unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs The fifth of the six New York cases consolidated under MDL, this case was brought after Judge McMahon's April 22 Directive regarding Calderon, Broccolino, Burke, and Roberson.

Of the class, there are four subclasses: Nationwide, Illinois, New York, and California. John is from New York, Balfanz is from California, and Jais and the rest of the class are from Illinois. This is the first action where the class is from three or more states.

The complaint emphasizes Clearview's lack of data security on top of its violation of privacy. The complaint is brought in SDNY against Clearview and its cofounders Hoan Ton-That and Richard Schwartz for violating BIPA. Like other complaints, complaint emphasizes Clearview's marketing of its proprietary facial recognition technology, and its paid contracts with ICE, foreign governments, and fitness, retail and entertainment companies. 

Judge McMahon ordered a statement of relatedness to Calderon, which was filed on May 5, 2020, finding that the SDNY cases and Illinois case 1. concern the same or substantially similar parties, transactions and events, 2. the facts substantially overlap, 3. the parties could get conflicting orders and 4. there would be duplication of effort and expense on the court, parties and witnesses if there is not a determination of relatedness. 

The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.  Clearview Facial Recognition BIPA, UDAP, ight to privacy, right to publicity, contracts, unjust enrichment Privacy"
"40","40","Marron v. Clearview AI, Inc.","Violates BIPA; seeking injunctive relief, statutory damages, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA'","BIPA","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York.; Transferred to US Dist. Ct. N.D. Illinois","5/20/2020","","0","Active","2/15/2021","5/1/2022","","","The last of the Clearview class action suits to be filed.","Plaintiffs Chris Marron and Maryann Daker brought this class action against Clearview AI, Inc., Hoan Ton-That, an Individual, Richard Schwartz, an Individual (collectively with Hoan Ton-That, “Individual Defendants”) and CDW Government LLC, an Illinois Company (“CDW”) for violating BIPA.

The basis of the complaint is the February 2020 leak that showed Clearview's 6,000 clientele, which included large companies and government agencies.

The claims are that since plaintiffs are residents of Illinois, they have posted their pictures or had their pictures posted online, and Clearview has scraped 3 billion images and thus violated plaintiffs' privacy. For CDW in particular, plaintiffs allege that the company provides services to local government agencies, and was Clearview's agent to ""advertise, license, and sell Clearview’s proprietary facial recognition platform to .... upon information and belief, to the Chicago Police Department""

The complaint describes the process of defendants finding a match in Clearview's system, and the ways in which it can use the plaintiff's private data.

Plaintiffs also brings actions against Clearview founder Richard Schwartz and Clearview founder and CEO Hoan Ton-That, citing statements that the algorithm always makes a match with no error, and that Clearview has been subject to numerous cyber attacks.

The case was consolidated under MDL in January 8, 2021.","Consolidated into MDL","1/8/2021","Marron v. Clearview AI, Inc. Violates BIPA; seeking injunctive relief, statutory damages, and litigation costs The last of the Clearview class action suits to be filed. Plaintiffs Chris Marron and Maryann Daker brought this class action against Clearview AI, Inc., Hoan Ton-That, an Individual, Richard Schwartz, an Individual (collectively with Hoan Ton-That, “Individual Defendants”) and CDW Government LLC, an Illinois Company (“CDW”) for violating BIPA.

The basis of the complaint is the February 2020 leak that showed Clearview's 6,000 clientele, which included large companies and government agencies.

The claims are that since plaintiffs are residents of Illinois, they have posted their pictures or had their pictures posted online, and Clearview has scraped 3 billion images and thus violated plaintiffs' privacy. For CDW in particular, plaintiffs allege that the company provides services to local government agencies, and was Clearview's agent to ""advertise, license, and sell Clearview’s proprietary facial recognition platform to .... upon information and belief, to the Chicago Police Department""

The complaint describes the process of defendants finding a match in Clearview's system, and the ways in which it can use the plaintiff's private data.

Plaintiffs also brings actions against Clearview founder Richard Schwartz and Clearview founder and CEO Hoan Ton-That, citing statements that the algorithm always makes a match with no error, and that Clearview has been subject to numerous cyber attacks.

The case was consolidated under MDL in January 8, 2021.  Clearview Facial Recognition BIPA Privacy"
"57","57","Sevatec, Inc. v. Ayyar","The court allowed expert testimony at trial to understand complex evidence related to artificial intelligence","'Corporate Law'","Corporate Law","'Evidence','Fiduciary Duty'","","'Role of Expert Testimony'","","","","","No","","State: Fairfax County of Virginia","10/09/2018","Yes","-1","Active","10/14/2021","10/29/2021","RA Done; Check for New Activity","Jenna","The two issues for expert testimony concerned (1) explaining complex artificial intelligence to the jury and (2) explaining the corporate business opportunity. For the complex issues, Hermus was an appropriate expert witness with 20 years of experience in information technology and could explain data analytics, artificial intelligence, and machine learning to the triers of fact. His background gave him ""knowledge beyond that of persons of common knowledge and ordinary experience.""","Plaintiff is a corporation, Sevatec, who provides ""data analytics"" solutions involving machine learning, artificial intelligence, and open source technologies. Sevatec brought suit in Fall 2018 against its former President and CEO Ayyar and Chief Technology Officer Bangalore. Sevatec alleges Ayyar and Bangalore ""conspired to develop a new technology solution involving artificial intelligence and data analytics prior to their departures and formed Defendant Percipient.AI, Inc. whose flagship offering is the technology solution developed while in the employ of Sevatec."" In March 2019, Sevatec assigned expert witness Hermus who is a technology specialist to testify on their usurpation of business from Sevatec. Defendants moved to exclude his testimony for three reasons: (1) Hermus's opinions  will mislead the jury about Virginia law by using a Delaware test, (2) ""Hermus's opinions will invade the province of the jury because they are rudimental and will not assist the jury in resolving any facts  at issue,"" and (3) Sevatec failed to identify all the documents and information relied upon by Hermus in his expert disclosure. On June 3, 2019, the court denied this motion in limine. For the first contention, the court compares the Usurpation of Corporate opportunity Standard with the Line Business Test of Delaware  as well as the Multiple Factors test and Fairness tests, concluding that Virginia has not adopted a test and thus can rely on an expert from another jurisdiction. Second, the court disagrees with the defendant that the issues are noncomplex, as his ""scientific, technical, or other specialized knowledge will assist the trier of fact"" in determining whether Defendants usurped a technology solution from Sevatec. Third, the court held that Sevatec was not required to identify Hermus' sources of information.","","","Sevatec, Inc. v. Ayyar The court allowed expert testimony at trial to understand complex evidence related to artificial intelligence The two issues for expert testimony concerned (1) explaining complex artificial intelligence to the jury and (2) explaining the corporate business opportunity. For the complex issues, Hermus was an appropriate expert witness with 20 years of experience in information technology and could explain data analytics, artificial intelligence, and machine learning to the triers of fact. His background gave him ""knowledge beyond that of persons of common knowledge and ordinary experience."" Plaintiff is a corporation, Sevatec, who provides ""data analytics"" solutions involving machine learning, artificial intelligence, and open source technologies. Sevatec brought suit in Fall 2018 against its former President and CEO Ayyar and Chief Technology Officer Bangalore. Sevatec alleges Ayyar and Bangalore ""conspired to develop a new technology solution involving artificial intelligence and data analytics prior to their departures and formed Defendant Percipient.AI, Inc. whose flagship offering is the technology solution developed while in the employ of Sevatec."" In March 2019, Sevatec assigned expert witness Hermus who is a technology specialist to testify on their usurpation of business from Sevatec. Defendants moved to exclude his testimony for three reasons: (1) Hermus's opinions  will mislead the jury about Virginia law by using a Delaware test, (2) ""Hermus's opinions will invade the province of the jury because they are rudimental and will not assist the jury in resolving any facts  at issue,"" and (3) Sevatec failed to identify all the documents and information relied upon by Hermus in his expert disclosure. On June 3, 2019, the court denied this motion in limine. For the first contention, the court compares the Usurpation of Corporate opportunity Standard with the Line Business Test of Delaware  as well as the Multiple Factors test and Fairness tests, concluding that Virginia has not adopted a test and thus can rely on an expert from another jurisdiction. Second, the court disagrees with the defendant that the issues are noncomplex, as his ""scientific, technical, or other specialized knowledge will assist the trier of fact"" in determining whether Defendants usurped a technology solution from Sevatec. Third, the court held that Sevatec was not required to identify Hermus' sources of information.   Corporate Law  "
"76","76","Williams-Sonoma, Inc. v. Amazon.com, Inc.","Williams-Sonoma sued Amazon for, among other things, copyright infringement stemming from Williams-Sonoma-owned photographs that an Amazon algorithm selected for display on Amazon's website from photographs submitted by third-party vendors. The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection.","'Copyright'","Copyright","'Copyright Infringement'","Copyright Infringement","'Infringement'","Infringement","","","","","Williams-Sonoma Inc.; Amazon, Inc.","Federal: U.S. Dist. Ct. N.D. California","12/13/2018","","0","Inactive","4/4/2022","7/28/2023","","Bob","The court's ruling on the motion to dismiss the copyright infringement claim in this case suggests that the actions of a computer algorithm that are in some sense ""automatic,"" in the sense that no human being is directly controlling or aware of them, can nonetheless be sufficient ""volitional acts"" of the company that is running that algorithm to render that company liable for direct copyright infringement. The allegations were that ""Amazon's image-selection algorithm affirmatively selects the image using 'multi factor criteria' designed and employed to enhance product sales and boost internet traffic on Amazon's website,"" and picking the most attractive photo increases the risk that it will infringe professionally produced photos. The court also held that, at least on a motion to dismiss, it could not hold that the Williams-Sonoma photos were ""stored at the direction of the user,"" as is required to qualify for the DMCA safe harbor under section 512(c), because Amazon allegedly had complete control over which photos would be displayed on its marketplace web pages.","Williams-Sonoma sued Amazon for trademark infringement, design patent infringement, unfair competition, and copyright infringement arising from the sale of ""Williams-Sonoma""-branded merchandise on Amazon's third-party online marketplace. The copyright infringement claim stemmed from photographs in which Williams-Sonoma owned copyright that an Amazon algorithm selected for display from photographs submitted by third-party vendors.  The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection.  The case then settled.","Case settled","4/19/2021","Williams-Sonoma, Inc. v. Amazon.com, Inc. Williams-Sonoma sued Amazon for, among other things, copyright infringement stemming from Williams-Sonoma-owned photographs that an Amazon algorithm selected for display on Amazon's website from photographs submitted by third-party vendors. The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection. The court's ruling on the motion to dismiss the copyright infringement claim in this case suggests that the actions of a computer algorithm that are in some sense ""automatic,"" in the sense that no human being is directly controlling or aware of them, can nonetheless be sufficient ""volitional acts"" of the company that is running that algorithm to render that company liable for direct copyright infringement. The allegations were that ""Amazon's image-selection algorithm affirmatively selects the image using 'multi factor criteria' designed and employed to enhance product sales and boost internet traffic on Amazon's website,"" and picking the most attractive photo increases the risk that it will infringe professionally produced photos. The court also held that, at least on a motion to dismiss, it could not hold that the Williams-Sonoma photos were ""stored at the direction of the user,"" as is required to qualify for the DMCA safe harbor under section 512(c), because Amazon allegedly had complete control over which photos would be displayed on its marketplace web pages. Williams-Sonoma sued Amazon for trademark infringement, design patent infringement, unfair competition, and copyright infringement arising from the sale of ""Williams-Sonoma""-branded merchandise on Amazon's third-party online marketplace. The copyright infringement claim stemmed from photographs in which Williams-Sonoma owned copyright that an Amazon algorithm selected for display from photographs submitted by third-party vendors.  The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection.  The case then settled. Williams-Sonoma Inc.; Amazon, Inc.  Copyright Copyright Infringement Infringement"
"92","92","Tremblay v. OpenAI, Inc.","Authors Paul Tremblay and Mona Awad sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.","'Generative AI'","Generative AI","'Copyright Infringement','Negligence','Unjust Enrichment','Unfair Competition','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information","'Copyright Infringement'","Copyright Infringement","'ChatGPT'","ChatGPT","'Yes'","","OpenAI, Inc.","Federal: US Dist. Ct. N.D. Ca.","06/28/2023","","0","Active","7/13/2023","7/27/2023","","Bob","","Plaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on June 28, 2023.  The case was assigned to Judge Araceli Martinez-Olguin on June 29, 2023.  Plaintiffs filed a motion to relate this case with Silverman v. OpenAI on July 19, 2023.","Plaintiffs filed motion to relate case to Silverman v. OpenAI","7/19/2023","Tremblay v. OpenAI, Inc. Authors Paul Tremblay and Mona Awad sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.  Plaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on June 28, 2023.  The case was assigned to Judge Araceli Martinez-Olguin on June 29, 2023.  Plaintiffs filed a motion to relate this case with Silverman v. OpenAI on July 19, 2023. OpenAI, Inc. ChatGPT Generative AI Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information Copyright Infringement"
"3","3","United States v. Curry","Court found that there were no exigent circumstances to justify the police seizing a defendant with no suspicious activity near the scene of gunshots because an algorithm indicated the area would be a hot spot for criminal activity, where the concurrence and dissent addressed that predictive policing algorithms have been shown to have questionable effectiveness and clear racial bias.","'Criminal Justice','Search and Seizure'","Criminal Justice; Search and Seizure","'Exigent Circumstances','Fourth Amendment'","Fourth Amendment; Exigent Circumstances","'Human Programming Flaws','Predictive Policing','Unreliability','Use of Race'","Use of Race, Predictive Policing; Unreliability; Human Programming Flaws","","","","No","","Federal: US Dist. Ct. E.D. Virginia","10/3/2017","Yes","-1","Inactive: Judgement for D","2/1/2021","3/19/2021","RA Done","Jenna","Judge Gregory's concurrence concludes that predictive policing used to prevent crimes rather than solve them all depend on how the officers implement the information they are given when they reach the neighborhood to not perpetuate a high-tech version of racial profiling.

Circuit Judge Wyn concurs to note that the Supreme Court has been reluctant to rely on studies and statistical inferences for constitutional issues, unlike the dissent suggestion. 

Judge Thacker concurs to address that predictive policing is just racial profiling with ""at best, questionable effectiveness."" Thacker further observes that the algorithm is only as good as the human programmer, and often the algorithms are programmed with racial biases inherent. An example is hot spot policing, which use neighborhood historical crime to predict future crime, often rampant with racial bias. Thacker and Wilkinson agree that the change must come to the police themselves, as it is the officers and not the algorithm that abuses their authority and causes fourth amendment violations.

Judge Wilkinson’s dissent calls this ruling a ""gut punch"" to predictive policing, which is a smart policy that can prevent crimes from occurring. Wilkinson explains computer algorithms have replaced push pins and cork boards for hot spot policing, it is not a new phenomenon it has just improved with algorithms. Wilkinson's attitude is that the inherent dangers and difficulties of police work outweigh the potential for racial bias when considering utilizing hot spot policing.","On September 7, 2017, the Richmond Police patrolled a hot spot neighborhood, and upon hearing gunshots, found Curry and another man walking and told them to show their hands. A struggle ensued after Curry did not show his waistband, with the officer locating a revolver. 

On October 3, 2017, a Grand Jury Convicted Curry of Possession of a Firearm by a Convicted Felon, for which he was arrested on October 4, 2017. Curry filed a motion to suppress on November 21, 2017 regarding the firearm and statements made during the encounter with the police officer who conducted the Terry stop. The officer stopped Curry and another man who were walking near a neighborhood where gunshots reported. Following a hearing and supplemental briefing into January 2018, where the parties disagreed on the moment that Curry was seized. The court on March 19, 2018 granted the Motion to Suppress because the ""officer's subjective interpretation of Curry's actions"" could not inform whether the stop was justified or violated the 4th amendment, noting particularly that the officer was not just stopping Curry and asking to see his hands.

The 4th Circuit remanded back to the district court to determine if the stop and flashlight search violated the Fourth Amendment based on exigent circumstances in September 2019. 
Amended in July 2020, the 4th Circuit affirmed the granting of a motion to suppress on grounds that exigent circumstances did not justify the ""suspicionless, investigatory stop."" The concurrence and dissent in this opinion provide key insights into algorithms.","Terminated","9/25/2020","United States v. Curry Court found that there were no exigent circumstances to justify the police seizing a defendant with no suspicious activity near the scene of gunshots because an algorithm indicated the area would be a hot spot for criminal activity, where the concurrence and dissent addressed that predictive policing algorithms have been shown to have questionable effectiveness and clear racial bias. Judge Gregory's concurrence concludes that predictive policing used to prevent crimes rather than solve them all depend on how the officers implement the information they are given when they reach the neighborhood to not perpetuate a high-tech version of racial profiling.

Circuit Judge Wyn concurs to note that the Supreme Court has been reluctant to rely on studies and statistical inferences for constitutional issues, unlike the dissent suggestion. 

Judge Thacker concurs to address that predictive policing is just racial profiling with ""at best, questionable effectiveness."" Thacker further observes that the algorithm is only as good as the human programmer, and often the algorithms are programmed with racial biases inherent. An example is hot spot policing, which use neighborhood historical crime to predict future crime, often rampant with racial bias. Thacker and Wilkinson agree that the change must come to the police themselves, as it is the officers and not the algorithm that abuses their authority and causes fourth amendment violations.

Judge Wilkinson’s dissent calls this ruling a ""gut punch"" to predictive policing, which is a smart policy that can prevent crimes from occurring. Wilkinson explains computer algorithms have replaced push pins and cork boards for hot spot policing, it is not a new phenomenon it has just improved with algorithms. Wilkinson's attitude is that the inherent dangers and difficulties of police work outweigh the potential for racial bias when considering utilizing hot spot policing. On September 7, 2017, the Richmond Police patrolled a hot spot neighborhood, and upon hearing gunshots, found Curry and another man walking and told them to show their hands. A struggle ensued after Curry did not show his waistband, with the officer locating a revolver. 

On October 3, 2017, a Grand Jury Convicted Curry of Possession of a Firearm by a Convicted Felon, for which he was arrested on October 4, 2017. Curry filed a motion to suppress on November 21, 2017 regarding the firearm and statements made during the encounter with the police officer who conducted the Terry stop. The officer stopped Curry and another man who were walking near a neighborhood where gunshots reported. Following a hearing and supplemental briefing into January 2018, where the parties disagreed on the moment that Curry was seized. The court on March 19, 2018 granted the Motion to Suppress because the ""officer's subjective interpretation of Curry's actions"" could not inform whether the stop was justified or violated the 4th amendment, noting particularly that the officer was not just stopping Curry and asking to see his hands.

The 4th Circuit remanded back to the district court to determine if the stop and flashlight search violated the Fourth Amendment based on exigent circumstances in September 2019. 
Amended in July 2020, the 4th Circuit affirmed the granting of a motion to suppress on grounds that exigent circumstances did not justify the ""suspicionless, investigatory stop."" The concurrence and dissent in this opinion provide key insights into algorithms.   Criminal Justice; Search and Seizure Fourth Amendment; Exigent Circumstances Use of Race, Predictive Policing; Unreliability; Human Programming Flaws"
"19","19","Lynch v. Florida","Defendant appeals conviction claiming he was misidentified by the facial recognition software comparing a photo an undercover cop snapped during a drug deal, noting even the analyist did not know how the facial recognition algorithm worked","'Facial Recognition'","Facial Recognition","'Due Process'","Due Process","'Human Programming Flaws','Transparency/Trade Secrecy','Unaware of Use of Algorithm','Use of Race','Unreliability/Miscalculationns'","Use of Race;  Human Programming Flaws; Unreliability/Miscalculation; Transparency; Unaware of Use of Algorithm; Lack of Remedy to prove innocence; Role of Expert Testimony","'FACES'","FACES","","No","ACLU; Electronic Frontier Foundation","State: Florida","9/2015","Yes","-1","Inactive: Appeals denied","2/11/2021","2/13/2021","RA done","Molly","In this case undercover officers bought cocaine from an individual called ""midnight"". The officers later identified Lynch as the seller and brought charges. At trial the defense was misidentification because facial recognition software was used to identify Lynch as ""midnight"" off of a photo the officers took during the drug exchange. 

The program used was the Face Analysis Comparison Examination System (FACES), a program the Pinellas County Sheriff’s office operates and makes available to law enforcement agencies throughout Florida. The algorithm operates in two steps. First it processes the image it is seeking to match (the “probe image”). This often involves “pose correction” and “face normalization” which rotates the image to match the pose of the photos to be matched and approximates what any missing parts of the face look like. It also generates a “faceprint” of features like eye position or skin texture. Second, the algorithm compares the faceprint of the probe image to the faceprint of images in the database and returns several potential matches. The accuracy of FACE is directly affect by the quality of the photos being searched, and can be extremely poor at identifying a person in a low resolution image. It also requires an analyst to utilize the program and evaluate whether the results are worth sending to the inquiring officers. 

Although the facial recognition software led the officers to Lynch, the state did not rely on the facial recognition to identify Lynch. The officers identified Lynch as the man who sold them drugs and the analyst did not even testify in the trial. In an amicus brief the ACLU argued, ""If a witness who identified Mr. Lynch stated that other individuals in a line-up looked like the perpetrator, the state would have had to disclose that information, an well as any information indicated that the witness was uncertain or impaired when making the identification. Here, those same principles should have required the state to disclose the other photos and information on how the algorithm functions."" But the court here seems to be unconcerned with the accuracy of FACE because although it led the officers to Lynch, the officers still identified Lynch as Midnight.","Two officers routinely drove around high-crime areas and posed as drug buyers looking for drugs. In this particular instant a dealer called Midnight flagged the officers down and asked if they “were good”, and then proceeded to sell them cocaine. Normally the officers would record these transactions but because Midnight approached them so suddenly they were not able to activate the recording system. One officer did snap a photo with his phone of Midnight leaning on the car. The phone used was not a modern smartphone rather an old tracfone from Walmart. The quality of phone combined with the photo being snapped while the officer pretended to be making a call, resulted in a photo that was from an oblique angle, off-axis, and blurred in places. 

The officers had no idea who Midnight was, so they emailed the photos to an analyst to identify Midnight. To begin with she looked up the nickname “midnight” in the law-enforcement database and found several people with that alias, but none who looked like the man in the photo. She then proceeded to use a facial-recognition program (FACES) that compared the photo against photos in the law-enforcement database.  

FACES could have been utilized as an open search, but she limited her search to black males and only considered Duval County booking photos. The program then returns photos almost like a photo lineup. Then the analyst makes a judgment call on whether to send that information to the detective. The program also gives you some amount of stars indicating the likelihood of a match, but the analyst was unsure how many stars were possible or how the program worked. She did remember that Lynch’s photo only had one star next to it, but it was the highest ranked match. According to an amicus brief filed by the ACLU his photo was actually just the first-listed photo in the list of possible matches but the first-listed photo is not necessarily the best match. The analyst told the officers that Lynch was a possible match to the man in the cell photo so the officers concluded that Lynch and Midnight were the same person. The Analyst did not testify at trial. 

At trial Lynch, as a pro se motion, sought to compel the state to produce the photographs of the other “Midnights” contained in the database, as well as the other photographs the facial-recognition program returned. The court denied the request concluding the photos were not relevant. Then court also revoked Lynch’s self-representation at this point and re appointed a public defender. 

Lynch argued on appeal that he should have access to the other photos because those photos could cast doubt on the State's case, and that by not providing the photos the state violated Brady v. Maryland. The court rejected this argument because lynch could not show that the other photos in the database resembled him, and that the attorney chose to not call the analyst as a witness because the analyst would only corroborate the officers testimony, and the jury convicted only after comparing the photo the officer took to Lynch himself.","Supreme Court of Florida denied review","7/19/2019","Lynch v. Florida Defendant appeals conviction claiming he was misidentified by the facial recognition software comparing a photo an undercover cop snapped during a drug deal, noting even the analyist did not know how the facial recognition algorithm worked In this case undercover officers bought cocaine from an individual called ""midnight"". The officers later identified Lynch as the seller and brought charges. At trial the defense was misidentification because facial recognition software was used to identify Lynch as ""midnight"" off of a photo the officers took during the drug exchange. 

The program used was the Face Analysis Comparison Examination System (FACES), a program the Pinellas County Sheriff’s office operates and makes available to law enforcement agencies throughout Florida. The algorithm operates in two steps. First it processes the image it is seeking to match (the “probe image”). This often involves “pose correction” and “face normalization” which rotates the image to match the pose of the photos to be matched and approximates what any missing parts of the face look like. It also generates a “faceprint” of features like eye position or skin texture. Second, the algorithm compares the faceprint of the probe image to the faceprint of images in the database and returns several potential matches. The accuracy of FACE is directly affect by the quality of the photos being searched, and can be extremely poor at identifying a person in a low resolution image. It also requires an analyst to utilize the program and evaluate whether the results are worth sending to the inquiring officers. 

Although the facial recognition software led the officers to Lynch, the state did not rely on the facial recognition to identify Lynch. The officers identified Lynch as the man who sold them drugs and the analyst did not even testify in the trial. In an amicus brief the ACLU argued, ""If a witness who identified Mr. Lynch stated that other individuals in a line-up looked like the perpetrator, the state would have had to disclose that information, an well as any information indicated that the witness was uncertain or impaired when making the identification. Here, those same principles should have required the state to disclose the other photos and information on how the algorithm functions."" But the court here seems to be unconcerned with the accuracy of FACE because although it led the officers to Lynch, the officers still identified Lynch as Midnight. Two officers routinely drove around high-crime areas and posed as drug buyers looking for drugs. In this particular instant a dealer called Midnight flagged the officers down and asked if they “were good”, and then proceeded to sell them cocaine. Normally the officers would record these transactions but because Midnight approached them so suddenly they were not able to activate the recording system. One officer did snap a photo with his phone of Midnight leaning on the car. The phone used was not a modern smartphone rather an old tracfone from Walmart. The quality of phone combined with the photo being snapped while the officer pretended to be making a call, resulted in a photo that was from an oblique angle, off-axis, and blurred in places. 

The officers had no idea who Midnight was, so they emailed the photos to an analyst to identify Midnight. To begin with she looked up the nickname “midnight” in the law-enforcement database and found several people with that alias, but none who looked like the man in the photo. She then proceeded to use a facial-recognition program (FACES) that compared the photo against photos in the law-enforcement database.  

FACES could have been utilized as an open search, but she limited her search to black males and only considered Duval County booking photos. The program then returns photos almost like a photo lineup. Then the analyst makes a judgment call on whether to send that information to the detective. The program also gives you some amount of stars indicating the likelihood of a match, but the analyst was unsure how many stars were possible or how the program worked. She did remember that Lynch’s photo only had one star next to it, but it was the highest ranked match. According to an amicus brief filed by the ACLU his photo was actually just the first-listed photo in the list of possible matches but the first-listed photo is not necessarily the best match. The analyst told the officers that Lynch was a possible match to the man in the cell photo so the officers concluded that Lynch and Midnight were the same person. The Analyst did not testify at trial. 

At trial Lynch, as a pro se motion, sought to compel the state to produce the photographs of the other “Midnights” contained in the database, as well as the other photographs the facial-recognition program returned. The court denied the request concluding the photos were not relevant. Then court also revoked Lynch’s self-representation at this point and re appointed a public defender. 

Lynch argued on appeal that he should have access to the other photos because those photos could cast doubt on the State's case, and that by not providing the photos the state violated Brady v. Maryland. The court rejected this argument because lynch could not show that the other photos in the database resembled him, and that the attorney chose to not call the analyst as a witness because the analyst would only corroborate the officers testimony, and the jury convicted only after comparing the photo the officer took to Lynch himself. ACLU; Electronic Frontier Foundation FACES Facial Recognition Due Process Use of Race;  Human Programming Flaws; Unreliability/Miscalculation; Transparency; Unaware of Use of Algorithm; Lack of Remedy to prove innocence; Role of Expert Testimony"
"35","35","Malenchik v. State","","'Criminal Justice','Sentencing'","Criminal Justice; Sentencing","","","","","'LSI-R'","LSI-R","","No","","State: Indiana","","Yes","-1","","2/15/2021","2/15/2021","","","","","","","Malenchik v. State     LSI-R Criminal Justice; Sentencing  "
"51","51","Thaler v. Commissioner of Patents","The Court upheld the UKIPO's dismissal of Thaler's patents for not having followed the statutory requirements for an application that the inventor be a natural person.","'Intellectual Property'","Patent Application; Intellectual Property","'Patent Application'","Patent Act;","'AI as Inventor'","Statutory Interpretation; Algorithm as Inventor","'DABUS'","DABUS","","No","","International: England and Wales Court of Appeal (Civil Division)","08/29/2019","Yes","-1","Inactive: Decision for P","9/28/2021","10/11/2021","RA Done","Jenna","The three issues the case presented: (1) does the Patent Act regard a non-human inventor as an invenotr? (2) how has the inventor's right to grant a patent transfer to Thaler to entitle him to apply for this patent, merely as the owner of DABUS? (3) Finally, was the Comptroller required to wait the 16 months before withdrawing or can it be immediate?. The High Court judge noted that although the Patent Act of 1977 was deemed to mean inventor as a natural person, the case at hand was not about whether an AI could be an inventor but rather statutory interpretation, and that the underlying issue should be addressed on appeal.","Dr. Stephen Thaler applied for a patent in the UK, naming DABUS (Device for Autonomous Bootstrapping of Unified Sentience) as the inventor on October 17 and November 7, 2018. For the application to be considered complete, Thaler had to submit a statement of inventorship, which he submited on July 23, 2019. On August 8, the IPO replied that Thaler must submit the name of the inventor and how he derived the right from the inventor. Thaler's attorney responded with a request for a hearing on August 28, 2019. In November, IPO rejected Thaler's application, and Thaler requested an appeal hearing to a Hearing Officer, which was rejected. Thaler then unsuccessfully appealed to the Patent Court, which dismissed its appeal on September 21, 2020 because the legislation was clear that inventor was a natural person. On September 20, 2021, the Court of Appeals rejected his appeal on the basis of three issues, although two judges dissented. The judges agreed that an inventor must be a person, and that Thaler did not meet the requirements in the application. They found that the IPO did not have to conduct factual or legal investigations, but one of the three judges found that Thaler had fulfilled the requirements because the IPO is not entitled to investigate. The case is being taken to the Supreme Court.","Highest Court Opinion","9/21/2021","Thaler v. Commissioner of Patents The Court upheld the UKIPO's dismissal of Thaler's patents for not having followed the statutory requirements for an application that the inventor be a natural person. The three issues the case presented: (1) does the Patent Act regard a non-human inventor as an invenotr? (2) how has the inventor's right to grant a patent transfer to Thaler to entitle him to apply for this patent, merely as the owner of DABUS? (3) Finally, was the Comptroller required to wait the 16 months before withdrawing or can it be immediate?. The High Court judge noted that although the Patent Act of 1977 was deemed to mean inventor as a natural person, the case at hand was not about whether an AI could be an inventor but rather statutory interpretation, and that the underlying issue should be addressed on appeal. Dr. Stephen Thaler applied for a patent in the UK, naming DABUS (Device for Autonomous Bootstrapping of Unified Sentience) as the inventor on October 17 and November 7, 2018. For the application to be considered complete, Thaler had to submit a statement of inventorship, which he submited on July 23, 2019. On August 8, the IPO replied that Thaler must submit the name of the inventor and how he derived the right from the inventor. Thaler's attorney responded with a request for a hearing on August 28, 2019. In November, IPO rejected Thaler's application, and Thaler requested an appeal hearing to a Hearing Officer, which was rejected. Thaler then unsuccessfully appealed to the Patent Court, which dismissed its appeal on September 21, 2020 because the legislation was clear that inventor was a natural person. On September 20, 2021, the Court of Appeals rejected his appeal on the basis of three issues, although two judges dissented. The judges agreed that an inventor must be a person, and that Thaler did not meet the requirements in the application. They found that the IPO did not have to conduct factual or legal investigations, but one of the three judges found that Thaler had fulfilled the requirements because the IPO is not entitled to investigate. The case is being taken to the Supreme Court.  DABUS Patent Application; Intellectual Property Patent Act; Statutory Interpretation; Algorithm as Inventor"
"70","70","Matter of Nonhuman Rights Project Inc. v Stanley","Denying a writ of habeas corpus for two  chimpanzees and dismissing a petition by the NonHumanRightsProject, even with over 100 affidavits recounting cognitive ability and autonomy.","'Constitutional Law'","","'Habeas Corpus'","","'AI Adjacent'","","","","","No","","State; New York","12/1/2013","","0","Inactive: Dismissed","11/1/2021","11/5/2021","RA Done","Jenna","To support their petition that chimpanzees are autonomous and self-determining beings entitled to fundamental rights, NonHuman Rights offered offers affidavits from ""psychologists, zoologists, anthropologists, and primatologists, who have conducted in-depth research into the behavior, personality, cognition, intelligence, communication, and language skills of chimpanzees and other nonhuman primates. Each expert attests, collectively and generally, to the complex cognitive abilities of chimpanzees."" This relates to algorithms in the necessity of experts to testify about the complex abilities and autonomy of algorithms and machine learning. While the petitioners focus on DNA and similarities to humans, algorithms share other similarities to human decision making. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans.","Beginning in 2013, the NonHumanRights began petitioning for writ of habeas corpus for chimpanzees Hercules and Leo in order to transfer from Stony Brook University and move them to a sanctuary. This petition did not attack the conditions the chimpanzees were kept in, but that they were contained. The petition failed in Suffolk County for  Hercules and Leo because the judge refused to hear either side to decide the issue as there was no issue to show cause and the petitioners had a remedy to remove them to a sanctuary. Petitioner's motion to reargue was granted despite the Attorney General filing a memorandum in opposition. On May 13, 2015 petitioners filed a demand, oral argument was held on May 27, 2015. The court determined that Hercules and Leo do not possess attributes sufficient to establish legal personhood. The court notes that the writ of habeas corpus is typcially brought in criminal rather than civil suits but the judge acknowledges that CPLR 7002 (b) provides that a habeas petition must be made to ""(1) the supreme court in the judicial district in which the person is detained; or . . . (3) any justice of the supreme court."" The court relies on statutory interpretation and dictionary definition of detention in a ""state institution"" and that in turn it is irrelevant that the instiuttion is the State University, and thus does not require a transfer of venue. Respondents claim that Suffolk County declining to hear Article 70 arguments barred petitioners ""from filing another order to show cause seeking the same relief from a different justice"" however the court notes that there must be final judgement before being barred as res judicata. Getting to legal personhood, the judge acknoweldges this term is not defined and that legal personhood does not have to be synonymous with human. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans. Personhood has evolved since the constiuttion only considered white, land owning males, and that while animals are beginnign to be treated as more than property, they are ultimately quasi persons owed some rights and not others. However, the court in Lavery held that a failure to establish a common law relief nature the court does not have to grant writ. The judge ultimately concluded even without being bound by Lavery, the writ of habeas corpus is ""best decided, if not by the legislature, then by the Court of Appeals, given its role in setting state policy.""","Judgement","7/29/2015","Matter of Nonhuman Rights Project Inc. v Stanley Denying a writ of habeas corpus for two  chimpanzees and dismissing a petition by the NonHumanRightsProject, even with over 100 affidavits recounting cognitive ability and autonomy. To support their petition that chimpanzees are autonomous and self-determining beings entitled to fundamental rights, NonHuman Rights offered offers affidavits from ""psychologists, zoologists, anthropologists, and primatologists, who have conducted in-depth research into the behavior, personality, cognition, intelligence, communication, and language skills of chimpanzees and other nonhuman primates. Each expert attests, collectively and generally, to the complex cognitive abilities of chimpanzees."" This relates to algorithms in the necessity of experts to testify about the complex abilities and autonomy of algorithms and machine learning. While the petitioners focus on DNA and similarities to humans, algorithms share other similarities to human decision making. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans. Beginning in 2013, the NonHumanRights began petitioning for writ of habeas corpus for chimpanzees Hercules and Leo in order to transfer from Stony Brook University and move them to a sanctuary. This petition did not attack the conditions the chimpanzees were kept in, but that they were contained. The petition failed in Suffolk County for  Hercules and Leo because the judge refused to hear either side to decide the issue as there was no issue to show cause and the petitioners had a remedy to remove them to a sanctuary. Petitioner's motion to reargue was granted despite the Attorney General filing a memorandum in opposition. On May 13, 2015 petitioners filed a demand, oral argument was held on May 27, 2015. The court determined that Hercules and Leo do not possess attributes sufficient to establish legal personhood. The court notes that the writ of habeas corpus is typcially brought in criminal rather than civil suits but the judge acknowledges that CPLR 7002 (b) provides that a habeas petition must be made to ""(1) the supreme court in the judicial district in which the person is detained; or . . . (3) any justice of the supreme court."" The court relies on statutory interpretation and dictionary definition of detention in a ""state institution"" and that in turn it is irrelevant that the instiuttion is the State University, and thus does not require a transfer of venue. Respondents claim that Suffolk County declining to hear Article 70 arguments barred petitioners ""from filing another order to show cause seeking the same relief from a different justice"" however the court notes that there must be final judgement before being barred as res judicata. Getting to legal personhood, the judge acknoweldges this term is not defined and that legal personhood does not have to be synonymous with human. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans. Personhood has evolved since the constiuttion only considered white, land owning males, and that while animals are beginnign to be treated as more than property, they are ultimately quasi persons owed some rights and not others. However, the court in Lavery held that a failure to establish a common law relief nature the court does not have to grant writ. The judge ultimately concluded even without being bound by Lavery, the writ of habeas corpus is ""best decided, if not by the legislature, then by the Court of Appeals, given its role in setting state policy.""     "
"87","87","Getty Images (US), Inc. v. Stability AI, Ltd.","Leading group of stock image companies sues developer of generative AI tool Stable Diffusion for copyright infringement, database right infringement, and trademark infringement","'Generative AI'","Generative AI","'Copyright Infringement'","Copyright Infringement","'Copyright Infringement'","Copyright Infringement","'Stable Diffusion'","Stable Diffusion","'No'","","Getty Images (US) Inc.; Getty Images International U.C.; Getty Images (UK) Limited; Getty Images Devco UK Limited; IStockphoto LP; Thomas M. Barwick, Inc.; Stability AI, Ltd.","International - UK - High Court of Justice - Chancery Division - Intellectual Property List","01/16/2023","","0","Active","7/21/2023","7/21/2023","","Bob","","","Order of Master sealed and dated 5-07-23, sent to defendant's solicitors to serve","7/6/2023","Getty Images (US), Inc. v. Stability AI, Ltd. Leading group of stock image companies sues developer of generative AI tool Stable Diffusion for copyright infringement, database right infringement, and trademark infringement   Getty Images (US) Inc.; Getty Images International U.C.; Getty Images (UK) Limited; Getty Images Devco UK Limited; IStockphoto LP; Thomas M. Barwick, Inc.; Stability AI, Ltd. Stable Diffusion Generative AI Copyright Infringement Copyright Infringement"
"15","15","Ark. Dep’t of Human Servs. v. Ledgerwood","Low income plaintiffs with physical disabilities sued when the Department of Health Services replaced their nurse assessment questionaire ArPath to determine hours of care with Resource Utilization Groups, drastically reducing attendant-care hours allotted per patient, successfully challenged this rulemaking under the APA and court unanimously granted a permanent injunction","'Disabilities Benefits','Health','Public Benefits'","Health; Disabilities Benefits; Public Benefits","'Administrative Procedure Act','Permanent Injunction','Preliminary Injunction'","Adminstrative Procedure Act; Preliminary Injunction; Permanent Injunction","'Justiciability','Lack of Remedy','Transparency in Change of Algorithm','Transparency/Trade Secrecy'","Transparency in Change of Algorithm; Trade Secrecy; Justiciability; Lack of Remedy","'RUGs'","RUGs","","No","LegalAid","State: Arkansas","1/26/2017","Yes","-1","Inactive: Judgement for P","2/7/2021","3/3/2021","RA Done","Jenna","For 17 years Arkansas used a questionnaire called ArPath, where a professional nurse used their discretion to assess a patient's Attendant Care Hours. The nurse would assess the patient with 286 questions about the patient's ""functional abilities, medical conditions, mental status, and caregiving arrangements."" The nurse used professional judgement and discretion to determine the number of care hours needed. 

In 2016, Arkansas switched without notice to a computer algorithm ArChoice, with the nurse no longer having discretion for hours as they are allotted based on the patient's Resource Utilization Group. The use of ArChoice cut attendant hours for 47% of patients. 

The circuit court granted an injunction against the state continuing to use this algorithm. 

DHS then purposely promulgated an Emergency Rule using the exact RUGs it was enjoined from using, however because it allowed nurses to use ""modest"" discretion to adjust the hours the Supreme Court reversed the circuit court's finding of contempt against using the emergency algorithm.

A non-judicial development is the state legislature holding DHS accountable by ordering numerous reviews of the algorithm.","The Arkansas Department of Health Services had calculated Home and Community Based Services (HCBS) through the discretion of a nurse assessing patients with a questionnaire. In 2014 and 2015, DHS began meeting with Medicaid service providers to discuss changes to the program including an increase in hourly rates but did not include any patient beneficiaries of the program in these discussions. On August 23, 2015, DHS proposed new rulemaking to go into effect on January 1, 2016, with the final rule submitted to DHS on December 17, 2015. The only notification that patients received of any change was on December 1, 2015 when patients were notified of the change to ArChoice with an explicit statement ""Your services and provider will remain the same way.""

Plaintiffs sued in 2016 for a temporary restraining order and a permanent injunction, and brought an ultra vires claim, declaratory judgement, and injury by an agency under Arkansas law. Plaintiffs maintained that the proposed rule and final rule did not indicate a change in calculation proposed or adopted, did not define the 23 tiers of the RUGs, did not specify criteria that the RUGs use to calculate hours and what each tier's hours would be, did not include the algorithm for the RUGs, or describe how the algorithms work in sufficient detail, or provide any data or studies on RUGs that the agency ""relied on"" when switching to this system . This algorithm ArChoice calculated a Patient-Centered Service Plan by placing each patient into one of 23 Resource Utilization Groups, which cut patient attendant hours for 47%.

This was not a class action lawsuit.

The circuit court granted the temporary restraining order for the plaintiffs on February 17, finding the plaintiffs met their burden for likelihood of success on the merits, irreparable injury, and in the public interest. This TRO enjoined DHS from continuing to use this algorithm for the Home and Community Based Services, 

DHS appealed the TRO to the Supreme Court of Arkansas, arguing that the circuit court abused its discretion finding irreparable harm and likelihood of success on the merits. 

The Supreme Court affirmed the February TRO, finding that the circuit court did not abuse its discretion as it agreed the plaintiffs met their burden, noting that the irreparable harm warrants the futility exception of exhaustion of remedies in Arkansas state law.

DHS further appealed the Circuit Court finding it in contempt for not complying with the temporary restraining order, which the Supreme Court reversed but dismissed as moot. The dissent did not agree with the reversal of contempt, as DHS purposely promulgated an emergency rule using the exact RUGs it was enjoined from using.","Supreme Court Dismissed Appeal","4/11/2019","Ark. Dep’t of Human Servs. v. Ledgerwood Low income plaintiffs with physical disabilities sued when the Department of Health Services replaced their nurse assessment questionaire ArPath to determine hours of care with Resource Utilization Groups, drastically reducing attendant-care hours allotted per patient, successfully challenged this rulemaking under the APA and court unanimously granted a permanent injunction For 17 years Arkansas used a questionnaire called ArPath, where a professional nurse used their discretion to assess a patient's Attendant Care Hours. The nurse would assess the patient with 286 questions about the patient's ""functional abilities, medical conditions, mental status, and caregiving arrangements."" The nurse used professional judgement and discretion to determine the number of care hours needed. 

In 2016, Arkansas switched without notice to a computer algorithm ArChoice, with the nurse no longer having discretion for hours as they are allotted based on the patient's Resource Utilization Group. The use of ArChoice cut attendant hours for 47% of patients. 

The circuit court granted an injunction against the state continuing to use this algorithm. 

DHS then purposely promulgated an Emergency Rule using the exact RUGs it was enjoined from using, however because it allowed nurses to use ""modest"" discretion to adjust the hours the Supreme Court reversed the circuit court's finding of contempt against using the emergency algorithm.

A non-judicial development is the state legislature holding DHS accountable by ordering numerous reviews of the algorithm. The Arkansas Department of Health Services had calculated Home and Community Based Services (HCBS) through the discretion of a nurse assessing patients with a questionnaire. In 2014 and 2015, DHS began meeting with Medicaid service providers to discuss changes to the program including an increase in hourly rates but did not include any patient beneficiaries of the program in these discussions. On August 23, 2015, DHS proposed new rulemaking to go into effect on January 1, 2016, with the final rule submitted to DHS on December 17, 2015. The only notification that patients received of any change was on December 1, 2015 when patients were notified of the change to ArChoice with an explicit statement ""Your services and provider will remain the same way.""

Plaintiffs sued in 2016 for a temporary restraining order and a permanent injunction, and brought an ultra vires claim, declaratory judgement, and injury by an agency under Arkansas law. Plaintiffs maintained that the proposed rule and final rule did not indicate a change in calculation proposed or adopted, did not define the 23 tiers of the RUGs, did not specify criteria that the RUGs use to calculate hours and what each tier's hours would be, did not include the algorithm for the RUGs, or describe how the algorithms work in sufficient detail, or provide any data or studies on RUGs that the agency ""relied on"" when switching to this system . This algorithm ArChoice calculated a Patient-Centered Service Plan by placing each patient into one of 23 Resource Utilization Groups, which cut patient attendant hours for 47%.

This was not a class action lawsuit.

The circuit court granted the temporary restraining order for the plaintiffs on February 17, finding the plaintiffs met their burden for likelihood of success on the merits, irreparable injury, and in the public interest. This TRO enjoined DHS from continuing to use this algorithm for the Home and Community Based Services, 

DHS appealed the TRO to the Supreme Court of Arkansas, arguing that the circuit court abused its discretion finding irreparable harm and likelihood of success on the merits. 

The Supreme Court affirmed the February TRO, finding that the circuit court did not abuse its discretion as it agreed the plaintiffs met their burden, noting that the irreparable harm warrants the futility exception of exhaustion of remedies in Arkansas state law.

DHS further appealed the Circuit Court finding it in contempt for not complying with the temporary restraining order, which the Supreme Court reversed but dismissed as moot. The dissent did not agree with the reversal of contempt, as DHS purposely promulgated an emergency rule using the exact RUGs it was enjoined from using. LegalAid RUGs Health; Disabilities Benefits; Public Benefits Adminstrative Procedure Act; Preliminary Injunction; Permanent Injunction Transparency in Change of Algorithm; Trade Secrecy; Justiciability; Lack of Remedy"
"31","31","Broccolino v. Clearview AI, Inc.","","'Facial Recognition'","Facial Recognition","","","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal:  US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","3/12/2020","","0","Active","2/15/2021","5/1/2022","","","Unlike the other complaints, Broccolino's complaint noted that Clearview was used in the Middle East and Russia, and that Google and Facebook had sent notices that Clearview's conduct violated their terms of use by not seeking consent. However, it did not go further with these issues and only filed its cause of action under BIPA.

Broccolino's complaint also notes that Clearview violated BIPA by not writing and making available a retention schedule for permanently destroying biometric identifiers and information.","Plaintiff filed complaint on March 13, 2020 alleging that Clearview violated BIPA. Plaintiff sent Clearview a letter requesting confirmation that her likeness was in the database on March 3, 2020 through the ""appropriate channels"" of its website with no response. 

This is the second case that the Judge in Calderon described saying it was better suited for Illinois on April 15, included in Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA. 

Broccolino was ordered to respond to Mutnick's Motion to Intervene, which was denied on May 29. 

On September 9 with now six cases before her, Judge McMahon stayed all six SDNY cases until MDL was worked out.","MDL Transfer Out","1/12/2021","Broccolino v. Clearview AI, Inc.  Unlike the other complaints, Broccolino's complaint noted that Clearview was used in the Middle East and Russia, and that Google and Facebook had sent notices that Clearview's conduct violated their terms of use by not seeking consent. However, it did not go further with these issues and only filed its cause of action under BIPA.

Broccolino's complaint also notes that Clearview violated BIPA by not writing and making available a retention schedule for permanently destroying biometric identifiers and information. Plaintiff filed complaint on March 13, 2020 alleging that Clearview violated BIPA. Plaintiff sent Clearview a letter requesting confirmation that her likeness was in the database on March 3, 2020 through the ""appropriate channels"" of its website with no response. 

This is the second case that the Judge in Calderon described saying it was better suited for Illinois on April 15, included in Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA. 

Broccolino was ordered to respond to Mutnick's Motion to Intervene, which was denied on May 29. 

On September 9 with now six cases before her, Judge McMahon stayed all six SDNY cases until MDL was worked out.  Clearview Facial Recognition  Privacy"
"47","47","CCC Info. Servs. Inc. v. Tractable Inc.","Trial court denied defendant Tractable's motion to compel arbitration after Plaintiff CCC Information Services Inc. accused Tractable employees committed fraud to access CCC Info Services' proprietary software and then used this data to Tractable's advantage.","'Agency','Intellectual Property','Licensing Agreement'","Licensing Agreement; Agency","'Breach of Contract','Trademark infringement','Arbitration'","Breach of Contract; Arbitration","'Infringement','Transparency/Trade Secrecy'","","","","","No","","Federal: US Dist. Ct. N.D. Illinois","11/26/2018","Yes","-1","Active","3/12/2021","5/4/2022","","Jenna","By denying the motion to compel arbitration, this case about infringing the algorithm software will go forward.","CCC Info Services uses an algorithm and database to calculate vehicle damage estimates, which it then licenses to independent automobile appraisers. 

Plaintiff CCC Information Services brought suit, claiming that Tractable fraudulently obtained access to CCC's algorithm through Tractable employees pretending to be customers and entering into a licensing agreement with an arbitration clause, and that Tractable then sought to reverse engineer the algorithm and recreate it. Plaintiff brought this action under the Computer Fraud and Abuse Act, the The Defend Trade Secrets Act Of 2016, The Illinois Trade Secrets Act Of 2016, Illinois Deceptive Trade Practices Act, trademark infringement, right to chattels, common fraud, unjust enrichment, and declaratory relief. 

The relief included destroying or returning any data and material relating to the platform and algorithm.

The court denied Tractable's motion to compel arbitration and stay the proceedings in May 2019. The court's reasoning is that non-parties to contracts cannot compel arbitration clauses.

The court held a joint status report in March 2021, of which it is not published yet where the case will lead.","Joint Status Report Status","12/21/2021","CCC Info. Servs. Inc. v. Tractable Inc. Trial court denied defendant Tractable's motion to compel arbitration after Plaintiff CCC Information Services Inc. accused Tractable employees committed fraud to access CCC Info Services' proprietary software and then used this data to Tractable's advantage. By denying the motion to compel arbitration, this case about infringing the algorithm software will go forward. CCC Info Services uses an algorithm and database to calculate vehicle damage estimates, which it then licenses to independent automobile appraisers. 

Plaintiff CCC Information Services brought suit, claiming that Tractable fraudulently obtained access to CCC's algorithm through Tractable employees pretending to be customers and entering into a licensing agreement with an arbitration clause, and that Tractable then sought to reverse engineer the algorithm and recreate it. Plaintiff brought this action under the Computer Fraud and Abuse Act, the The Defend Trade Secrets Act Of 2016, The Illinois Trade Secrets Act Of 2016, Illinois Deceptive Trade Practices Act, trademark infringement, right to chattels, common fraud, unjust enrichment, and declaratory relief. 

The relief included destroying or returning any data and material relating to the platform and algorithm.

The court denied Tractable's motion to compel arbitration and stay the proceedings in May 2019. The court's reasoning is that non-parties to contracts cannot compel arbitration clauses.

The court held a joint status report in March 2021, of which it is not published yet where the case will lead.   Licensing Agreement; Agency Breach of Contract; Arbitration "
"66","66","People v. Superior Court (Chubbs)","Similar to H.K. and Wakefiled, the confrontation clause is not violated when the defendant does not have access to the source code of the DNA genotyping algorithm.","'Criminal Justice'","","'Due Process'","","'Confrontation Clause'","","","","","","","State: Los Angeles County Super. Ct.","11/18/2012","","0","Inactive","10/28/2021","10/28/2021","","","","","","","People v. Superior Court (Chubbs) Similar to H.K. and Wakefiled, the confrontation clause is not violated when the defendant does not have access to the source code of the DNA genotyping algorithm.       "
"83","83","Gonzalez v. Google, LLC","Family of Nohemi Gonzalez, a victim in the 2015 ISIS attacks in Paris, sued Google and YouTube under the Anti-Terrorism Act. Gonzalez asserts that Google should not be eligible for immunity under Section 230 because YouTube recommended ISIS videos to users and collected ad payments from said videos.

Arguments heard by Supreme Court on 2/21/2023.","'Social Media','Terrorism'","Social Media, Terrorism","'Antiterrorism Act'","Antiterrorism Act","'Accountability'","Accountability","","","","","Google; YouTube","Ninth Circuit","06/14/2016","","0","Active","2/28/2023","2/28/2023","Heard at SCOTUS 2/21/2023","Sydney Huppert","Nohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  Gonzalez's family argues that YouTube, and YouTube's owner Google, lost Section 230 immunity because YouTube recommended ISIS content to others.  They also argue that the Anti-Terrorism Act (ATA) circumvents Section 230 immunity and that Google and YouTube provided knowing assistance to ISIS because they were aware that ISIS videos on their platform were being used for propaganda and that ISIS had monetized their videos on YouTube.","Nohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  The next day, ISIS claimed responsibility for the Paris attacks via a written statement and a video posted to YouTube. Gonzalez's family sued YouTube and Google, YouTube's owner, arguing that YouTube should be considered the ""publisher"" of the videos because YouTube had recommended ISIS videos to other users, allowing ISIS propaganda to reach more people.  Additionally, they argue that YouTube and Google are liable under the Anti-Terrorism Statute (ATA) because YouTube and Google knowingly allowed monetization of ISIS videos, allowing ISIS to profit from their YouTube videos.  Plaintiffs also argue that the ATA bypasses Section 230 immunity.

The Northern District of California ruled that Section 230 immunity still applied to videos recommended by YouTube because the videos were uploaded by a user.  The District Court also ruled that the ATA did not bypass Section 230; rather, the laws should be read as cooperative, and Section 230 still protected a internet service provider whose service was used by a terrorist group to upload content.  Gonzalez appealed to the Ninth Circuit.

The Ninth Circuit upheld the District Court's decision. 

Gonzalez petitioned for certiorari on 04/06/2022. The Supreme Court granted cert on 10/03/2022.

The Supreme Court heard oral arguments for the case on 02/21/2023.","Oral arguments heard by Supreme Court of the United States on 02/21/2023","2/21/2023","Gonzalez v. Google, LLC Family of Nohemi Gonzalez, a victim in the 2015 ISIS attacks in Paris, sued Google and YouTube under the Anti-Terrorism Act. Gonzalez asserts that Google should not be eligible for immunity under Section 230 because YouTube recommended ISIS videos to users and collected ad payments from said videos.

Arguments heard by Supreme Court on 2/21/2023. Nohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  Gonzalez's family argues that YouTube, and YouTube's owner Google, lost Section 230 immunity because YouTube recommended ISIS content to others.  They also argue that the Anti-Terrorism Act (ATA) circumvents Section 230 immunity and that Google and YouTube provided knowing assistance to ISIS because they were aware that ISIS videos on their platform were being used for propaganda and that ISIS had monetized their videos on YouTube. Nohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  The next day, ISIS claimed responsibility for the Paris attacks via a written statement and a video posted to YouTube. Gonzalez's family sued YouTube and Google, YouTube's owner, arguing that YouTube should be considered the ""publisher"" of the videos because YouTube had recommended ISIS videos to other users, allowing ISIS propaganda to reach more people.  Additionally, they argue that YouTube and Google are liable under the Anti-Terrorism Statute (ATA) because YouTube and Google knowingly allowed monetization of ISIS videos, allowing ISIS to profit from their YouTube videos.  Plaintiffs also argue that the ATA bypasses Section 230 immunity.

The Northern District of California ruled that Section 230 immunity still applied to videos recommended by YouTube because the videos were uploaded by a user.  The District Court also ruled that the ATA did not bypass Section 230; rather, the laws should be read as cooperative, and Section 230 still protected a internet service provider whose service was used by a terrorist group to upload content.  Gonzalez appealed to the Ninth Circuit.

The Ninth Circuit upheld the District Court's decision. 

Gonzalez petitioned for certiorari on 04/06/2022. The Supreme Court granted cert on 10/03/2022.

The Supreme Court heard oral arguments for the case on 02/21/2023. Google; YouTube  Social Media, Terrorism Antiterrorism Act Accountability"
"4","4","Berliner v. Nassau County","Nassau residents brought a class action against the county for an inaccurate and incomplete property tax reassessment algorithm as unfair and unconstitutional, granted a preliminary injunction against the county using this reassessment for 2020 real property taxes, almost settling but for the question of legal fees","'Constitutional Law','Real Property','Tax'","Real Property; Tax","'42 USC 1983','Due Process','Equal Protection','Preliminary Injunction'","42 USC 1983; Equal Protection; Due Process; Preliminary Injunction","'Lack of Human Review','Notice','Transparency in Change of Algorithm','Underperformance'","Underperformance;  Transparency in Change of Algorithm; Notice; Lack of Remedy","","","","Yes","","State: New York-Nassau County","4/30/2019","Yes","-1","Inactive","2/1/2021","5/1/2022","Satisfaction of judgment filed Mar 2021; no further documents filed","Sydney","Berliner filed this class action to get disclosure of the county's property tax reassessment algorithm. The county discontinued its argument of trade secrecy and produced the algorithm, leading residents to challenge the legality because the algorithm had missing files that would not let the code run effectively. 
A New York lower court ruled that the class action of Nassau County residents can move forward, the ruling resulted in the discontinuation of the Reassessment algorithm in question and reverting to the previous market value and tax levels for the 2020 tax assessment. Plaintiffs allege that ""the reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms.""","In March 2018, Nassau County legislature approved reassessments of real property tax for the 2020-2021 tax season using. The algorithm used data of recent sales of comparable houses to produce a predictive model, then multiplying by a neighborhood factor of one of the 324 neighborhoods in the county to assess property value, with neighborhood factors ranging from .6 to 1.9. 

In November 2018, the residents were notified of their preliminary market values that would roll out in April 2020, with 85,000 of the 400,000 houses needing reassessment before April 2020. The properties lowered in value did not have their tax accordingly lowered.

In the complaint filed in April 2019, the plaintiffs allege: the countywide reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms."" The underassessed homes would see their taxes increase, and over assessed homes would challenge the valuation.

During this time in summer of 2020, a second lawsuit by Sean M. McCarthy is dismissed with ID Number 607458 / 2020.

Judgement on Plaintiff's October 1, 2020 motion for attorney's fees as part of the settlement agreement, ordered on December 1, corrected on December 22 and entered on December 28 awarding fees and costs of $300,000 to Plaintiffs.

Nassau County Appeals to the Appellate Division of the Supreme Court of the State of New York, did the court err in finding the plaintiffs had established entitlement to award?

In March 2021, plaintiffs filed certificate for satisfaction of judgment.

In April 2021, plaintiffs brought issue with Nassau County sending out fliers that stated ""ALERT NASSAU COUNTY DID NOT RAISE TAXES"" and other statements relating to the lawsuit.","Plaintiffs filed satisfaction of judgment","3/8/2021","Berliner v. Nassau County Nassau residents brought a class action against the county for an inaccurate and incomplete property tax reassessment algorithm as unfair and unconstitutional, granted a preliminary injunction against the county using this reassessment for 2020 real property taxes, almost settling but for the question of legal fees Berliner filed this class action to get disclosure of the county's property tax reassessment algorithm. The county discontinued its argument of trade secrecy and produced the algorithm, leading residents to challenge the legality because the algorithm had missing files that would not let the code run effectively. 
A New York lower court ruled that the class action of Nassau County residents can move forward, the ruling resulted in the discontinuation of the Reassessment algorithm in question and reverting to the previous market value and tax levels for the 2020 tax assessment. Plaintiffs allege that ""the reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms."" In March 2018, Nassau County legislature approved reassessments of real property tax for the 2020-2021 tax season using. The algorithm used data of recent sales of comparable houses to produce a predictive model, then multiplying by a neighborhood factor of one of the 324 neighborhoods in the county to assess property value, with neighborhood factors ranging from .6 to 1.9. 

In November 2018, the residents were notified of their preliminary market values that would roll out in April 2020, with 85,000 of the 400,000 houses needing reassessment before April 2020. The properties lowered in value did not have their tax accordingly lowered.

In the complaint filed in April 2019, the plaintiffs allege: the countywide reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms."" The underassessed homes would see their taxes increase, and over assessed homes would challenge the valuation.

During this time in summer of 2020, a second lawsuit by Sean M. McCarthy is dismissed with ID Number 607458 / 2020.

Judgement on Plaintiff's October 1, 2020 motion for attorney's fees as part of the settlement agreement, ordered on December 1, corrected on December 22 and entered on December 28 awarding fees and costs of $300,000 to Plaintiffs.

Nassau County Appeals to the Appellate Division of the Supreme Court of the State of New York, did the court err in finding the plaintiffs had established entitlement to award?

In March 2021, plaintiffs filed certificate for satisfaction of judgment.

In April 2021, plaintiffs brought issue with Nassau County sending out fliers that stated ""ALERT NASSAU COUNTY DID NOT RAISE TAXES"" and other statements relating to the lawsuit.   Real Property; Tax 42 USC 1983; Equal Protection; Due Process; Preliminary Injunction Underperformance;  Transparency in Change of Algorithm; Notice; Lack of Remedy"
"20","20","Barry v. Lyon","Sixth Circuit affirmed reversing the automatic disqualification and inadequate notice of the Michigan's Department of Health and Human Services when they employed an algorithm that disqualified from food assistant benefits anyone with an outstanding felony warrant, including inaccurately accusing thousands","'Criminal Justice','Food Assistance'","Food Assistance; Criminal Justice","'Due Process','Supplemental Nutrition Assistance Program'","Due Process; Supplemental Nutrition Assistance Program","'Lack of Human Review','Lack of Remedy to prove innocence','Unreliability/Miscalculationns'","Unreliability/Miscalculation; Lack of Remedy to Prove Innocence; Lack of Human Review","","","","Yes","ACLU","Federal: US Dist. Ct. E.D. Michigan","7/1/2013","Yes","-1","Inactive","2/11/2021","2/13/2021","","","","","Sixth Circuit Court of Appeals Affirm District Court; Remand to District Court to enforce injunction","9/25/2016","Barry v. Lyon Sixth Circuit affirmed reversing the automatic disqualification and inadequate notice of the Michigan's Department of Health and Human Services when they employed an algorithm that disqualified from food assistant benefits anyone with an outstanding felony warrant, including inaccurately accusing thousands   ACLU  Food Assistance; Criminal Justice Due Process; Supplemental Nutrition Assistance Program Unreliability/Miscalculation; Lack of Remedy to Prove Innocence; Lack of Human Review"
"36","36","Vermont v. Clearview AI, Inc.","Vermont Attorney General brought three Vermonst consumer protection claims: unfair and deceptive practices by collection photographs and making misrepresenations about their program and fraudelently acquiring brokered personal information against Cleaview, and it survived a motion to dismiss where Clearview argued 1A, 230, Standing and Venue in M2D","'Facial Recognition'","Facial Recognition","'UDAP'","UDAP","'Law Enforcement','Privacy'","Privacy; Law Enforcement;","'Clearview'","Clearview","","No","","State: Vermont Sup. Ct. (Chittenden Unit)","3/1/2020","Yes","-1","Active","2/15/2021","4/1/2021","RA Done; Check for New Activity","Jenna","This case survived a motion to dismiss in the lower court.

The court allowed the Vermont AG's claim that Clearview's actions qualify under the Vermont Consumer Protection Act for an unfairness claim: immoral, unethical, oppressive or unscrupulous. Additionally, the court did not dismiss the claim relating to substantial injury by the unwanted surveillance and marketing Clearview to law enforcement.","Vermont's Attorney General brought three claims against Clearview: 1. Clearview's privacy policy misrepresents when it says it does not process data it does not have permission for, 2. unfair and deceptive to scan thousands of pictures from social media without permission, and 3. web scraping social media for images was fraudulent acquisition under Vermont State Law.   

Ruling on Clearview's motion to dismiss, the superior court struck down two of Vermont's three claims: 1. misrepresentation because no way to verify at the time it was made, and 2. the web scraping was not fraudulent/misrepresentation, and made a comparison to larceny. The court was not convinced by Clearview's arguments for standing, venue, Section 230, or the first amendment. The court allowed the claim of statements about Clearview's use of social media pictures being deceptive to continue. Clearview deceived consumers about the ability to opt out of Clearview's database, the purpose and use of the information (being for law enforcement and not personal purposes), that it had success in assisting in law enforcement investigations, match accuracy success, and removing information based on geography.","Court ruling on motion to dismiss","9/20/2020","Vermont v. Clearview AI, Inc. Vermont Attorney General brought three Vermonst consumer protection claims: unfair and deceptive practices by collection photographs and making misrepresenations about their program and fraudelently acquiring brokered personal information against Cleaview, and it survived a motion to dismiss where Clearview argued 1A, 230, Standing and Venue in M2D This case survived a motion to dismiss in the lower court.

The court allowed the Vermont AG's claim that Clearview's actions qualify under the Vermont Consumer Protection Act for an unfairness claim: immoral, unethical, oppressive or unscrupulous. Additionally, the court did not dismiss the claim relating to substantial injury by the unwanted surveillance and marketing Clearview to law enforcement. Vermont's Attorney General brought three claims against Clearview: 1. Clearview's privacy policy misrepresents when it says it does not process data it does not have permission for, 2. unfair and deceptive to scan thousands of pictures from social media without permission, and 3. web scraping social media for images was fraudulent acquisition under Vermont State Law.   

Ruling on Clearview's motion to dismiss, the superior court struck down two of Vermont's three claims: 1. misrepresentation because no way to verify at the time it was made, and 2. the web scraping was not fraudulent/misrepresentation, and made a comparison to larceny. The court was not convinced by Clearview's arguments for standing, venue, Section 230, or the first amendment. The court allowed the claim of statements about Clearview's use of social media pictures being deceptive to continue. Clearview deceived consumers about the ability to opt out of Clearview's database, the purpose and use of the information (being for law enforcement and not personal purposes), that it had success in assisting in law enforcement investigations, match accuracy success, and removing information based on geography.  Clearview Facial Recognition UDAP Privacy; Law Enforcement;"
"52","52","IBM Corp. v. Indiana","Algorithm-adjacent, this case involves electronic automation including statistical methods to determine eligibility for Indiana benefits programs, and after four appeals the Supreme Court ruled for the State who terminated a billion dollar contract with IBM after three years of performance issues.","'Disabilities Benefits','Health'","Public Benefits; Electronic Automation; Government; Health","'Breach of Contract','Performance Metrics'","Breach of Contract; Performance Metrics","'Lack of Remedy','Underperformance','Unreliability/Miscalculationns','AI Adjacent'","","","","","No","","State: Indiana","","Yes","0","Active","9/28/2021","10/11/2021","RA Done; Check for New Activity","Jenna","The electronic automation of Indiana's benefits selection program. The dissent of the March 2019 Supreme Court opinion disagreed that the damages awarded to the state largely to fund the ""hybrid"" system the State eventually implemented instead of IBM's modernization, viewing the implementation as not direct damages because IBM was only required to implement modernization and not hybrid as well.","In 2006, Indiana contracted with IBM to modernize the welfare system with electronic automation. The billion-dollar contract was for 10 years. After three years, Indiana terminated the contract for performance issues. Both IBM and Indiana filed lawsuits about this terminated contract, and the issue was whether Indiana could terminate the ten year contract over performance issues. The Marion County Superior Court consolidated the case before them in 2010. The State separately appealed to the Supreme Court to avoid a deposition by Governor Daniels. The trial court granted partial summary judgement for assignment fees to IBM, and then in 2012 found no material breach by IBM. The first appeal, filed by both parties, saw the Supreme Court reverse the material breach finding and reverse other damages except the assignment fees. The case remanded to the trial court for damages calculations, which was appealed to the Supreme Court by both the State and IBM in calculating pre- and post-judgment damages. In 2017, the trial court rejected IBM's motion for post-judgement interest on the 2012 partial summary judgment award for assignment damages, but granted the State's motion for post-judgement interest damages. The rationale was to ""compensate[] plaintiffs for the loss of money that has been determined to be have rightfully belonged to them."" IBM appealed and in 2019 the Supreme Court affirmed the trial court and Court of Appeals' calculation of damages for State. The State filed a Verified Motion to Enter Final Judgement, and the trial court denied this motion in March of 2020. The State appealed, but the Supreme Court affirmed the proper denial.","Court denied state to receive more money from IBM","12/9/2020","IBM Corp. v. Indiana Algorithm-adjacent, this case involves electronic automation including statistical methods to determine eligibility for Indiana benefits programs, and after four appeals the Supreme Court ruled for the State who terminated a billion dollar contract with IBM after three years of performance issues. The electronic automation of Indiana's benefits selection program. The dissent of the March 2019 Supreme Court opinion disagreed that the damages awarded to the state largely to fund the ""hybrid"" system the State eventually implemented instead of IBM's modernization, viewing the implementation as not direct damages because IBM was only required to implement modernization and not hybrid as well. In 2006, Indiana contracted with IBM to modernize the welfare system with electronic automation. The billion-dollar contract was for 10 years. After three years, Indiana terminated the contract for performance issues. Both IBM and Indiana filed lawsuits about this terminated contract, and the issue was whether Indiana could terminate the ten year contract over performance issues. The Marion County Superior Court consolidated the case before them in 2010. The State separately appealed to the Supreme Court to avoid a deposition by Governor Daniels. The trial court granted partial summary judgement for assignment fees to IBM, and then in 2012 found no material breach by IBM. The first appeal, filed by both parties, saw the Supreme Court reverse the material breach finding and reverse other damages except the assignment fees. The case remanded to the trial court for damages calculations, which was appealed to the Supreme Court by both the State and IBM in calculating pre- and post-judgment damages. In 2017, the trial court rejected IBM's motion for post-judgement interest on the 2012 partial summary judgment award for assignment damages, but granted the State's motion for post-judgement interest damages. The rationale was to ""compensate[] plaintiffs for the loss of money that has been determined to be have rightfully belonged to them."" IBM appealed and in 2019 the Supreme Court affirmed the trial court and Court of Appeals' calculation of damages for State. The State filed a Verified Motion to Enter Final Judgement, and the trial court denied this motion in March of 2020. The State appealed, but the Supreme Court affirmed the proper denial.   Public Benefits; Electronic Automation; Government; Health Breach of Contract; Performance Metrics "
"71","71","Rana v. Amazon et al","A lawsuit against Amazon for vicarious liability of a delivery truck driver Williams, the contracting delivery company Harper Logistics and the delivery business’s insurance provider, Old Republic Insurance Co. for a car crash by Amazon Delivery Driver that left plainitff paralyzed.","'Personal Injury'","","'Negligence','Vicarious Liability'","","'Misuse of AI'","","","","","No","Amazon","State: Georgia","06/2021","No","0","Active","11/15/2021","11/17/2021","RA Done; Check for New Updates","Jenna","Although have been over 100 lawsuits filed against Amazon Logistics in the last year for crashes by delivery vans, this case is the most severe in its argument of control by Amazon rather than the contracted delivery companies and insurance providers. The outcome of this case will influence future cases against Amazon, and could result in the public exposure of Amazon's algorithms. By demonstrating managerial ownership of Harper Logistics rather than Amazon merely being a customer, plaintiff hopes to show Amazon's algorithm controlled the driver route and speed, and therefore is vicariously liable for negligently making drivers work unreasonable shifts.","On March 15, 2021, plaintiff was in a car accident in Atlanta when an Amazon Delivery truck hit their car. Plaintiff suffered spine and brain injuries, on a ventilator and now in a wheelchair. Plainitiff filed complaint in state Atlanta court in June 2021 against Amazon, the delivery driver Williams, the contractor delivery truck company Harper Logistics, and the delivery company's insurance provider. Through the theory of vicarious liability, plaintiff argues that Amazon's algorithms controls the whole delivery operations of the delivery truck drivers and trucks to deliver all the packages in a speedy manner. The arguments for vicairous liablity are that Amazon controls the route, the hours, the number of packages, and requires drivers to wear the Amazon logo.","","","Rana v. Amazon et al A lawsuit against Amazon for vicarious liability of a delivery truck driver Williams, the contracting delivery company Harper Logistics and the delivery business’s insurance provider, Old Republic Insurance Co. for a car crash by Amazon Delivery Driver that left plainitff paralyzed. Although have been over 100 lawsuits filed against Amazon Logistics in the last year for crashes by delivery vans, this case is the most severe in its argument of control by Amazon rather than the contracted delivery companies and insurance providers. The outcome of this case will influence future cases against Amazon, and could result in the public exposure of Amazon's algorithms. By demonstrating managerial ownership of Harper Logistics rather than Amazon merely being a customer, plaintiff hopes to show Amazon's algorithm controlled the driver route and speed, and therefore is vicariously liable for negligently making drivers work unreasonable shifts. On March 15, 2021, plaintiff was in a car accident in Atlanta when an Amazon Delivery truck hit their car. Plaintiff suffered spine and brain injuries, on a ventilator and now in a wheelchair. Plainitiff filed complaint in state Atlanta court in June 2021 against Amazon, the delivery driver Williams, the contractor delivery truck company Harper Logistics, and the delivery company's insurance provider. Through the theory of vicarious liability, plaintiff argues that Amazon's algorithms controls the whole delivery operations of the delivery truck drivers and trucks to deliver all the packages in a speedy manner. The arguments for vicairous liablity are that Amazon controls the route, the hours, the number of packages, and requires drivers to wear the Amazon logo. Amazon    "
"88","88","L. v. Alphabet","A number of anonymous plaintiffs bring a class action suit against Alphabet, Inc. and related companies, alleging that their development of Bard, the AI chatbot, involves the conversion/theft of data, invasion of privacy, unfair competition, unjust enrichment, copyright infringement, and removal of copyright management information under the DMCA.","'Generative AI'","Generative AI","'Copyright Infringement','Right to Privacy','Unjust Enrichment','Unfair Competition','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Right to Privacy, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information","'Copyright Infringement'","Copyright Infringement","'Bard'","Bard","'Yes'","","Alphabet, Inc.; Google DeepMind; Google, LLC","Federal: US Dist. Ct. N.D. Ca.","07/11/23","","0","Active","7/25/2023","7/25/2023","","Bob","","The plaintiffs allege that Google has been unlawfully collecting personal data from private individuals across the United States, violating privacy laws, copyright, the Copyright Act's prohibition on removal of copyright management information, unfair competition laws, and is now using that data to develop AI tools such as the Bard chatbot.","Case Reassigned to Judge Araceli Martinez-Olguin","7/18/2023","L. v. Alphabet A number of anonymous plaintiffs bring a class action suit against Alphabet, Inc. and related companies, alleging that their development of Bard, the AI chatbot, involves the conversion/theft of data, invasion of privacy, unfair competition, unjust enrichment, copyright infringement, and removal of copyright management information under the DMCA.  The plaintiffs allege that Google has been unlawfully collecting personal data from private individuals across the United States, violating privacy laws, copyright, the Copyright Act's prohibition on removal of copyright management information, unfair competition laws, and is now using that data to develop AI tools such as the Bard chatbot. Alphabet, Inc.; Google DeepMind; Google, LLC Bard Generative AI Copyright Infringement, Right to Privacy, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information Copyright Infringement"
"5","5","K.W. v. Armstrong","Class action reached a settlment after the ACLU of Idaho sought injunctive relief against the Department of Healht and Welfare cutting disabilities services because of a trade secret algorithm, resulting in development of new ADS (algorithmic decision system) to calculate disabilities benefits, litigation ensues to define the scope of the settlement","'Agency Budget','Constitutional Law','Disabilities Benefits','Health'","Health; Disabilities Benefits; Agency Budget","'42 C.F.R. § 431.210(b) Medicaid Adequate Notice','Preliminary Injunction'","42 C.F.R. § 431.210(b) Medicaid Adequate Notice; Preliminary Injunction","'Assigned Budget Amount','Lack of Remedy','Transparency in Change of Algorithm','Transparency/Trade Secrecy'","Assigned Budget Amount; Transparency in Change of Algorithm; Trade Secrecy; Lack of Remedy","","","","Yes","ACLU","Federal: US Dist. Ct. D. Idaho","1/18/2012","Yes","-1","Active","2/1/2021","9/20/2021","RA Done; Check for New Activity","Jenna","Idaho Department of Health and Welfare program, the DD Waiver Program, had a change in formula to calculate the dollar value amount each adult patient with physical or intellectual disabilities would receive in Medicaid services led to severe drop for in-home care and services. The IDHW began building the budget tool by collecting 2009 and 2010 data for 3,500 patient records, but 66% of the sample size was discarded for various errors including missing information. The Court concluded that this formula resulted in 10-15% of patients receiving inadequate budgets, and 62% of the budgets were reconsidered after Independent Assessment Providers who are contracted by the state, so regular testing must be conducted on the formula.

The Individual Assessment Provider contracted by IDHW would determine the level for factors such as type of disability and need for nursing and living services, level of hearing, vision and mobility, and then enter into the algorithm. The IAP then carries over this data to categories in the Individualized Budget Calculation, and from there the budget tool automatically calculates what Medicaid would need to pay for these needs. The budget has a standard dollar figure for each item called the ""constant"" which increases or decreases based on the IAP's evaluation, to total the Assigned Budget Amount. The Care Manager then approves the budget if it is deemed to meet the patient's needs. While disputed, the court concluded that the Service Plan Notice contains an attachment that includes copies of the IBC and the Inventory of Individual Needs for that participant, what services the Care Manager approved and denied, and the right to appeal this decision. However, the patient has 28 days to appeal to a hearing officer who can affirm or remand the decision back to the care manager, but the hearing officer themselves cannot modify the budget. 

Idaho's automated decision-making system algorithm was initially not disclosed as a trade secret, the ACLU succeeded in disclosure of the formula. Once the court determined the formula was ""unconstitutionally arbitrary"" it forced the Medicaid program to reconfigure its automated decision-making system so that the patients received the proper dollar value services, as well as restore the dollar value services the patients previously received before the drop in the ADS. Another important requirement is that the State Medicaid program must evaluate the new ADS formula regularly to ensure no severe drops occur like this again. The settlement negotiations are still in litigation, with the state requesting an extended timeline and scope to make these changes. It is also important to note that the court left the onus on the Medicaid program to fix the formula, but it would need support and assistance from outside firms and from the impacted patients.

The settlement addressed the class three concerns: 1. the need for an accurate budget tool, 2. revising the budget notice to inform participants more clearly about changes to their budgets, and 3. aid with appeals. The settlement acknowledged the costs of developing a new budget tool by setting a deadline of two years and provided cushion for plaintiffs in that they retained their 2011 level of benefits in the meantime. After the January 2020 deadline passed, IDHW requested until January 2023 to implement structural changes and creating the new budget tool, but the court set a short-term deadline for the creation of a new budget tool because the restructuring delay is not an identical delay for the creation of a new budget tool that was promised in the 2017 settlement. 

Importantly, the settlement provided that the public would have the right to inspect and copy the data ""about the IDHW’s budget setting methodologies, models, and tools"" and particularly DD Waiver program participants would have the right to inspect past, present, and future information, all with redaction only when necessary to protect PII. 

The settlement agreed that a permanent injunction was not necessary.","Plaintiffs filed complaint on January 18, 2012. They brought class claims and individual claims: the class claims challenge the budget tool, the lack of notice, and the exclusion from hearings on this new tool, while the sixteen named plaintiffs bring individual claims that the change to the algorithm lead to a significant risk of them being institutionalized.

injunction restored the Plaintiffs’ budgets to the levels they were at prior to July 1, 2011, the date IDHW sent the unconstitutional budget notices. The injunction also prohibited IDHW from reducing Plaintiffs budgets until it (1) provided Plaintiffs with notices, approved by this Court, and (2) made available for copying specified documents it used to calculate Plaintiffs’ budgets.

The Ninth Circuit affirmed the injunction on June 5, 2015, agreeing that court approval of a proper notice that explains the budget reductions are necessary.

On March 28, 2016, the District Court awarded plaintiffs’ attorneys fees for establishing the record. The court then considered cross-motions for summary judgement on both class and individual claims, motions to strike, as well as a joint motion for preliminary approval of a settlement.

disclosure of formula, finding formula unconstitutional and require new formula, -- so this was reported in later orders but i can't find the initial order so i don't have the exact dates


The parties reached a preliminary settlement on the class action claims in October 2016, requiring IDHW to 1. develop a new budget tool within two years, and 2. retain plaintiffs’ benefits at their 2011 level until the new budget tool was approved. The settlement provided that if the budget tool were not implemented in three years by January 2020, the plaintiffs could ask the court to set a ""reasonable deadline"" for IDHW. The court approved the proposed notice of this settlement by sending a copy to each class member, each class member's guardian, support programs, and advocacy programs. The court granted the joint motion for preliminary approval of the settlement for the class action claims but denied approval of the revised budget because it required the class members can comment on the budget before it could be approved. Additionally, the settlement did not account for the individual claims made by the 16 named plaintiffs, called the Olmstead claims.

In September 2017, the court denied IDHW's motion to dismiss the Olmstead individual claims on the grounds that they are moot with the class action settlement, but the Court disagreed and ordered that once the new budget tool is released, trial will be set for the individual claims as the settlement did not grant all the relief that the plaintiffs sued for.


After the deadline for a new budget tool and restructuring passed, plaintiffs requested 120 days for IDHW to implement the new budget tool, whereas IDHW requested until January 2023 in order to implement: (1) redefine the supported living service and restructure how supports are paid; (2) developing habilitation and prevocational services; (3) improving the person-centered planning process; and (4) restructuring medical transportation. On June 4, 2020, the court granted in part plaintiff's motion to enforce judgement and defendant's motion to set reasonable deadlines by setting up a two-track deadline system: ""longer deadline for the restructuring of services and the other track being a shorter deadline for creation of the new budget tool."" The court granted the defendant's other two motions for COVID-19 relief and to allow sur-reply brief. 

Most recently, on November 24, 2020, the district court concurred with Plaintiffs of the need to resolve the ongoing dispute for a proper schedule for settlement but decided further mediation would only prolong complications and instead ordered a hearing to set a briefing schedule.","Strike filed, attorneys hosted Zoom update for members of the class action: http://ourhealthandwelfare.org/news/2021/3/24/latest-updates-about-kw-v-armstrong","3/24/2021","K.W. v. Armstrong Class action reached a settlment after the ACLU of Idaho sought injunctive relief against the Department of Healht and Welfare cutting disabilities services because of a trade secret algorithm, resulting in development of new ADS (algorithmic decision system) to calculate disabilities benefits, litigation ensues to define the scope of the settlement Idaho Department of Health and Welfare program, the DD Waiver Program, had a change in formula to calculate the dollar value amount each adult patient with physical or intellectual disabilities would receive in Medicaid services led to severe drop for in-home care and services. The IDHW began building the budget tool by collecting 2009 and 2010 data for 3,500 patient records, but 66% of the sample size was discarded for various errors including missing information. The Court concluded that this formula resulted in 10-15% of patients receiving inadequate budgets, and 62% of the budgets were reconsidered after Independent Assessment Providers who are contracted by the state, so regular testing must be conducted on the formula.

The Individual Assessment Provider contracted by IDHW would determine the level for factors such as type of disability and need for nursing and living services, level of hearing, vision and mobility, and then enter into the algorithm. The IAP then carries over this data to categories in the Individualized Budget Calculation, and from there the budget tool automatically calculates what Medicaid would need to pay for these needs. The budget has a standard dollar figure for each item called the ""constant"" which increases or decreases based on the IAP's evaluation, to total the Assigned Budget Amount. The Care Manager then approves the budget if it is deemed to meet the patient's needs. While disputed, the court concluded that the Service Plan Notice contains an attachment that includes copies of the IBC and the Inventory of Individual Needs for that participant, what services the Care Manager approved and denied, and the right to appeal this decision. However, the patient has 28 days to appeal to a hearing officer who can affirm or remand the decision back to the care manager, but the hearing officer themselves cannot modify the budget. 

Idaho's automated decision-making system algorithm was initially not disclosed as a trade secret, the ACLU succeeded in disclosure of the formula. Once the court determined the formula was ""unconstitutionally arbitrary"" it forced the Medicaid program to reconfigure its automated decision-making system so that the patients received the proper dollar value services, as well as restore the dollar value services the patients previously received before the drop in the ADS. Another important requirement is that the State Medicaid program must evaluate the new ADS formula regularly to ensure no severe drops occur like this again. The settlement negotiations are still in litigation, with the state requesting an extended timeline and scope to make these changes. It is also important to note that the court left the onus on the Medicaid program to fix the formula, but it would need support and assistance from outside firms and from the impacted patients.

The settlement addressed the class three concerns: 1. the need for an accurate budget tool, 2. revising the budget notice to inform participants more clearly about changes to their budgets, and 3. aid with appeals. The settlement acknowledged the costs of developing a new budget tool by setting a deadline of two years and provided cushion for plaintiffs in that they retained their 2011 level of benefits in the meantime. After the January 2020 deadline passed, IDHW requested until January 2023 to implement structural changes and creating the new budget tool, but the court set a short-term deadline for the creation of a new budget tool because the restructuring delay is not an identical delay for the creation of a new budget tool that was promised in the 2017 settlement. 

Importantly, the settlement provided that the public would have the right to inspect and copy the data ""about the IDHW’s budget setting methodologies, models, and tools"" and particularly DD Waiver program participants would have the right to inspect past, present, and future information, all with redaction only when necessary to protect PII. 

The settlement agreed that a permanent injunction was not necessary. Plaintiffs filed complaint on January 18, 2012. They brought class claims and individual claims: the class claims challenge the budget tool, the lack of notice, and the exclusion from hearings on this new tool, while the sixteen named plaintiffs bring individual claims that the change to the algorithm lead to a significant risk of them being institutionalized.

injunction restored the Plaintiffs’ budgets to the levels they were at prior to July 1, 2011, the date IDHW sent the unconstitutional budget notices. The injunction also prohibited IDHW from reducing Plaintiffs budgets until it (1) provided Plaintiffs with notices, approved by this Court, and (2) made available for copying specified documents it used to calculate Plaintiffs’ budgets.

The Ninth Circuit affirmed the injunction on June 5, 2015, agreeing that court approval of a proper notice that explains the budget reductions are necessary.

On March 28, 2016, the District Court awarded plaintiffs’ attorneys fees for establishing the record. The court then considered cross-motions for summary judgement on both class and individual claims, motions to strike, as well as a joint motion for preliminary approval of a settlement.

disclosure of formula, finding formula unconstitutional and require new formula, -- so this was reported in later orders but i can't find the initial order so i don't have the exact dates


The parties reached a preliminary settlement on the class action claims in October 2016, requiring IDHW to 1. develop a new budget tool within two years, and 2. retain plaintiffs’ benefits at their 2011 level until the new budget tool was approved. The settlement provided that if the budget tool were not implemented in three years by January 2020, the plaintiffs could ask the court to set a ""reasonable deadline"" for IDHW. The court approved the proposed notice of this settlement by sending a copy to each class member, each class member's guardian, support programs, and advocacy programs. The court granted the joint motion for preliminary approval of the settlement for the class action claims but denied approval of the revised budget because it required the class members can comment on the budget before it could be approved. Additionally, the settlement did not account for the individual claims made by the 16 named plaintiffs, called the Olmstead claims.

In September 2017, the court denied IDHW's motion to dismiss the Olmstead individual claims on the grounds that they are moot with the class action settlement, but the Court disagreed and ordered that once the new budget tool is released, trial will be set for the individual claims as the settlement did not grant all the relief that the plaintiffs sued for.


After the deadline for a new budget tool and restructuring passed, plaintiffs requested 120 days for IDHW to implement the new budget tool, whereas IDHW requested until January 2023 in order to implement: (1) redefine the supported living service and restructure how supports are paid; (2) developing habilitation and prevocational services; (3) improving the person-centered planning process; and (4) restructuring medical transportation. On June 4, 2020, the court granted in part plaintiff's motion to enforce judgement and defendant's motion to set reasonable deadlines by setting up a two-track deadline system: ""longer deadline for the restructuring of services and the other track being a shorter deadline for creation of the new budget tool."" The court granted the defendant's other two motions for COVID-19 relief and to allow sur-reply brief. 

Most recently, on November 24, 2020, the district court concurred with Plaintiffs of the need to resolve the ongoing dispute for a proper schedule for settlement but decided further mediation would only prolong complications and instead ordered a hearing to set a briefing schedule. ACLU  Health; Disabilities Benefits; Agency Budget 42 C.F.R. § 431.210(b) Medicaid Adequate Notice; Preliminary Injunction Assigned Budget Amount; Transparency in Change of Algorithm; Trade Secrecy; Lack of Remedy"
"21","21","State v. Pickett","Court of Appeals ruling that the source code must be revealed under a protective order for effective review of the reliability of the state's proprietary DNA analysis when there was not enough DNA for traditional DNA analysis to identify a criminal defendant, emphasizing the importance of independent review and the dangers of programmer bias","'Criminal Justice','DNA Analysis','Intellectual Property'","Criminal Justice; DNA Analysis; Intellectual Property","'5th Amendment','N.J.R.E. 702','6th Amendment'","5th Amendment; 6th Amendment; N.J.R.E. 702","'Insufficient Research','Role of Expert Testimony','Transparency/Trade Secrecy','Unreliability/Miscalculationns'","Transparency / Trade Secrecy; Role of Expert Testimony; Insufficient Research; Unreliabilty/Miscalculation","'TrueAllele'","TrueAllele","","No","The Innocence Project; ACDL-NJ; Upturn; Legal Aid Society; ACLU-NJ","State: New Jersey","4/16/2017","Yes","-1","Active: On Remand","2/11/2021","3/25/2021","RA Done","Jenna","This is the first case on appeal to tackle the issue of trade secrecy in determining the reliability of forensic evidentiary technology TrueAllele in New Jersey. The solution to balancing constitutional and intellectual property rights was a protective order.

The Court of Appeals highlighted True Allele’s competitor who was forced to reveal the source code in another criminal case and multiple errors were found. The court also found the need for independent review for both the judge and the defendant to independently evaluate the State's expert's testimony but acknowledged the concerns about the proprietary information getting out. The court also recognized that the data programmed might be inherently biased, thus exacerbating bias. TrueAllele is designed to evaluate cases where there are low amounts of DNA where other DNA analysis tests will not work.

Many groups wrote amicus briefs highlighting the necessity for algorithmic transparency, which are excerpted in the order.","On April 16, 2017, police witnessed defendant and co-defendant shoot into a crowd and flee, where police pursued and arrested them. The police picked up two handguns after retracing Pickett's path and a ski mask retracing the co-defendant's path. The forensic scientist said the small amount of DNA amylase from the saliva on the ski mask was not enough for a traditional DNA analysis but compared to swabs from the Defendant that produced results. The rest of the DNA samples did not produce any results, so the State sent it out. 

Hudson County Grand Jury indicted and charged defendant with first degree murder and charges relating to weapons.

The State sent the samples to Cybergenetics lab in Pittsburgh who used TrueAllele to make up for the smaller samples that often result in more ""probabilistic"" analysis and ""leaves more room for interpretation than for the single-source or simple-mixture samples that have been traditionally DNA tested."" The TrueAllele program calculates likelihood that the given individual was a contributor compared to an unrelated individual to account for the effects of the smaller sample.

At the Hudson County court Frye hearing in late April 2019, the State's DNA expert (and co-founder of Cybergenetics) used a software to conclude that the defendant's DNA was connected to the murder in question. After briefs and oral arguments, on June 23, 2020 the judge denied the defendant's request for discovery to this software source code and documents under trade secrecy, finding that the hearing testimony and documents were sufficient. The State's opposition brief included statements from Cybergenetics saying this software was thousands of lines long, not included in the patent because the industry is too highly competitive, and that defendant could examine parts of the source code on a specific computer after signing an NDA. The Judge's order did not engage with the reliability of the software.

Defendant appealed this ruling, arguing that the source code was necessary to determine the reliability and therefore admissibility. The Court of Appeals determined that the defendant was entitled to True Allele’s source code for the purpose of challenging the reliability of expert testimony and reliance on the DNA analysis. The court found that defendant was entitled to the source code and documents because the defendant showed particularized need for this discovery: testing, design, bug reporting, change logs, program requirements, any documents needed to challenge the reliability, an example of other jurisdictions safeguarding IP with protective orders.","Court of Appeals Ruling","2/3/2021","State v. Pickett Court of Appeals ruling that the source code must be revealed under a protective order for effective review of the reliability of the state's proprietary DNA analysis when there was not enough DNA for traditional DNA analysis to identify a criminal defendant, emphasizing the importance of independent review and the dangers of programmer bias This is the first case on appeal to tackle the issue of trade secrecy in determining the reliability of forensic evidentiary technology TrueAllele in New Jersey. The solution to balancing constitutional and intellectual property rights was a protective order.

The Court of Appeals highlighted True Allele’s competitor who was forced to reveal the source code in another criminal case and multiple errors were found. The court also found the need for independent review for both the judge and the defendant to independently evaluate the State's expert's testimony but acknowledged the concerns about the proprietary information getting out. The court also recognized that the data programmed might be inherently biased, thus exacerbating bias. TrueAllele is designed to evaluate cases where there are low amounts of DNA where other DNA analysis tests will not work.

Many groups wrote amicus briefs highlighting the necessity for algorithmic transparency, which are excerpted in the order. On April 16, 2017, police witnessed defendant and co-defendant shoot into a crowd and flee, where police pursued and arrested them. The police picked up two handguns after retracing Pickett's path and a ski mask retracing the co-defendant's path. The forensic scientist said the small amount of DNA amylase from the saliva on the ski mask was not enough for a traditional DNA analysis but compared to swabs from the Defendant that produced results. The rest of the DNA samples did not produce any results, so the State sent it out. 

Hudson County Grand Jury indicted and charged defendant with first degree murder and charges relating to weapons.

The State sent the samples to Cybergenetics lab in Pittsburgh who used TrueAllele to make up for the smaller samples that often result in more ""probabilistic"" analysis and ""leaves more room for interpretation than for the single-source or simple-mixture samples that have been traditionally DNA tested."" The TrueAllele program calculates likelihood that the given individual was a contributor compared to an unrelated individual to account for the effects of the smaller sample.

At the Hudson County court Frye hearing in late April 2019, the State's DNA expert (and co-founder of Cybergenetics) used a software to conclude that the defendant's DNA was connected to the murder in question. After briefs and oral arguments, on June 23, 2020 the judge denied the defendant's request for discovery to this software source code and documents under trade secrecy, finding that the hearing testimony and documents were sufficient. The State's opposition brief included statements from Cybergenetics saying this software was thousands of lines long, not included in the patent because the industry is too highly competitive, and that defendant could examine parts of the source code on a specific computer after signing an NDA. The Judge's order did not engage with the reliability of the software.

Defendant appealed this ruling, arguing that the source code was necessary to determine the reliability and therefore admissibility. The Court of Appeals determined that the defendant was entitled to True Allele’s source code for the purpose of challenging the reliability of expert testimony and reliance on the DNA analysis. The court found that defendant was entitled to the source code and documents because the defendant showed particularized need for this discovery: testing, design, bug reporting, change logs, program requirements, any documents needed to challenge the reliability, an example of other jurisdictions safeguarding IP with protective orders. The Innocence Project; ACDL-NJ; Upturn; Legal Aid Society; ACLU-NJ TrueAllele Criminal Justice; DNA Analysis; Intellectual Property 5th Amendment; 6th Amendment; N.J.R.E. 702 Transparency / Trade Secrecy; Role of Expert Testimony; Insufficient Research; Unreliabilty/Miscalculation"
"37","37","People v. Younglove","","'Criminal Justice','Sentencing'","Criminal Justice; Sentencing","","","","","'COMPAS'","COMPAS","","No","","State: Michigan","","Yes","-1","","2/15/2021","2/15/2021","","","","This appeal about COMPAS is brought relating to: PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. ERIN RENEE YOUNGLOVE, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. DARRELL WAYNE HEGLER, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. LUKE MATTHEW WILSON, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. FREDERICK ANTHONY BRADFORD, Defendant-Appellant.","","","People v. Younglove   This appeal about COMPAS is brought relating to: PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. ERIN RENEE YOUNGLOVE, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. DARRELL WAYNE HEGLER, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. LUKE MATTHEW WILSON, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. FREDERICK ANTHONY BRADFORD, Defendant-Appellant.  COMPAS Criminal Justice; Sentencing  "
"54","54","People v. Wakefield","Acknowledging the intersection of due process and scientific advancements, the highest court affirmed a trial court finding that TrueAllele Casework System, the DNA software program used to identify defendant in a murder scene, was generally accepted by the scientific community and did not violate defendant's right to face accusers by not having access to the source code by differentiating DNA collection vs. DNA probability","'Constitutional Law','Criminal Justice','DNA Analysis','Sentencing'","","'Biometric Information Privacy Act','Conviction Challenge','Due Process','Evidence','6th Amendment'","","'Admissibility','Transparency/Trade Secrecy','Unreliability','Reliability','Confrontation Clause'","","'TrueAllele'","TrueAllele","","No","","State: New York","07/2014","Yes","-1","Inactive","10/14/2021","10/21/2021","RA Done","Jenna","The two issues relating to algorithms in this case was the scientific validity of TrueAllele and the defendant's right to face his accuser as an algorithm. First, the court notes that TrueAllele uses the MCMC algorithm to ""solve high dimension calculus problems that would be impossible or impractical without a computer so as to identify all possibilities, not just the maximum possibility."" At the trial court Frye hearing, expert witness testified that TrueAllele uses the Markov Chain Monte Carlo algorithm give probabilities of all different possibilities, as it proposes the possibilities for different genotypes based on the lab generated data from the DNA electropherogram rather than the traditional interpretation by a person. The expert witness added that ""after objectively generating all genotype possibilities, TrueAllele answers the question of ""how much more the suspect matches the evidence [than] a random person would,"" and the answer takes the form of a likelihood ratio."""" For the second issue of the right to face accuser violated because he was not granted access to the source code. The court grappled with the intersection of due process and science. The court differentiates that the DNA extraction done by state police traditionally go through combined probability inclusion to simplify the DNA for human observation whereas TrueAllele is a fully-continuous probabilistic systems uses all available data to look at more patterns. There is human interaction with True Allele as it tells the software what to download and what questions to ask when running the data.","The defendant was brought on murder and robbery charges in Schenectady County. After the murder victim was found by a mental health case worker after not responding, the police published request for information. A friend of the defendant informed police that the defendant had admitted to murdering the victim, leading to the defendant's arrest. The police performed a nasal swab and sent the DNA to a private lab, Cybergenetics, hat used TrueAllele for testing. At the trial court, the defendant moved to exclude all evidence regarding TrueAllele until it was established that it was recognized by the scientific community in a Frye hearing. The trial court granted the Frye hearing and heard testimony from Cybergenetics' founder and chief scientist in July of 2014.  The court allowed the DNA probability into evidence, a jury trial found the defendant guilty of first degree murder and first degree robbery, anhd he was sentenced for life in prison without parole. The defendant appealed. In affirming the trial court's finding under the Frye protocol of hearing expert testimony"" based on a scientific principle or procedure which has been sufficiently established to have gained general acceptance in the particular field in which it belongs."" TrueAllele has gone through 25 validation studies and had been published in six forensic science journals, has been recognized by The DNA Subcommittee of the New York State Forensic Science Commission, and has used it to identify remains from 9/11. Defendant's other claim on appeal is that the DNA evidence does not establsih robbery, however TrueAllele's probability the defendant's DNA on the missing items was categorically more probable than coincidental. Even viewing the DNA evidence in a neutral light, the addition of witness testimony convinced the appellate court to affirm. The defendant's third claim on appeal is that the defendant did not have the right ot face his accuser against TrueAllele. Unlike traditional DNA analysis that does not use all the data extracted and relies on a human analyst, True Allele uses all the data to come up with probabilities through a calculus algorithm. The source code is protected by trade secret as only two people know it, and the source code was designed with a high level of mathematical understanding.  The court found that Cybergenetics was acting to assist law enforcement, the report of comparing the defendant's DNA to the DNA on the crime scene was testimonial in nature and thus True Allele is not a declarant and affirmed the trial court. The concurring judge said it was unnecessary to decide this issue because the defendant did not move for the source code to be disclosed post Frye Hearing.","Highest Court Opinion","8/15/2019","People v. Wakefield Acknowledging the intersection of due process and scientific advancements, the highest court affirmed a trial court finding that TrueAllele Casework System, the DNA software program used to identify defendant in a murder scene, was generally accepted by the scientific community and did not violate defendant's right to face accusers by not having access to the source code by differentiating DNA collection vs. DNA probability The two issues relating to algorithms in this case was the scientific validity of TrueAllele and the defendant's right to face his accuser as an algorithm. First, the court notes that TrueAllele uses the MCMC algorithm to ""solve high dimension calculus problems that would be impossible or impractical without a computer so as to identify all possibilities, not just the maximum possibility."" At the trial court Frye hearing, expert witness testified that TrueAllele uses the Markov Chain Monte Carlo algorithm give probabilities of all different possibilities, as it proposes the possibilities for different genotypes based on the lab generated data from the DNA electropherogram rather than the traditional interpretation by a person. The expert witness added that ""after objectively generating all genotype possibilities, TrueAllele answers the question of ""how much more the suspect matches the evidence [than] a random person would,"" and the answer takes the form of a likelihood ratio."""" For the second issue of the right to face accuser violated because he was not granted access to the source code. The court grappled with the intersection of due process and science. The court differentiates that the DNA extraction done by state police traditionally go through combined probability inclusion to simplify the DNA for human observation whereas TrueAllele is a fully-continuous probabilistic systems uses all available data to look at more patterns. There is human interaction with True Allele as it tells the software what to download and what questions to ask when running the data. The defendant was brought on murder and robbery charges in Schenectady County. After the murder victim was found by a mental health case worker after not responding, the police published request for information. A friend of the defendant informed police that the defendant had admitted to murdering the victim, leading to the defendant's arrest. The police performed a nasal swab and sent the DNA to a private lab, Cybergenetics, hat used TrueAllele for testing. At the trial court, the defendant moved to exclude all evidence regarding TrueAllele until it was established that it was recognized by the scientific community in a Frye hearing. The trial court granted the Frye hearing and heard testimony from Cybergenetics' founder and chief scientist in July of 2014.  The court allowed the DNA probability into evidence, a jury trial found the defendant guilty of first degree murder and first degree robbery, anhd he was sentenced for life in prison without parole. The defendant appealed. In affirming the trial court's finding under the Frye protocol of hearing expert testimony"" based on a scientific principle or procedure which has been sufficiently established to have gained general acceptance in the particular field in which it belongs."" TrueAllele has gone through 25 validation studies and had been published in six forensic science journals, has been recognized by The DNA Subcommittee of the New York State Forensic Science Commission, and has used it to identify remains from 9/11. Defendant's other claim on appeal is that the DNA evidence does not establsih robbery, however TrueAllele's probability the defendant's DNA on the missing items was categorically more probable than coincidental. Even viewing the DNA evidence in a neutral light, the addition of witness testimony convinced the appellate court to affirm. The defendant's third claim on appeal is that the defendant did not have the right ot face his accuser against TrueAllele. Unlike traditional DNA analysis that does not use all the data extracted and relies on a human analyst, True Allele uses all the data to come up with probabilities through a calculus algorithm. The source code is protected by trade secret as only two people know it, and the source code was designed with a high level of mathematical understanding.  The court found that Cybergenetics was acting to assist law enforcement, the report of comparing the defendant's DNA to the DNA on the crime scene was testimonial in nature and thus True Allele is not a declarant and affirmed the trial court. The concurring judge said it was unnecessary to decide this issue because the defendant did not move for the source code to be disclosed post Frye Hearing.  TrueAllele   "
"73","73","Renderos v. Clearview AI, Inc.","Plaintiffs initially filed suit against Clearview in County of Alameda Superior Court in California on March 9, 2021.  Clearview filed an action to remove the matter to the Northern District of California (N.D. Cal.).

This case was transferred to N.D. Ill. on Oct. 5, 2021, to be joined with the existing MDL, In re Clearview.","'Biometric Data','Facial Recognition','Privacy'","Biometric Data, Facial Recognition, Privacy","'Right to Privacy','Right to Publicity'","Right to Privacy, Right to Publicity","'Facial Recognition','Law Enforcement'","Facial Recognition, Law Enforcement","'Clearview'","Clearview","'Yes'","","","California","03/14/2021","","0","Inactive","3/23/2022","3/23/2022","","","Renderos was the first case against Clearview in California.  The plaintiffs also filed claims against police departments in California for uploading photographs of plaintiffs and other California citizens to the Clearview database, despite the City of Alameda (where one of the police departments resided) banning facial recognition in 2019.  The Renderos claims were primarily focused on the use of facial recognition for speech chilling and police action, rather than solely Clearview's acquisition of biometric data.

The Renderos plaintiffs, resting on their claims against the California municipal defendants, attempted to remain in California state court rather than be transferred to the MDL in N.D. Ill.  However, the Judicial Panel on Multidistrict Litigation determined that the issues in the case were substantially similar to the other cases in In re Clearview.  Although the arguments were different, the issues regarding collection, distribution, and profiting off of citizens' biometric data were the same.  The case was transferred to N.D. Ill. and combined with In re Clearview on Oct. 5, 2021.","Renderos et al. filed suit in California Superior Court against Clearview and the Alameda County District Attorney, Alameda Police Department, El Segundo Police Department, Antioch Police Department, and anonymous police officers on Apr. 22, 2021.

Clearview filed a motion June 14, 2021, to remove the case to N.D. Cal., arguing that the diversity and amount in controversy requirements had both been met.

On June 21, 2021, the United States Judicial Panel on Multidistrict Litigation filed a conditional transfer order to transfer this case to N.D. Ill. and join it with the other cases in In re Clearview.  Plaintiffs requested that the panel vacate the order on the grounds that their case involved California municipal defendants and was centered on fear of police action, rather than loss of privacy.

On Oct. 5th, 2021, the United States Judicial Panel on Multidistrict Litigation upheld the conditional transfer order and ordered the transfer to N.D. Ill. and consolidation with In re Clearview.","10/05/2021","10/5/2021","Renderos v. Clearview AI, Inc. Plaintiffs initially filed suit against Clearview in County of Alameda Superior Court in California on March 9, 2021.  Clearview filed an action to remove the matter to the Northern District of California (N.D. Cal.).

This case was transferred to N.D. Ill. on Oct. 5, 2021, to be joined with the existing MDL, In re Clearview. Renderos was the first case against Clearview in California.  The plaintiffs also filed claims against police departments in California for uploading photographs of plaintiffs and other California citizens to the Clearview database, despite the City of Alameda (where one of the police departments resided) banning facial recognition in 2019.  The Renderos claims were primarily focused on the use of facial recognition for speech chilling and police action, rather than solely Clearview's acquisition of biometric data.

The Renderos plaintiffs, resting on their claims against the California municipal defendants, attempted to remain in California state court rather than be transferred to the MDL in N.D. Ill.  However, the Judicial Panel on Multidistrict Litigation determined that the issues in the case were substantially similar to the other cases in In re Clearview.  Although the arguments were different, the issues regarding collection, distribution, and profiting off of citizens' biometric data were the same.  The case was transferred to N.D. Ill. and combined with In re Clearview on Oct. 5, 2021. Renderos et al. filed suit in California Superior Court against Clearview and the Alameda County District Attorney, Alameda Police Department, El Segundo Police Department, Antioch Police Department, and anonymous police officers on Apr. 22, 2021.

Clearview filed a motion June 14, 2021, to remove the case to N.D. Cal., arguing that the diversity and amount in controversy requirements had both been met.

On June 21, 2021, the United States Judicial Panel on Multidistrict Litigation filed a conditional transfer order to transfer this case to N.D. Ill. and join it with the other cases in In re Clearview.  Plaintiffs requested that the panel vacate the order on the grounds that their case involved California municipal defendants and was centered on fear of police action, rather than loss of privacy.

On Oct. 5th, 2021, the United States Judicial Panel on Multidistrict Litigation upheld the conditional transfer order and ordered the transfer to N.D. Ill. and consolidation with In re Clearview.  Clearview Biometric Data, Facial Recognition, Privacy Right to Privacy, Right to Publicity Facial Recognition, Law Enforcement"
"89","89","Doe 1 v. Github, Inc.","Anonymous plaintiffs sue Github, Microsoft, and Open AI for alleged wrongs committed in training Codex and Copilot generative AI coding tools, including removal of copyright management information, breach of open-source license, unfair competition, and others","'Generative AI'","Generative AI","'California Consumer Privacy Act','Negligence','17 U.S.C. 1202 Removal of Copyright Management Information'","California Consumer Privacy Act, Negligence, 17 U.S.C. 1202 Removal of Copyright Management Information","'Accountability'","Accountability","'Copilot','Codex'","Copilot, Codex","'Yes'","","Github, Inc.; Microsoft Corporation; OpenAI, Inc.","Federal: US Dist. Ct. N.D. Ca.","11/03/22","","0","Active","1/15/2023","7/26/2023","","Bob","","","Order re: Discovery Dispute","7/26/2023","Doe 1 v. Github, Inc. Anonymous plaintiffs sue Github, Microsoft, and Open AI for alleged wrongs committed in training Codex and Copilot generative AI coding tools, including removal of copyright management information, breach of open-source license, unfair competition, and others   Github, Inc.; Microsoft Corporation; OpenAI, Inc. Copilot, Codex Generative AI California Consumer Privacy Act, Negligence, 17 U.S.C. 1202 Removal of Copyright Management Information Accountability"
"7","7","Ewert v. Canada","Canada's Supreme Court ruled that Correctional Service of Canada breached their statutory duty to take all reasonable steps to learn how the algorithms did not account for indigenous populations when an inmate argued the that the psychological and risk assessment algorithms were invalid when applied to Indigenous inmates for lack of research","'Criminal Justice','Recidivism'","Criminal Justice; Recidivism","'Corrections and Conditional Release Act, S.C. 1992, c. 20, s. 24(1)'","Corrections and Conditional Release Act, S.C. 1992, c. 20, s. 24(1)","'Cross Culture Validity','Insufficient Research','Socioeconomics Bias','Use of Race','Unreliability/Miscalculationns'","Use of Race; Socioeconomic Bias; Insufficient Research; Unreliabilty/Miscalculation; Cross Cultural Validity","","","","No","","International: Canada","4/2000","Yes","-1","Inactive: Judgement for P","2/1/2021","3/30/2021","RA Done","Jenna","Canada's Supreme Court ruled that CSC breached their statutory duty when they did not take all reasonable steps to study the cross-cultural validity of the algorithm on indigenous populations. The dissent took issue with Ewert bringing this case for the use of the psychological and risk assessment algorithms on all indigenous inmates, arguing that Ewert should have just brought suit about his specific results of the algorithm since that is what the relief related to. The majority however emphasized that Indigenous inmates were less likely to be granted early release, were classified as high risk, and the tools had been developed using information from non-indigenous populations.

The majority and dissent also disagreed on whether the CSC should test for accuracy (majority) or validity (dissent).

The five tools Ewert challenged were: ""Hare Psychopathy Checklist-Revised (“PCL-R”), a tool that was designed to assess the presence of psychopathy but is also used to assess the risk of recidivism. Mr. Ewert also challenged the use of the Violence Risk Appraisal Guide (“VRAG”) and the Sex Offender Risk Appraisal Guide (“SORAG”), two actuarial tools designed to assess the risk of violent recidivism; the Static-99, an actuarial tool designed to estimate the probability of sexual and violent recidivism; and the Violence Risk Scale – Sex Offender (“VRS-SO”), a rating scale designed to assess the risk of sexual recidivism that is used in connection with the delivery of sex offender treatment.""","The Corrections and Conditional Release Act requires the Correctional Services of Canada (""CSC"") to take ""all reasonable steps"" to ensure information is accurate and complete about an inmate. The CSC used five different risk assessment algorithmic tools to make decisions about the inmates. 

Ewert is an inmate serving two sentences for murder and attempted murder. Ewert is Métis. Ewert filed the first suit about these internal review tools as early as early April 2000. Ultimately, Ewert's complaint is that the tools were made based on non-Indigenous people and were less accurate for him, and that CSC was violating the law by not showing proof first that the algorithms worked on Indigenous offenders. Ewert also brought claims for his Charter rights which were rejected by the Supreme Court.

The CSC made claims to Ewert that they would study indigenous populations and the five psychological and risk assessment algorithms in 2007. However, by 2015 they had still not produced any cross-cultural validity data.

In 2015, the Federal Court ruled for Ewert, granting declaratory relief and an injunction for using the algorithms on himself in the future and not using any of the past algorithmic results. Ewert's expert showed that there was a research gap on the validity of the tests, and the court mandated further study. 

Federal Court of Appeals overruled, finding Ewert did not show enough evidence of ""false results and conclusions"" and thus was not entitled to the injunction and research mandate. 

The Supreme Court on June 13, 2018 ruled for Ewert, holding that CSC had not taken reasonable steps to ensure and prove that its psychological and statistical algorithms that make decisions about Indigenous inmates are effective. The majority cites to facts that indigenous offenders are less likely to be granted early release, and classified as higher risk than non-indigenous inmates. The majority also points to CSC using the tools even with concerns. However, the Supreme court decision did not reinstate the injunction that the court of appeals overruled.

The dissent disagreed on the definition of ""information"" about inmates to be the factual information and biographical information, and that CSC only needed to keep accurate records of the results of the tools. The dissent proposed that Ewert should have appealed the specific decisions the algorithm made about him rather than saying the whole algorithm did not take into account indigenous offenders.","Supreme Court Judgement","6/13/2018","Ewert v. Canada Canada's Supreme Court ruled that Correctional Service of Canada breached their statutory duty to take all reasonable steps to learn how the algorithms did not account for indigenous populations when an inmate argued the that the psychological and risk assessment algorithms were invalid when applied to Indigenous inmates for lack of research Canada's Supreme Court ruled that CSC breached their statutory duty when they did not take all reasonable steps to study the cross-cultural validity of the algorithm on indigenous populations. The dissent took issue with Ewert bringing this case for the use of the psychological and risk assessment algorithms on all indigenous inmates, arguing that Ewert should have just brought suit about his specific results of the algorithm since that is what the relief related to. The majority however emphasized that Indigenous inmates were less likely to be granted early release, were classified as high risk, and the tools had been developed using information from non-indigenous populations.

The majority and dissent also disagreed on whether the CSC should test for accuracy (majority) or validity (dissent).

The five tools Ewert challenged were: ""Hare Psychopathy Checklist-Revised (“PCL-R”), a tool that was designed to assess the presence of psychopathy but is also used to assess the risk of recidivism. Mr. Ewert also challenged the use of the Violence Risk Appraisal Guide (“VRAG”) and the Sex Offender Risk Appraisal Guide (“SORAG”), two actuarial tools designed to assess the risk of violent recidivism; the Static-99, an actuarial tool designed to estimate the probability of sexual and violent recidivism; and the Violence Risk Scale – Sex Offender (“VRS-SO”), a rating scale designed to assess the risk of sexual recidivism that is used in connection with the delivery of sex offender treatment."" The Corrections and Conditional Release Act requires the Correctional Services of Canada (""CSC"") to take ""all reasonable steps"" to ensure information is accurate and complete about an inmate. The CSC used five different risk assessment algorithmic tools to make decisions about the inmates. 

Ewert is an inmate serving two sentences for murder and attempted murder. Ewert is Métis. Ewert filed the first suit about these internal review tools as early as early April 2000. Ultimately, Ewert's complaint is that the tools were made based on non-Indigenous people and were less accurate for him, and that CSC was violating the law by not showing proof first that the algorithms worked on Indigenous offenders. Ewert also brought claims for his Charter rights which were rejected by the Supreme Court.

The CSC made claims to Ewert that they would study indigenous populations and the five psychological and risk assessment algorithms in 2007. However, by 2015 they had still not produced any cross-cultural validity data.

In 2015, the Federal Court ruled for Ewert, granting declaratory relief and an injunction for using the algorithms on himself in the future and not using any of the past algorithmic results. Ewert's expert showed that there was a research gap on the validity of the tests, and the court mandated further study. 

Federal Court of Appeals overruled, finding Ewert did not show enough evidence of ""false results and conclusions"" and thus was not entitled to the injunction and research mandate. 

The Supreme Court on June 13, 2018 ruled for Ewert, holding that CSC had not taken reasonable steps to ensure and prove that its psychological and statistical algorithms that make decisions about Indigenous inmates are effective. The majority cites to facts that indigenous offenders are less likely to be granted early release, and classified as higher risk than non-indigenous inmates. The majority also points to CSC using the tools even with concerns. However, the Supreme court decision did not reinstate the injunction that the court of appeals overruled.

The dissent disagreed on the definition of ""information"" about inmates to be the factual information and biographical information, and that CSC only needed to keep accurate records of the results of the tools. The dissent proposed that Ewert should have appealed the specific decisions the algorithm made about him rather than saying the whole algorithm did not take into account indigenous offenders.   Criminal Justice; Recidivism Corrections and Conditional Release Act, S.C. 1992, c. 20, s. 24(1) Use of Race; Socioeconomic Bias; Insufficient Research; Unreliabilty/Miscalculation; Cross Cultural Validity"
"23","23","Burke v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, CCPA, Cal. commercial misappropriation, unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs","'Facial Recognition'","Facial Recognition","'California Consumer Privacy Act','Illinois Biometric Information Privacy Act','Unjust Enrichment','Commercial Misappropriation'","Illinois Biometric Information Privacy Act; California Consumer Privacy Act; Commercial misapporpriation; unjust enrichment","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. S.D. California;  Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","2/27/2020","No","0","Active","2/12/2021","5/1/2022","","","The complaint was originally brought in California under both BIPA and the CCPA before being transferred to SDNY and then Northern District of Illinois.","The amended complaint brought against Clearview, its two co founders, and the directors and officers as Does 1-10, argued Clearview violated California's unfair competition law, consumer privacy law, committed misappropriation and received unjust enrichment, as well as violated the Illinois BIPA.

The plaintiffs that they had uploaded images of themselves to Google and Facebook in the years Clearview actively scraped, plaintiffs never consented or gave written permission to Clearview, thus Clearview profited off of the plaintiffs' images and took away their control of their biometric information.

The complaint differentiates biometric information as defined by Illinois and by California, and argues Clearview knowingly and willfully violated both.

The four subclasses are: 1. commercial misappropriation, 2. BIPA, 3. CCPA and 4. unjust enrichment.

On April 17, the case was transferred from the Southern District of California to SDNY after a joint motion from Burke.

On April 24, the case was accepted as related to Calderon, and then reassigned to Judge McMahon who oversaw the total six Clearview cases in New York, at the time the five.

The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.","MDL Transfer out","1/13/2021","Burke v. Clearview AI, Inc. Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, CCPA, Cal. commercial misappropriation, unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs The complaint was originally brought in California under both BIPA and the CCPA before being transferred to SDNY and then Northern District of Illinois. The amended complaint brought against Clearview, its two co founders, and the directors and officers as Does 1-10, argued Clearview violated California's unfair competition law, consumer privacy law, committed misappropriation and received unjust enrichment, as well as violated the Illinois BIPA.

The plaintiffs that they had uploaded images of themselves to Google and Facebook in the years Clearview actively scraped, plaintiffs never consented or gave written permission to Clearview, thus Clearview profited off of the plaintiffs' images and took away their control of their biometric information.

The complaint differentiates biometric information as defined by Illinois and by California, and argues Clearview knowingly and willfully violated both.

The four subclasses are: 1. commercial misappropriation, 2. BIPA, 3. CCPA and 4. unjust enrichment.

On April 17, the case was transferred from the Southern District of California to SDNY after a joint motion from Burke.

On April 24, the case was accepted as related to Calderon, and then reassigned to Judge McMahon who oversaw the total six Clearview cases in New York, at the time the five.

The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.  Clearview Facial Recognition Illinois Biometric Information Privacy Act; California Consumer Privacy Act; Commercial misapporpriation; unjust enrichment Privacy"
"39","39","Thornley v. Clearview AI, Inc.","Clearview has appealed Remand in 7th Cir.","'Facial Recognition'","Facial Recognition","","","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","State: Illinois Cir. Ct. (Cook County); Removd to N.D. Ill.; Transferred to US Dist Ct. S.D. New York BUT Remanded to Ill. Cir. Ct. (Cook County)","5/27/2020","","0","Active","2/15/2021","5/1/2022","","","This lawsuit differs from other lawsuits against Clearview because they seek only statutory damages and attorneys fees under BIPA 15(c) instead of seeking damages for actual injury of the scraping, collecting, and compiling of data under BIPA 15(a) and 15(b).","Class action from Cook County on June 30, 2020 to ND Illinois for statutory damages and attorneys fees for violating BIPA 15(c) which states that:  “No private entity in possession of a biometric
identifier or biometric information may sell, lease, trade, or otherwise profit from a person’s or a customer’s biometric identifier or biometric information.”

Transferred to SDNY August 18, 2020. Plaintiffs then filed motion to remand for lack of Article III standing, because Clearview did not establish injury in fact of a concrete, particularized harm under the 15(c) claim. The court found that the plaintiff was allowed to make a narrow claim of relief, thus allowing the case to remand to state court.

On October 30, 2020 order remanding back to Cook County, Clearview appealed to Seventh Circuit who affirmed remand, 7th Circuit Appeal Deny Petition for Rehearing on March 9, 2021. Remanded on March 10, 2021 to Cook County.","Case Set for Status call on 5/4/2021","3/25/2021","Thornley v. Clearview AI, Inc. Clearview has appealed Remand in 7th Cir. This lawsuit differs from other lawsuits against Clearview because they seek only statutory damages and attorneys fees under BIPA 15(c) instead of seeking damages for actual injury of the scraping, collecting, and compiling of data under BIPA 15(a) and 15(b). Class action from Cook County on June 30, 2020 to ND Illinois for statutory damages and attorneys fees for violating BIPA 15(c) which states that:  “No private entity in possession of a biometric
identifier or biometric information may sell, lease, trade, or otherwise profit from a person’s or a customer’s biometric identifier or biometric information.”

Transferred to SDNY August 18, 2020. Plaintiffs then filed motion to remand for lack of Article III standing, because Clearview did not establish injury in fact of a concrete, particularized harm under the 15(c) claim. The court found that the plaintiff was allowed to make a narrow claim of relief, thus allowing the case to remand to state court.

On October 30, 2020 order remanding back to Cook County, Clearview appealed to Seventh Circuit who affirmed remand, 7th Circuit Appeal Deny Petition for Rehearing on March 9, 2021. Remanded on March 10, 2021 to Cook County.  Clearview Facial Recognition  Privacy"
"56","56","Zalatel v. Prisma Labs","The district court balanced the trademark infringement likelihood of confusion factors, focusing on the functionality of the defendant's machine learning programming that creates a machine redrawn image rather than photo filtering","'Infringement','Intellectual Property'","","'Trademark infringement'","","'Functionality'","","","","","No","","Federal: District Court District of Delaware","09/19/2016","Yes","-1","Inactive","10/14/2021","10/28/2021","RA Done","Jenna","In considering the motion to dismiss, the court contrasted the defendant's app from Zaletel in its interactions with indiivduals: individuals do not make an account, it is free to download from a third party platofrm, and it does not track the location of the app.","Plaintiff Zaletel created an app ""Prizmia for GoPro"" to edit pictures from GoPro and first launched it in the app store in August of 2014. The marketed features of this app included ""professional filters and effects, independent color grading controls for contrast, saturation, gamma and brightness, optical slow motion speed adjustment, live filters preview, Direct GoPro media library access and full control over all GoPro settings and features."" Zaletel subsequently registered a trademark for this photoediting app ""Prizmia"" on February 3, 2015. As of 2016, the app evolved to ""allow users to modify photographs or videos with filters that alter the photo's style or add an artistic effect."" In May of 2016, Zaletel renamed the app merely ""Prizmia"" to avoid infringing on GoPro's mark. Defendant is a Russian software company with a Bay Area office who launched a photoediting app ""Prisma"" in June 2016. Prisma is marketed as using artificial intelligence to make a user's image look in the style of famous artists like Van Gogh and Picasso. While Prizmia costs 99cents in Apple Store, Prisma is free in Google Store and Apple Store that then links to a third party download site.  On August 31, 2016 Zaletel sent Prizmia a cease and desist letter. On September 29, 2016, Zaletel filed in Eastern Virginia for a jury trial, claiming that defendant, through defendant’s use of the “Prisma” mark, infringes on plaintiff’s registered “Prizmia” mark.  On November 22, Zaletel filed a Motion for Preliminary Injunction and Prisma Labs filed a Motion to Dismiss for Lack of Jurisdiction Or, In The Alternative, To Transfer Venue. On December 22, the court considered the defendant's motion to dismiss and found no personal jurisdiction in Virginia when defendant's servers could not track the location of an app, the app could not be downloaded from defendant's passive website but only through a third party download site, and individuals do not create an account with the Prisma app. Finding no presence in Virginia, especially no purposeful availment, However instead of transferring  to the Northern District of California, the court transferred to the Delaware because Prisma was incorporated in Delaware and thus subject to general jurisdiction. On March 6, 2017, the Delaware District Court judge denied the motion for preliminary injunction, finding Zaletel has made no showing of reverse confusion. The court weighed the Lapp test factors for likelihood of confusion: although the names Prisma and Prizmia sound and look the same and the defendant's intent by uploading the app during the month Zaletel removed it to rename,  the remaining factors weigh for the defendant: the lack of strength of the Prizmia mark, the consumer care to purchase a free Prisma app,  the lack of actual confusion. The most convincing factor was the competition and overlap, determining that the apps had two extremely different functions: Prisma is a photofiltering app using AI to redraw the pictures in a style, whereas Prizmia provides professional filters for pictures taken on GoPro. On April 4, Zaletel filed amendment complaint and counterclaim. However on June 8, 2017, the case was dismissed with prejudice against Zalatel","Dismissal of Case","6/8/2017","Zalatel v. Prisma Labs The district court balanced the trademark infringement likelihood of confusion factors, focusing on the functionality of the defendant's machine learning programming that creates a machine redrawn image rather than photo filtering In considering the motion to dismiss, the court contrasted the defendant's app from Zaletel in its interactions with indiivduals: individuals do not make an account, it is free to download from a third party platofrm, and it does not track the location of the app. Plaintiff Zaletel created an app ""Prizmia for GoPro"" to edit pictures from GoPro and first launched it in the app store in August of 2014. The marketed features of this app included ""professional filters and effects, independent color grading controls for contrast, saturation, gamma and brightness, optical slow motion speed adjustment, live filters preview, Direct GoPro media library access and full control over all GoPro settings and features."" Zaletel subsequently registered a trademark for this photoediting app ""Prizmia"" on February 3, 2015. As of 2016, the app evolved to ""allow users to modify photographs or videos with filters that alter the photo's style or add an artistic effect."" In May of 2016, Zaletel renamed the app merely ""Prizmia"" to avoid infringing on GoPro's mark. Defendant is a Russian software company with a Bay Area office who launched a photoediting app ""Prisma"" in June 2016. Prisma is marketed as using artificial intelligence to make a user's image look in the style of famous artists like Van Gogh and Picasso. While Prizmia costs 99cents in Apple Store, Prisma is free in Google Store and Apple Store that then links to a third party download site.  On August 31, 2016 Zaletel sent Prizmia a cease and desist letter. On September 29, 2016, Zaletel filed in Eastern Virginia for a jury trial, claiming that defendant, through defendant’s use of the “Prisma” mark, infringes on plaintiff’s registered “Prizmia” mark.  On November 22, Zaletel filed a Motion for Preliminary Injunction and Prisma Labs filed a Motion to Dismiss for Lack of Jurisdiction Or, In The Alternative, To Transfer Venue. On December 22, the court considered the defendant's motion to dismiss and found no personal jurisdiction in Virginia when defendant's servers could not track the location of an app, the app could not be downloaded from defendant's passive website but only through a third party download site, and individuals do not create an account with the Prisma app. Finding no presence in Virginia, especially no purposeful availment, However instead of transferring  to the Northern District of California, the court transferred to the Delaware because Prisma was incorporated in Delaware and thus subject to general jurisdiction. On March 6, 2017, the Delaware District Court judge denied the motion for preliminary injunction, finding Zaletel has made no showing of reverse confusion. The court weighed the Lapp test factors for likelihood of confusion: although the names Prisma and Prizmia sound and look the same and the defendant's intent by uploading the app during the month Zaletel removed it to rename,  the remaining factors weigh for the defendant: the lack of strength of the Prizmia mark, the consumer care to purchase a free Prisma app,  the lack of actual confusion. The most convincing factor was the competition and overlap, determining that the apps had two extremely different functions: Prisma is a photofiltering app using AI to redraw the pictures in a style, whereas Prizmia provides professional filters for pictures taken on GoPro. On April 4, Zaletel filed amendment complaint and counterclaim. However on June 8, 2017, the case was dismissed with prejudice against Zalatel     "
"75","75","Cahoo v. Fast Enters. LLC","","'Employment'","Employment","'Administrative Procedure Act'","Administrative Procedure Act","'Justiciability','Unreliability'","Justiciability, Unreliability","","","","","","","","","0","","4/4/2022","","","","","","","","Cahoo v. Fast Enters. LLC      Employment Administrative Procedure Act Justiciability, Unreliability"
"91","91","Silverman v. OpenAI, Inc.","Authors Sarah Silverman, Christopher Golden and Richard Kadrey sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.","'Generative AI'","Generative AI","'Copyright Infringement','Negligence','Unjust Enrichment','Unfair Competition','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information","'Copyright Infringement'","Copyright Infringement","'ChatGPT'","ChatGPT","'Yes'","","Open AI, Inc, and related companies","Federal: US Dist. Ct. N.D. Ca.","07/07/2023","","0","Active","7/27/2023","7/27/2023","","Bob","","Plaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on July 7, 2023; the case was assigned to Judge Trina L. Thompson on July 24, 2023","Case assigned to Judge Trina L. Thompson","7/24/2023","Silverman v. OpenAI, Inc. Authors Sarah Silverman, Christopher Golden and Richard Kadrey sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.  Plaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on July 7, 2023; the case was assigned to Judge Trina L. Thompson on July 24, 2023 Open AI, Inc, and related companies ChatGPT Generative AI Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information Copyright Infringement"
"13","13","Bertuccelli v. Universal City Studios LLC","Court allows facial recognition expert to testify about his algorithmic facial reocnigtion analysis of the allegedly infringing and infringed masks to determine if a human would find them substantially similar","'Copyright','Intellectual Property'","Intellectual Property; Copyright","'Copyright Infringement','Federal Rule of Evidence 702'","Copyright Infringement; Federal Rule of Evidence 702","'Role of Expert Testimony'","Role of Expert Testimony;","","","","No","","Federal: US Dist. Ct. E.D. Louisiana","2/12/2019","Yes","-1","Inactive: Dismissed","2/4/2021","10/11/2021","In Progress","","","This order on a motion to exclude expert testimony in a copyright infringement lawsuit approves of the use of ""artificial intelligence facial recognition analysis"" to determine whether two masks were substantially similar In a copyright infringement case, The court held that the testimony of plaintiff's expert witness Dr. Edward R. Griffor is admissible.  Dr. Griffor performed ""artificial intelligence assisted facial recognition analysis of the King Cake Baby and Happy Death Day mask to determine whether the use of mathematics and target facial recognition algorithms comparing the two works would find that human perception would view the works as substantially similar."" After the March order, multiple motions by the Plaintiff for leave to consult experts were granted. In May 2021, the court denied the Plaintiffs' Motion for Partial Clarification, Partial Reconsideration, and Incorporated Motion for Leave to Amend. The court then denied a Motion to Strike Jury Demand in June 2021, with defendants then submitting proposed jury instructions. The court then granted the motion to expedite the trial, and then denied defendant's motion to exclude untimely evidence. The parties settled on June 14 and the case was dismissed.","Dismissal of Case","6/14/2021","Bertuccelli v. Universal City Studios LLC Court allows facial recognition expert to testify about his algorithmic facial reocnigtion analysis of the allegedly infringing and infringed masks to determine if a human would find them substantially similar  This order on a motion to exclude expert testimony in a copyright infringement lawsuit approves of the use of ""artificial intelligence facial recognition analysis"" to determine whether two masks were substantially similar In a copyright infringement case, The court held that the testimony of plaintiff's expert witness Dr. Edward R. Griffor is admissible.  Dr. Griffor performed ""artificial intelligence assisted facial recognition analysis of the King Cake Baby and Happy Death Day mask to determine whether the use of mathematics and target facial recognition algorithms comparing the two works would find that human perception would view the works as substantially similar."" After the March order, multiple motions by the Plaintiff for leave to consult experts were granted. In May 2021, the court denied the Plaintiffs' Motion for Partial Clarification, Partial Reconsideration, and Incorporated Motion for Leave to Amend. The court then denied a Motion to Strike Jury Demand in June 2021, with defendants then submitting proposed jury instructions. The court then granted the motion to expedite the trial, and then denied defendant's motion to exclude untimely evidence. The parties settled on June 14 and the case was dismissed.   Intellectual Property; Copyright Copyright Infringement; Federal Rule of Evidence 702 Role of Expert Testimony;"
"29","29","Mutnick v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA, 1A by intefering with use of social media sites, 4A gathering images under color of law, 14A threatening free assembly and exposing users to identity theft and domestic violence etc, Const. contracts clause, unjust enrichment; and sought seeking injunctive relief (deletion of data), damages, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA','Unjust Enrichment'","BIPA; unjust enrichment","'Facial Recognition','Privacy'","Facial Recognition, Privacy","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","1/22/2020","","0","Active","2/15/2021","2/15/2021","","","Of the nine cases consolidated into In Re Clearview, Mutnick was the first filed and many subsequent cases use the same set of facts/causes of action almost verbatim. Mutnick also spearheaded the consolidation attempts.","Plaintiffs filed its complaint on January 22, amending on January 29 to include that plaintiff was bringing claims for all citizens on constitutional grounds and for all Illinois residents as an Illinois class for violating BIPA.

As plaintiffs in the other in re Clearview cases will state, the Plaintiff's tie to Clearview is that ""[a]t relevant times, images of Plaintiff’s face appeared on numerous internet-based platforms and websites"" and at no time did Clearview contact the plaintiff for notice or consent.

On April 27, Clearview filed a motion to dismiss or alternatively to transfer venue, and on May 6 filed an opposition to a Preliminary Injunction.
On May 19 the court denied the stay and motion to dismiss or transfer.

On August 12, Mutnick was consolidated with Hall v. Clearview AI, Inc., (1:20-cv-00846) and Marron v. Clearview AI, Inc., (1:20-cv-02989) after unsuccessful attempt on May 29 to intervene and dismiss or transfer six cases in SDNY to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.


On August 18, Clearview moved to transfer to SDNY.

However, on January 8, 2021 the cases were combined into an MDL.

Thus on January 15, the court denied plaintiff's motions for preliminary injunction and for reconsideration and defendants' motion to transfer case as moot.","Combined into MDL","1/8/2021","Mutnick v. Clearview AI, Inc. Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA, 1A by intefering with use of social media sites, 4A gathering images under color of law, 14A threatening free assembly and exposing users to identity theft and domestic violence etc, Const. contracts clause, unjust enrichment; and sought seeking injunctive relief (deletion of data), damages, and litigation costs Of the nine cases consolidated into In Re Clearview, Mutnick was the first filed and many subsequent cases use the same set of facts/causes of action almost verbatim. Mutnick also spearheaded the consolidation attempts. Plaintiffs filed its complaint on January 22, amending on January 29 to include that plaintiff was bringing claims for all citizens on constitutional grounds and for all Illinois residents as an Illinois class for violating BIPA.

As plaintiffs in the other in re Clearview cases will state, the Plaintiff's tie to Clearview is that ""[a]t relevant times, images of Plaintiff’s face appeared on numerous internet-based platforms and websites"" and at no time did Clearview contact the plaintiff for notice or consent.

On April 27, Clearview filed a motion to dismiss or alternatively to transfer venue, and on May 6 filed an opposition to a Preliminary Injunction.
On May 19 the court denied the stay and motion to dismiss or transfer.

On August 12, Mutnick was consolidated with Hall v. Clearview AI, Inc., (1:20-cv-00846) and Marron v. Clearview AI, Inc., (1:20-cv-02989) after unsuccessful attempt on May 29 to intervene and dismiss or transfer six cases in SDNY to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.


On August 18, Clearview moved to transfer to SDNY.

However, on January 8, 2021 the cases were combined into an MDL.

Thus on January 15, the court denied plaintiff's motions for preliminary injunction and for reconsideration and defendants' motion to transfer case as moot.  Clearview Facial Recognition BIPA; unjust enrichment Facial Recognition, Privacy"
"45","45","Force v. Facebook","Suit dismissed against Facebook and cert denied by the Supreme Court, plaintiffs arguing that Facebook's algorithm suggests friends and groups based on similar interests, and highlights popular posts the user would like, and thus Facebook was providing the terrorist organization Hamas with means to reach an audience it would not otherwise have access to.","'Advertising','Social Media','Terrorism'","Advertising; Social Media; Terrorism","'Antiterrorism Act','Section 230'","Section 230; Antiterrorism Act;","'Lack of Remedy','Targeted Advertising'","Targetted Advertisting; Lack of Remedy","","","","No","Facebook","Federal: US Dist. Ct. S.D. New York; Transferred to E.D.N.Y.","7/10/2016","Yes","-1","Inactive: cert denied","3/5/2021","4/3/2021","In Progress","Jenna","The 2nd Circuit Dissent is the most important part of this case, which would have held Facebook liable for its algorithms and not immunized under Section 230: ""After collecting mountains of data about each user's activity on and off its platform, Facebook unleashes its algorithms to generate friend, group, and event suggestions based on what it perceives to be the user's interests. Id. at 345-46 ¶¶ 608-14. If a user posts about a Hamas attack or searches for information about a Hamas leader, Facebook may ""suggest"" that that user become friends with Hamas terrorists on Facebook or join Hamas-related Facebook groups. By ""facilitating] [Hamas's] ability to reach and engage an audience it could not otherwise reach as effectively,"" plaintiffs allege that Facebook's algorithms provide material support and personnel to terrorists. Id. at 347 ¶ 622; see id. at 352-58 ¶¶ 646-77. As applied to the algorithms, plaintiffs' claims do not seek to punish Facebook for the content others post, for deciding whether to publish third parties' content, or for editing (or failing to edit) others' content before publishing it. In short, they do not rely on treating Facebook as ""the publisher"" of others' information. Instead, they would hold Facebook liable for its affirmative role in bringing terrorists together.""","Plaintiffs filed their complaint on July 10, 2016, stating that Facebook uses algorithms to collect data and then ""actively"" suggest friends and groups to users, and ""actively"" promote posts that the user might like. Additionally, Facebook's uses targeted advertising. The complaint argues that Facebook allowed Hamas to reach and engage with the audience it would not have otherwise been able to effectively reach, and thus resulted in terrorist attacks. 

The amended complaint after the case was transferred to EDNY asserts this case concerns Section 230, and that Facebook violated the Anti-Terrorism Act by providing ""material support"" to Hamas through their algorithms. The amended complaint adds that Facebook had the power to flag, review and remove these Hamas accounts. 

The court granted Facebook's motion to dismiss because the claims were against Facebook in its publisher/speaker role under Section 230, and denied Force's motion to alter judgement and allow a second amended complaint. The reasoning: 

In July 2019, the Second Circuit affirmed that Section 230 immunized Facebook. The majority also rejected foreign law claims. Interestingly, Chief Judge Katzmann dissent in part to say that Section 230 did not immunize against these certain alleged actions of bringing terrorists together. The Second Circuit denied rehearing on August 29, 2019.

Supreme Court denied certiorari on May 18, 2020.","Supreme Court Denied Cert","5/18/2020","Force v. Facebook Suit dismissed against Facebook and cert denied by the Supreme Court, plaintiffs arguing that Facebook's algorithm suggests friends and groups based on similar interests, and highlights popular posts the user would like, and thus Facebook was providing the terrorist organization Hamas with means to reach an audience it would not otherwise have access to. The 2nd Circuit Dissent is the most important part of this case, which would have held Facebook liable for its algorithms and not immunized under Section 230: ""After collecting mountains of data about each user's activity on and off its platform, Facebook unleashes its algorithms to generate friend, group, and event suggestions based on what it perceives to be the user's interests. Id. at 345-46 ¶¶ 608-14. If a user posts about a Hamas attack or searches for information about a Hamas leader, Facebook may ""suggest"" that that user become friends with Hamas terrorists on Facebook or join Hamas-related Facebook groups. By ""facilitating] [Hamas's] ability to reach and engage an audience it could not otherwise reach as effectively,"" plaintiffs allege that Facebook's algorithms provide material support and personnel to terrorists. Id. at 347 ¶ 622; see id. at 352-58 ¶¶ 646-77. As applied to the algorithms, plaintiffs' claims do not seek to punish Facebook for the content others post, for deciding whether to publish third parties' content, or for editing (or failing to edit) others' content before publishing it. In short, they do not rely on treating Facebook as ""the publisher"" of others' information. Instead, they would hold Facebook liable for its affirmative role in bringing terrorists together."" Plaintiffs filed their complaint on July 10, 2016, stating that Facebook uses algorithms to collect data and then ""actively"" suggest friends and groups to users, and ""actively"" promote posts that the user might like. Additionally, Facebook's uses targeted advertising. The complaint argues that Facebook allowed Hamas to reach and engage with the audience it would not have otherwise been able to effectively reach, and thus resulted in terrorist attacks. 

The amended complaint after the case was transferred to EDNY asserts this case concerns Section 230, and that Facebook violated the Anti-Terrorism Act by providing ""material support"" to Hamas through their algorithms. The amended complaint adds that Facebook had the power to flag, review and remove these Hamas accounts. 

The court granted Facebook's motion to dismiss because the claims were against Facebook in its publisher/speaker role under Section 230, and denied Force's motion to alter judgement and allow a second amended complaint. The reasoning: 

In July 2019, the Second Circuit affirmed that Section 230 immunized Facebook. The majority also rejected foreign law claims. Interestingly, Chief Judge Katzmann dissent in part to say that Section 230 did not immunize against these certain alleged actions of bringing terrorists together. The Second Circuit denied rehearing on August 29, 2019.

Supreme Court denied certiorari on May 18, 2020. Facebook  Advertising; Social Media; Terrorism Section 230; Antiterrorism Act; Targetted Advertisting; Lack of Remedy"
"64","64","In re Google Assistant Privacy Litigation","The California District court allowed the proposed class action to pursue California Privacy law claims, and to refile consumer protection claims, for Google devices accepting ""False Accepts"" from their smartphone voice assistants and then illegally recording and disseminating the private conversations","'Privacy'","","'Biometric Information Privacy Act','Commercial Misappropriation'","","'Failure to Disclosure','Notice','Privacy'","","","","'Yes'","Yes","Google, Alphabet","Federal: Northern District of California","","","0","Active","10/14/2021","4/11/2022","","","The court found GooglePdid not have authorization to disclose any audio recordings or transcripts resulting from false accepts. It did so for analyses and improvement of Google Assistant for its own financial benefit and targeting personalized advertising to users.","Google Assistant produces a script of each audio recording that it stores. Google hires human subcontractors to comparing the script to the audio recording and check the accuracy of the Google Assistant's interpretation. Google Assistant may be triggered into active listening mode (false accepts). Google stores these recordings for future advertisements.","","","In re Google Assistant Privacy Litigation The California District court allowed the proposed class action to pursue California Privacy law claims, and to refile consumer protection claims, for Google devices accepting ""False Accepts"" from their smartphone voice assistants and then illegally recording and disseminating the private conversations The court found GooglePdid not have authorization to disclose any audio recordings or transcripts resulting from false accepts. It did so for analyses and improvement of Google Assistant for its own financial benefit and targeting personalized advertising to users. Google Assistant produces a script of each audio recording that it stores. Google hires human subcontractors to comparing the script to the audio recording and check the accuracy of the Google Assistant's interpretation. Google Assistant may be triggered into active listening mode (false accepts). Google stores these recordings for future advertisements. Google, Alphabet    "
"81","81","Thaler v. Perlmutter et al","Stephen Thaler, owner of an artificial intelligence system that he calls a ""creativity machine,"" challenges the refusal of Shira Perlmutter, in her capacity as the Register of Copyrights, to issue a copyright registration for a graphic art work entitled ""A Recent Entrance to Paradise,"" which Thaler alleges was authored by his ""creativity machine.""","'Generative AI'","Generative AI","'Administrative Procedure Act'","Administrative Procedure Act","'AI as Author'","AI as Author","","Creativity Machine","'No'","","United States Copyright Office","Federal: US Dist. Ct. D. D.C.","06/02/2022","","0","Active","12/5/2022","7/20/2023","","Bob","The U.S. Copyright Office has taken the position that only works created by human authors are subject to copyright protection under U.S. law. In this action brought under the Administrative Procedure Act, plaintiff Stephen Thaler is challenging the Copyright Office's refusal to register a graphic art work that was allegedly created by artificial intelligence, and is thereby challenging the Copyright Office's position, and seeking recognition of copyright protection for works created by artificial intelligence.","On November 13, 2018, Stephen Thaler applied to the U.S. Copyright Office to register a claim of copyright in a graphic art work titled ""A Recent Entrance to Paradise.""  He listed the ""Creativity Machine"" as the author of the work, noting that the work was ""autonomously created by machine,"" and he listed himself as the Copyright Claimant, by virtue of his ""ownership of the machine."" The Copyright Office refused to register the work on the ground that it lacked human authorship. In a letter opinion dated February 14, 2022, the U.S. Copyright Office Review Board rejected Thaler's Second Request for Reconsideration for Refusal to Register the work. The Review Board concluded that judicial precedent, federal agency precedent, and Copyright Office practice all require human authorship as a condition of copyright protect.  The Review Board also rejected Thaler's contention that the work was a ""work made for hire.""  Thaler then brought this action in federal court under the Administrative Procedure Act, challenging the Copyright Office's refusal to register a work alleged to have been created by artificial intelligence. Thaler moved for summary judgment on January 10, 2023; the Copyright Office filed a cross-motion for summary judgment on February 7, 2023. Thaler then filed an opposition to the Copyright Office's motion on March 7, 2023, and the Copyright Office filed a reply on April 5, 2023.","Copyright Office Reply in support of its cross-motion for summary judgment","4/5/2023","Thaler v. Perlmutter et al Stephen Thaler, owner of an artificial intelligence system that he calls a ""creativity machine,"" challenges the refusal of Shira Perlmutter, in her capacity as the Register of Copyrights, to issue a copyright registration for a graphic art work entitled ""A Recent Entrance to Paradise,"" which Thaler alleges was authored by his ""creativity machine."" The U.S. Copyright Office has taken the position that only works created by human authors are subject to copyright protection under U.S. law. In this action brought under the Administrative Procedure Act, plaintiff Stephen Thaler is challenging the Copyright Office's refusal to register a graphic art work that was allegedly created by artificial intelligence, and is thereby challenging the Copyright Office's position, and seeking recognition of copyright protection for works created by artificial intelligence. On November 13, 2018, Stephen Thaler applied to the U.S. Copyright Office to register a claim of copyright in a graphic art work titled ""A Recent Entrance to Paradise.""  He listed the ""Creativity Machine"" as the author of the work, noting that the work was ""autonomously created by machine,"" and he listed himself as the Copyright Claimant, by virtue of his ""ownership of the machine."" The Copyright Office refused to register the work on the ground that it lacked human authorship. In a letter opinion dated February 14, 2022, the U.S. Copyright Office Review Board rejected Thaler's Second Request for Reconsideration for Refusal to Register the work. The Review Board concluded that judicial precedent, federal agency precedent, and Copyright Office practice all require human authorship as a condition of copyright protect.  The Review Board also rejected Thaler's contention that the work was a ""work made for hire.""  Thaler then brought this action in federal court under the Administrative Procedure Act, challenging the Copyright Office's refusal to register a work alleged to have been created by artificial intelligence. Thaler moved for summary judgment on January 10, 2023; the Copyright Office filed a cross-motion for summary judgment on February 7, 2023. Thaler then filed an opposition to the Copyright Office's motion on March 7, 2023, and the Copyright Office filed a reply on April 5, 2023. United States Copyright Office Creativity Machine Generative AI Administrative Procedure Act AI as Author"
"97","97","Matsko v. Tesla","Plaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.","'Autonomous Vehicles'","Autonomous Vehicles","'Breach of Implied Warranty'","Breach of Implied Warranty","'Misrepresentation','Autonomous Vehicle'","Misrepresentation, Autonomous Vehicle","'Autopilot'","Autopilot","'Yes'","","Tesla, Inc.; Tesla Finance, LLC; Tesla Lease Trust","Federal: US Dist. Ct. N.D. Ca.","09/04/2022","","0","Active","2/1/2023","7/20/2023","","Bob","","Plaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.  Plaintiff filed complaint on September 14, 2022, and Amended Complaint on September 23, 2022.  Defendants filed motion to dismiss and motion to compel arbitration.  Plaintiffs filed motion for preliminary injunction and motion for class certification.  As of July 20, 2023, court had not yet ruled on motions.","Plaintiffs file motion or preliminary injunction and for class certification","3/22/2023","Matsko v. Tesla Plaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.  Plaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.  Plaintiff filed complaint on September 14, 2022, and Amended Complaint on September 23, 2022.  Defendants filed motion to dismiss and motion to compel arbitration.  Plaintiffs filed motion for preliminary injunction and motion for class certification.  As of July 20, 2023, court had not yet ruled on motions. Tesla, Inc.; Tesla Finance, LLC; Tesla Lease Trust Autopilot Autonomous Vehicles Breach of Implied Warranty Misrepresentation, Autonomous Vehicle"
"10","10","ACLU v. DOJ","The ACLU of Massachusetts brought suit against the Department of Justice, Drug Enforcement Agency and the Federal Bureau of Investigation in response to the lack of response to their Freedom of Information Act Request for all policies, contracts and records relating to facial recognition and identifying program and technology.","'Constitutional Law','Facial Recognition'","Facial Recognition","'FOIA 5 U.S.C. § 552','Injunction'","FOIA 5 U.S.C. § 552; Injunction","'Facial Recognition','Privacy','Use of Race','Unreliability/Miscalculationns'","Facial Recognition; Use of Race; Unreliability/Miscalculation; Privacy","","","","","ACLU","Federal: US Dist. Ct D. Massachusetts","10/31/2019","No","0","Active","2/4/2021","3/16/2022","","","","","Closed without entry of judgement (may be reopened upon motion of any party when their present cooperation on FBI's processing of responsive documents comes to an end).","10/13/2021","ACLU v. DOJ The ACLU of Massachusetts brought suit against the Department of Justice, Drug Enforcement Agency and the Federal Bureau of Investigation in response to the lack of response to their Freedom of Information Act Request for all policies, contracts and records relating to facial recognition and identifying program and technology.   ACLU  Facial Recognition FOIA 5 U.S.C. § 552; Injunction Facial Recognition; Use of Race; Unreliability/Miscalculation; Privacy"
"26","26","Hudson v. Tesla, Inc.","Customer brought suit against Tesla for autonomous vehicle crash when his vehicle did not detect another vehicle, arguing that Tesla's advertising convinced customers that the autopilot could safely operate with minimal driver input and oversight","'Autonomous Vehicles'","Autonomous Vehicles","'Breach of Implied Warranty','Florida’s Deceptive and Unfair Trade Practices Act','Negligence'","Negligence; Breach of Implied Warranty; Florida’s Deceptive and Unfair Trade Practices Act","'False Positive Dilemma','Product Liability','Underperformance'","Product Liability; Underperformance; False Positive Dilemma","'Autopilot'","Autopilot","","No","","State: Florida","10/30/2018","?","0","?","2/12/2021","2/14/2021","","","A personal injury and consumer protection lawsuit for injuries plaintiff suffered when his Tesla crashed into another vehicle while in autopilot mode. In this case the Autopilot of the Tesla was unable to detected a disabled vehicle that had stalle in his lane, and in turn crashed into it.","On the Morning of October 12, 2016 Hudson was travelling southbound at approximately 80 mph in the left lane on a stretch of Florida Turnpike. He had engage the Tesla's autopilot and was relaxing during his commute. Unbeknownst to Hudson, his model S was rapidly approaching a disabled vehicle that had stalled in his lane of travel. Suddenly, and without any warning, the Model S crashed into the disabled vehicle. The entire front area of Hudson’s model S was destroyed. Hudson suffered permanent injuries.

Hudson specifically bought his 2017 Tesla Model S with the autopilot feature because Tesla represented that the autopilot system could detect a hazard, and alert the driver if necessary. The sales rep assured Hudson that all ne needed to da as the""driver"" was to occasionally place his hand on the steering wheel and the vehicle would do everything else. 

The case is still pending","Motion to Dismiss Filed","7/9/2020","Hudson v. Tesla, Inc. Customer brought suit against Tesla for autonomous vehicle crash when his vehicle did not detect another vehicle, arguing that Tesla's advertising convinced customers that the autopilot could safely operate with minimal driver input and oversight A personal injury and consumer protection lawsuit for injuries plaintiff suffered when his Tesla crashed into another vehicle while in autopilot mode. In this case the Autopilot of the Tesla was unable to detected a disabled vehicle that had stalle in his lane, and in turn crashed into it. On the Morning of October 12, 2016 Hudson was travelling southbound at approximately 80 mph in the left lane on a stretch of Florida Turnpike. He had engage the Tesla's autopilot and was relaxing during his commute. Unbeknownst to Hudson, his model S was rapidly approaching a disabled vehicle that had stalled in his lane of travel. Suddenly, and without any warning, the Model S crashed into the disabled vehicle. The entire front area of Hudson’s model S was destroyed. Hudson suffered permanent injuries.

Hudson specifically bought his 2017 Tesla Model S with the autopilot feature because Tesla represented that the autopilot system could detect a hazard, and alert the driver if necessary. The sales rep assured Hudson that all ne needed to da as the""driver"" was to occasionally place his hand on the steering wheel and the vehicle would do everything else. 

The case is still pending  Autopilot Autonomous Vehicles Negligence; Breach of Implied Warranty; Florida’s Deceptive and Unfair Trade Practices Act Product Liability; Underperformance; False Positive Dilemma"
"42","42","Zynda et al. v. Zimmer et al.","Settlement agreement in which Michigan's Unemployment Insurance Agency admits no wrongdoing in its use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, in exchange for terms of reasonable review and investigation into UIA's procedure and policy, requiring future commnications in plain language and with adequate notice, and providing the claimant with reasons for why they were flagged for fraud and ability to appeal","'Agency','Civil Rights','Fraud','Unemployment Insurance'","Civil Rights; Unemployment Insurance; Fraud; Agency","'Due Process','Injunction','Social Security Act'","Injunction; Due Process; Social Security Act","'Accountability','Lack of Human Review','Lack of Remedy','Notice','Role of Expert Testimony','Miscalculation'","Miscalculation; Accountability; Notice; Lack of Human Review; Role of Expert Testimony; Lack of Remedy;","'MIDAS'","MiDAS","","No","","Federal: US Dist. Ct. E. D. Michigan","4/21/2015","Yes","-1","Inactive: Settled","3/3/2021","3/5/2021","","","","","Dismissed","2/2/2017","Zynda et al. v. Zimmer et al. Settlement agreement in which Michigan's Unemployment Insurance Agency admits no wrongdoing in its use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, in exchange for terms of reasonable review and investigation into UIA's procedure and policy, requiring future commnications in plain language and with adequate notice, and providing the claimant with reasons for why they were flagged for fraud and ability to appeal    MiDAS Civil Rights; Unemployment Insurance; Fraud; Agency Injunction; Due Process; Social Security Act Miscalculation; Accountability; Notice; Lack of Human Review; Role of Expert Testimony; Lack of Remedy;"
"59","59","WeRide Corp. v. Kun Huang","Autonomous vehicle companies won suit against a former employee and his current autonomous vehicle employer for misappropriation of trade secrets, succeeding on likelihood to succeed on the merits when they demonstrated  particular files in the code base and demonstrated that the source code was only accessible on-site or using a VPN by employees.","'Autonomous Vehicles','Intellectual Property'","Autonomous Vehicles; Intellectual Property","","","'Transparency/Trade Secrecy','Functionality','Autonomous Vehicle'","","","","","","","Federal: United States District Court, N.D. California, San Jose Division","11/29/2018","","0","Inactive","10/14/2021","11/29/2021","In Progress","Jenna","A key finding for misappropraition cases, the court here found that ""[t]he implausibly fast development of technology can contribute to finding misappropriation"" when AllRide and former WeRide employees developed strikingly similar technology in a fast turnaround from leaving WeRide.","","Date Terminated, last known filing","5/8/2020","WeRide Corp. v. Kun Huang Autonomous vehicle companies won suit against a former employee and his current autonomous vehicle employer for misappropriation of trade secrets, succeeding on likelihood to succeed on the merits when they demonstrated  particular files in the code base and demonstrated that the source code was only accessible on-site or using a VPN by employees. A key finding for misappropraition cases, the court here found that ""[t]he implausibly fast development of technology can contribute to finding misappropriation"" when AllRide and former WeRide employees developed strikingly similar technology in a fast turnaround from leaving WeRide.    Autonomous Vehicles; Intellectual Property  "
"78","78","Carpenter v. McDonald’s Corporation","Customer brought putative class action against fast food restaurant, asserting violation of Illinois Biometric Information Privacy Act (BIPA) by collecting customers’ voiceprint biometrics via artificial intelligence (AI) voice assistant technology in drive-through lanes and storing, disclosing, and disseminating biometric information without customers' consent.","'Biometric Data'","Biometric Data","'Biometric Information Privacy Act'","Biometric Information Privacy Act","'Privacy'","Privacy","","","","","","N.D. Illinois","May 28 2021","","0","","4/11/2022","4/11/2022","","","At the stage of motion to dismiss, the court can consider patent for fast food restaurant's AI voice assistant technology.","McDonald's deploys an artificial intelligence voice assistant in the drive-through lanes of various McDonald's restaurants that uses voice recognition technology to allow customers to place orders without interacting with a person.
The court considered patent for fast food restaurant's AI voice assistant technology and found that the technology may allow McDonald's to collect, collate, or otherwise obtain a voiceprint.","","","Carpenter v. McDonald’s Corporation Customer brought putative class action against fast food restaurant, asserting violation of Illinois Biometric Information Privacy Act (BIPA) by collecting customers’ voiceprint biometrics via artificial intelligence (AI) voice assistant technology in drive-through lanes and storing, disclosing, and disseminating biometric information without customers' consent. At the stage of motion to dismiss, the court can consider patent for fast food restaurant's AI voice assistant technology. McDonald's deploys an artificial intelligence voice assistant in the drive-through lanes of various McDonald's restaurants that uses voice recognition technology to allow customers to place orders without interacting with a person.
The court considered patent for fast food restaurant's AI voice assistant technology and found that the technology may allow McDonald's to collect, collate, or otherwise obtain a voiceprint.   Biometric Data Biometric Information Privacy Act Privacy"
"94","94","Getty Images (US), Inc. v. Stability AI, Inc.","Leading stock image distributor sues developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output.","'Generative AI'","Generative AI","'Copyright Infringement','Trademark infringement','Unfair and Deceptive Trade Practices','Unfair Competition','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Trademark infringement, Unfair and Deceptive Trade Practices, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information","'Copyright Infringement'","Copyright Infringement","'Stable Diffusion'","Stable Diffusion","'No'","","","Federal: US Dist. Ct. D. Del.","02/03/2023","","0","Active","7/12/2023","7/27/2023","","Bob","","Leading stock image distributor Getty Images sues Stability AI, Inc., developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output. Case was assigned to Judge Gregory Williams on February 8, 2023.  On May 2, 2023, defendant filed motion to dismiss for lack of personal jurisdiction, for failure to join a necessary party, and for failure to state a claim, and alternatively to transfer claim to the Northern District of California.","Defendant filed motion to dismiss or to transfer","5/2/2023","Getty Images (US), Inc. v. Stability AI, Inc. Leading stock image distributor sues developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output.  Leading stock image distributor Getty Images sues Stability AI, Inc., developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output. Case was assigned to Judge Gregory Williams on February 8, 2023.  On May 2, 2023, defendant filed motion to dismiss for lack of personal jurisdiction, for failure to join a necessary party, and for failure to state a claim, and alternatively to transfer claim to the Northern District of California.  Stable Diffusion Generative AI Copyright Infringement, Trademark infringement, Unfair and Deceptive Trade Practices, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information Copyright Infringement"
"2","2","Henderson v. Steinsburg","Prisoner files Section 1983 challenge to denial of parole using COMPAS risk assessment report, claims COMPAS algorithm discriminates on basis of race in violation of Equal Protection Clause","'Criminal Justice','Sentencing'","Criminal Justice; Sentencing","'42 USC 1983','Equal Protection'","42 USC 1983, Equal Protection","'Use of Race'","Use of Race","'COMPAS'","COMPAS","","No","","Federal: US Dist. Ct. W.D. Wisconsin","7/16/2018","Yes","-1","Active","1/30/2021","5/1/2022","RA Done; Check for New Activity","Sydney","Plaintiff argued that defendants in charge of Northpointe knew of COMPAS's racial bias, and that the Wisconsin Parole Board defendants still used COMPAS even knowing it was biased instead of paying for an update or improvement. Henderson also argued that he had no way of knowing how the algorithm came to the predetermined, biased conclusion because he was not allowed access to the proprietary tool and that the correctional officers could inaccurately provide ""false negative comments"" into African American inmates' files without them knowing. 

The judge differentiates Henderson from Loomis because Loomis was a due process case about trade secrecy and use of gender, not an equal protection case, and studies do raise the concern about COMPAS and race. The Judge also notes that in the defendant's second motion to dismiss, it is not clear if the 2014 COMPAS risk assessment that produced the low risk was the same used to determine parole one year later, and thus converted the motion to dismiss into a summary judgment motion to give both plaintiff and defendants time for new briefs. In the motion for summary judgement, defendant insisted that there was no connection between COMPAS and Henderson's denial of parole.","Titus Henderson was convicted and incarcerated in the state of Wisconsin in July 1995, serving a 40-year sentence. In October 2014, COMPAS determined Henderson was low risk. After a Parole Hearing in November 2015, Henderson claims he was denied Parole and transfer from Wisconsin to Mississippi because of COMPAS's biased algorithm for both gender and against African-Americans because he would not sign the interstate compact release because it did not apply to him as a PMR inmate.

In a March 2020 Memorandum, the Judge converted the Motion to Dismiss into a Summary Judgement Motion because he could not decide the issue solely on the pleadings and the 2014 COMPAS report, requiring new brief and Henderson's response. Judge rejected defendants' claims in their first motion to dismiss, arguing there is enough information to infer that the Department of Corrections knew of the racial bias and its harm to African American inmates, and rejecting the defendant's use of Loomis because Loomis was not an equal protection case. The Judge also denied in part defendants' argument that Henderson did not exhaust all other avenues before bringing this claim, only dismissing one defendant from the case.

Defendants filed a motion for summary judgement on April 9, 2020, arguing that Henderson was not denied parole based on the COMPAS report.

On November 12, 2020 defendants jointly filed to stay deadlines, with trial supposed to start on January 11, 2021 because they were waiting on responses to their motion to strike plaintiff's expert witness.

On March 26, 2021 the Judge ordered the case dismissed, and on April 5, 2021 Henderson filed notice of appeal in the Seventh Circuit.","Appeal to 7th Circuit filed","4/5/2021","Henderson v. Steinsburg Prisoner files Section 1983 challenge to denial of parole using COMPAS risk assessment report, claims COMPAS algorithm discriminates on basis of race in violation of Equal Protection Clause Plaintiff argued that defendants in charge of Northpointe knew of COMPAS's racial bias, and that the Wisconsin Parole Board defendants still used COMPAS even knowing it was biased instead of paying for an update or improvement. Henderson also argued that he had no way of knowing how the algorithm came to the predetermined, biased conclusion because he was not allowed access to the proprietary tool and that the correctional officers could inaccurately provide ""false negative comments"" into African American inmates' files without them knowing. 

The judge differentiates Henderson from Loomis because Loomis was a due process case about trade secrecy and use of gender, not an equal protection case, and studies do raise the concern about COMPAS and race. The Judge also notes that in the defendant's second motion to dismiss, it is not clear if the 2014 COMPAS risk assessment that produced the low risk was the same used to determine parole one year later, and thus converted the motion to dismiss into a summary judgment motion to give both plaintiff and defendants time for new briefs. In the motion for summary judgement, defendant insisted that there was no connection between COMPAS and Henderson's denial of parole. Titus Henderson was convicted and incarcerated in the state of Wisconsin in July 1995, serving a 40-year sentence. In October 2014, COMPAS determined Henderson was low risk. After a Parole Hearing in November 2015, Henderson claims he was denied Parole and transfer from Wisconsin to Mississippi because of COMPAS's biased algorithm for both gender and against African-Americans because he would not sign the interstate compact release because it did not apply to him as a PMR inmate.

In a March 2020 Memorandum, the Judge converted the Motion to Dismiss into a Summary Judgement Motion because he could not decide the issue solely on the pleadings and the 2014 COMPAS report, requiring new brief and Henderson's response. Judge rejected defendants' claims in their first motion to dismiss, arguing there is enough information to infer that the Department of Corrections knew of the racial bias and its harm to African American inmates, and rejecting the defendant's use of Loomis because Loomis was not an equal protection case. The Judge also denied in part defendants' argument that Henderson did not exhaust all other avenues before bringing this claim, only dismissing one defendant from the case.

Defendants filed a motion for summary judgement on April 9, 2020, arguing that Henderson was not denied parole based on the COMPAS report.

On November 12, 2020 defendants jointly filed to stay deadlines, with trial supposed to start on January 11, 2021 because they were waiting on responses to their motion to strike plaintiff's expert witness.

On March 26, 2021 the Judge ordered the case dismissed, and on April 5, 2021 Henderson filed notice of appeal in the Seventh Circuit.  COMPAS Criminal Justice; Sentencing 42 USC 1983, Equal Protection Use of Race"
"18","18","Louisiana v. Hickerson","Court denied motion to overturn the conviction of racketeering and a new trial in light of the Prosecutor not disclosing the use of the Palantir Gotham system that mapped gang members' connections, as Gotham was not used in Hickerson's case, Hickerson files full appeal","'Criminal Justice'","Criminal Justice;","'Conviction Challenge'","Conviction Challenge","'Predictive Policing','Unaware of Use of Algorithm','Use of Race'","Use of Race; Predictive Policing; Unaware of Use of Algorithm","'Gotham'","Gotham","","No","","State: Louisiana","6/1/2013","Yes","-1","Inactive: denial of motion for new trial","2/11/2021","3/13/2021","","","","","Affirm in part, vacate in part Hickerson's conviction","12/30/2020","Louisiana v. Hickerson Court denied motion to overturn the conviction of racketeering and a new trial in light of the Prosecutor not disclosing the use of the Palantir Gotham system that mapped gang members' connections, as Gotham was not used in Hickerson's case, Hickerson files full appeal    Gotham Criminal Justice; Conviction Challenge Use of Race; Predictive Policing; Unaware of Use of Algorithm"
"34","34","ACLU v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated violates BIPA. Sought injunctive relief and litigation costs, court considering motion to dismiss on April 2","'Facial Recognition'","Facial Recognition","'BIPA'","BIPA","'Privacy'","Privacy","'Clearview'","Clearview","","No","","State: Ill. Cir. Ct. (Cook County, Chancery Div.)","5/28/2020","","0","Active","2/15/2021","4/2/2021","","","This class action filed by the ACLU was not consolidated into the In Re Clearview Litigation because it has remained in Cook County Court while the other nine cases were in federal court. While the ACLU is concerned about overall individual privacy and security, other plaintiffs have more specific issues: CAASE argues Clearview's use with police officers will make abuse victims more fearful to work with police, Mujeres raises a similar complaint for their Latina specific abuse victims clients, and SWOP similarly argues for the privacy of current and former sex workers and could interfere with SWOP volunteers outreach and services.","The plaintiffs filed this class action against Clearview for violating plaintiffs' rights under BIPA by collecting images and data without their knowledge, ""much less the consent"" of the plaintiffs, then storing the data. The complaint requested injunctive relief against Clearview for collecting face prints from photographs online, compiling those into a database, and keeping links of where they got the images. The crux of the issue is that Clearview has not attempted to inform or obtain consent from the people it is collecting data on. The next issue is Clearview's clientele: it offered billionaires, individual police officers without the agency's knowledge, and multiple major retail chains.

Clearview ""voluntarily"" ended all accounts of all non-government users and all Illinois entities in an attempt to avoid jurisdiction.

Clearview filed its motion to dismiss on October 7, 2020, arguing: 1. Clearview is not subject to jurisdiction in Illinois because it ended all of its conduct in Illinois, alternatively suggests it collects photos from NY, 2. BIPA does not regulate out of state conduct, 3. Clearview is protected under the First Amendment, and 4. even if Clearview was subject to BIPA, BIPA does not regulate photographs. 

Plaintiffs filed a surreply on January 5, 2021 that 1. BIPA is not a direct regulation of speech, 2. BIPA is not subject to strict scrutiny and 3. BIPA survives intermediate scrutiny.","Court will rule on Motion to Dismiss 08/27/2021","4/2/2021","ACLU v. Clearview AI, Inc. Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated violates BIPA. Sought injunctive relief and litigation costs, court considering motion to dismiss on April 2 This class action filed by the ACLU was not consolidated into the In Re Clearview Litigation because it has remained in Cook County Court while the other nine cases were in federal court. While the ACLU is concerned about overall individual privacy and security, other plaintiffs have more specific issues: CAASE argues Clearview's use with police officers will make abuse victims more fearful to work with police, Mujeres raises a similar complaint for their Latina specific abuse victims clients, and SWOP similarly argues for the privacy of current and former sex workers and could interfere with SWOP volunteers outreach and services. The plaintiffs filed this class action against Clearview for violating plaintiffs' rights under BIPA by collecting images and data without their knowledge, ""much less the consent"" of the plaintiffs, then storing the data. The complaint requested injunctive relief against Clearview for collecting face prints from photographs online, compiling those into a database, and keeping links of where they got the images. The crux of the issue is that Clearview has not attempted to inform or obtain consent from the people it is collecting data on. The next issue is Clearview's clientele: it offered billionaires, individual police officers without the agency's knowledge, and multiple major retail chains.

Clearview ""voluntarily"" ended all accounts of all non-government users and all Illinois entities in an attempt to avoid jurisdiction.

Clearview filed its motion to dismiss on October 7, 2020, arguing: 1. Clearview is not subject to jurisdiction in Illinois because it ended all of its conduct in Illinois, alternatively suggests it collects photos from NY, 2. BIPA does not regulate out of state conduct, 3. Clearview is protected under the First Amendment, and 4. even if Clearview was subject to BIPA, BIPA does not regulate photographs. 

Plaintiffs filed a surreply on January 5, 2021 that 1. BIPA is not a direct regulation of speech, 2. BIPA is not subject to strict scrutiny and 3. BIPA survives intermediate scrutiny.  Clearview Facial Recognition BIPA Privacy"
"50","50","Thaler v. Comptroller General of Patents Trade Marks and Designs","In a landmark decision, the Australian Federal Court set aside the Deputy Commissioner's decision that an artificial intelligence program could not be an inventor, allowing application to go forward when scientist Thaler listed the algorithm DABUS as the inventor for which he owns the copyright to the DABUS source code. Australia sides with South Africa, who outright granted Thaler's application, whereas the US, EU, and UK do not view AI as inventors.","'Intellectual Property'","Patent Application; Intellectual Property; Pharmaceuticals","'Patent Application'","Patents Act of 1991; Patent Acts of 1990; Patent Cooperation Treaty;","'AI as Inventor'","Algorithm as Inventor; Algorithm; semi-autonomous systems; Statutory Interpretation; Statutory Definition;","'DABUS'","DABUS","","No","","International: Federal Court of Australia","2/09/2021","Yes","-1","Active: On Appeal","9/28/2021","10/3/2021","RA Done; Check for New Activity","Jenna","The judge argues the Deputy Commissioner and Commissioner before him confused the identity of a patentee with an inventor, arguing that the inventor does not have to be human, because by that logic one with a patentable invention but no inventor could not apply for the patent, which goes against Section 2A of the Patent Act. The judge explicitly stated that he does not offer a definition for ""artificial intelligence."" The judge also distinguished DABUS as semi-autonomous rather than an automation. The judge also goes into depth explaining how artificial neural networks are the most sophisticated form of machine learning.","Plaintiff Dr. Stephen Thaler filed this appeal from the Deputy Commissioner and Commissioner's ruling on his patent application. Thaler owns the copyright to the source code of DABUS (Device for Autonomous Bootstrapping of Unified Sentience) a type of machine learning, trained by both supervised and unsupervised learning, that learns new concepts which are encoded as chained associative memories. With each new memory, DABUS generates new patterns of information and can adapt without human input. Thaler applied for a patent for ""food container and devices and methods for attracting enhanced attention"" on September 17, 2019. The Deputy Commissioner found the application had lapsed on September 15, 2020, because an inventor had to be a person. Because the Commission decided Thaler did not comply with application instructions by listing a human inventor. Judicial review found that this was incorrect because there is no definition of an inventor or explicit statement that an inventor has to be a human in the Act. The statute only provides that ""reg 3.2C(2)(aa), an applicant must provide the name of the inventor of the invention to which the application relates."" Section 9 requires the applicant to be a human person. Upon a finding for Thaler, the IP Commission noted it would appeal this Federal Court Decision.","Notice of Appeal of Federal Court Decision","8/30/2021","Thaler v. Comptroller General of Patents Trade Marks and Designs In a landmark decision, the Australian Federal Court set aside the Deputy Commissioner's decision that an artificial intelligence program could not be an inventor, allowing application to go forward when scientist Thaler listed the algorithm DABUS as the inventor for which he owns the copyright to the DABUS source code. Australia sides with South Africa, who outright granted Thaler's application, whereas the US, EU, and UK do not view AI as inventors. The judge argues the Deputy Commissioner and Commissioner before him confused the identity of a patentee with an inventor, arguing that the inventor does not have to be human, because by that logic one with a patentable invention but no inventor could not apply for the patent, which goes against Section 2A of the Patent Act. The judge explicitly stated that he does not offer a definition for ""artificial intelligence."" The judge also distinguished DABUS as semi-autonomous rather than an automation. The judge also goes into depth explaining how artificial neural networks are the most sophisticated form of machine learning. Plaintiff Dr. Stephen Thaler filed this appeal from the Deputy Commissioner and Commissioner's ruling on his patent application. Thaler owns the copyright to the source code of DABUS (Device for Autonomous Bootstrapping of Unified Sentience) a type of machine learning, trained by both supervised and unsupervised learning, that learns new concepts which are encoded as chained associative memories. With each new memory, DABUS generates new patterns of information and can adapt without human input. Thaler applied for a patent for ""food container and devices and methods for attracting enhanced attention"" on September 17, 2019. The Deputy Commissioner found the application had lapsed on September 15, 2020, because an inventor had to be a person. Because the Commission decided Thaler did not comply with application instructions by listing a human inventor. Judicial review found that this was incorrect because there is no definition of an inventor or explicit statement that an inventor has to be a human in the Act. The statute only provides that ""reg 3.2C(2)(aa), an applicant must provide the name of the inventor of the invention to which the application relates."" Section 9 requires the applicant to be a human person. Upon a finding for Thaler, the IP Commission noted it would appeal this Federal Court Decision.  DABUS Patent Application; Intellectual Property; Pharmaceuticals Patents Act of 1991; Patent Acts of 1990; Patent Cooperation Treaty; Algorithm as Inventor; Algorithm; semi-autonomous systems; Statutory Interpretation; Statutory Definition;"
"69","69","Thaler v. Hirshfield","The court ruled that AI could not be an inventor.","'Intellectual Property','Patent'","","'Patent Application'","","'AI as Inventor'","","","","","","","State: Virginia","","","0","Active","10/28/2021","3/27/2022","","","The district rule found that the language of the Patent Act indicates an ""inventor"" is a natural person because it: was amended in 2011, when AI was already in existence. 

The Act includes a definition for ""inventor"" that uses the term ""individual"" and pronouns ""himself or herself."" Finally, the Act requires the inventor to make an oath.

The US Supreme Court considered the Dictionary Act, which would apply to the Patent Act, and concluded that the ordinary meaning of ""individual"" is a natural person.

Furthermore, Federal Circuit precedent has held that inventors must be natural persons, and this is relevant even though those decisions concerned states and corporations.","Stephen Thaler develops and applies advanced artificial intelligence (AI) systems that are capable of generating patentable output and is the owner of DABUS. He applies for patent on behalf of DABUS. Because DABUS could not execute the necessary oath or declaration that the Patent Act requires of an inventor, Thaler signed the substitute statement for DABUS and assigns DABUS's ""rights"" in the patent to him.","Appeal","","Thaler v. Hirshfield The court ruled that AI could not be an inventor. The district rule found that the language of the Patent Act indicates an ""inventor"" is a natural person because it: was amended in 2011, when AI was already in existence. 

The Act includes a definition for ""inventor"" that uses the term ""individual"" and pronouns ""himself or herself."" Finally, the Act requires the inventor to make an oath.

The US Supreme Court considered the Dictionary Act, which would apply to the Patent Act, and concluded that the ordinary meaning of ""individual"" is a natural person.

Furthermore, Federal Circuit precedent has held that inventors must be natural persons, and this is relevant even though those decisions concerned states and corporations. Stephen Thaler develops and applies advanced artificial intelligence (AI) systems that are capable of generating patentable output and is the owner of DABUS. He applies for patent on behalf of DABUS. Because DABUS could not execute the necessary oath or declaration that the Patent Act requires of an inventor, Thaler signed the substitute statement for DABUS and assigns DABUS's ""rights"" in the patent to him.     "
"86","86","Mobley v. Workday, Inc.","A class action lawsuit was brought to challenge to Workday's artificial intelligence systems and screening tools, arguing that these tools are biased against applicants who are either over the age of 40, Black, or disabled. The lawsuit argues that Workday violated the Age Discrimination in Employment Act, the Americans with Disabilities Act, and the Civil Rights Act.","'Civil Rights','Employment','Hiring'","Civil Rights, Employment, Hiring","'Civil Rights'","Civil Rights Act; ADEA; ADA","'Programmer Bias','Transparency/Trade Secrecy','Use of Race'","Programmer Bias, Transparency/Trade Secrecy, Use of Race","","ATS","'Yes'","","","N.D. Cal","02/21/2023","","0","Active","3/4/2023","3/4/2023","","","","","","","Mobley v. Workday, Inc. A class action lawsuit was brought to challenge to Workday's artificial intelligence systems and screening tools, arguing that these tools are biased against applicants who are either over the age of 40, Black, or disabled. The lawsuit argues that Workday violated the Age Discrimination in Employment Act, the Americans with Disabilities Act, and the Civil Rights Act.    ATS Civil Rights, Employment, Hiring Civil Rights Act; ADEA; ADA Programmer Bias, Transparency/Trade Secrecy, Use of Race"
"14","14","Dinerstein v. Google, LLC","Judge dismissed patient suit against Google and University of Chicago Medical Center over patient health records that the univeresity transferred to Google for machine learning data, arguing it was a prima facie violation of HIPAA, on appeal currently","'Health','Privacy'","Health; Privacy","'Breach of Contract','CCPA','HIPAA'","CCPA, HIPAA; Breach of Contract","'Personally identifiable Information','Terms of Service'","Terms of Service; Personally Identifiable Information","","","","Yes","","Federal: US Dist. Ct. N.D. Illinois","6/26/2019","Yes","-1","Active: On Appeal","2/4/2021","4/30/2022","RA Done","Molly","This case considers the issue of re-identification of de-identified health data. The University of Chicago gave Google de-identified health data to create a predictive health model. However, because of all the additional data Google has, there is a risk of the shared de-identified personal health information being re-identified. If you combine the patients geolocation information that Google already has, with the Electronic Health Records given by the hospital (which include the date and time of hospital services) Google has the data points to identify who these patients really are.","University of Chicago and Google partnered to use machine learning to create a predictive health model to reduce hospital readmission and anticipate future medical events. Part of this partnership involved the university disclosing to Google the ""de-identified"" electronic health records of hospital patients. Dinerstein was a patient and sued the hospital for breach of contract, sued Google for tortious interference with contract, and sued them both for intrusion upon seclusion.","Oral Argument, 7th Circuit","9/17/2021","Dinerstein v. Google, LLC Judge dismissed patient suit against Google and University of Chicago Medical Center over patient health records that the univeresity transferred to Google for machine learning data, arguing it was a prima facie violation of HIPAA, on appeal currently This case considers the issue of re-identification of de-identified health data. The University of Chicago gave Google de-identified health data to create a predictive health model. However, because of all the additional data Google has, there is a risk of the shared de-identified personal health information being re-identified. If you combine the patients geolocation information that Google already has, with the Electronic Health Records given by the hospital (which include the date and time of hospital services) Google has the data points to identify who these patients really are. University of Chicago and Google partnered to use machine learning to create a predictive health model to reduce hospital readmission and anticipate future medical events. Part of this partnership involved the university disclosing to Google the ""de-identified"" electronic health records of hospital patients. Dinerstein was a patient and sued the hospital for breach of contract, sued Google for tortious interference with contract, and sued them both for intrusion upon seclusion.   Health; Privacy CCPA, HIPAA; Breach of Contract Terms of Service; Personally Identifiable Information"
"30","30","Calderon v. Clearview AI, Inc.","Violates BIPA; seeking injunctive relief (including deletion of data), statutory damages, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA'","BIPA","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal:  US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","2/13/2020","Yes","-1","Inactive","2/15/2021","2/15/2021","","","Like other Illinois cases, this complaint is brought against both Clearview and CDW. However, a complaint was filed in both Illinois and SDNY on the same day. Mutnick's motion to intervene was denied on May 29, 2020.","The plaintiffs filed complaint in SDNY even though they are residetn and citizens of Illinois. The complaint alleges that the photographs of the plaintiffs contained metadata reflecting the location of Ilinois, and thus plaintiffs are ""informed and believes"" that their facial biometrics are contained in Clearview's database and have been disclosed to and used by CDW and CPD. 

On April 14, the Judge issued a directive to consolidate the two New York cases before her, also indicating that the cases were better suited for Illinois because they were about Illinois statutes. Judge said: ""There are only two related cases pending before me. Should this New York court end up being the place where this Illinois statute gets interpreted, and where alleged violations of Illinois law are litigated, my inclination would be to consolidate the two cases and allow the three law firms involved for the plaintiffs to divide the laboring oar, on the understanding that I would not be paying three, or even two, sets of lawyers to appear and do the work of one at any conference, hearing, deposition, or other event. ... I simply have two related but identical class actions in front of me, as to which attorneys' fees will be parceled out eventually (should plaintiffs prevail) as though it were a single case. I thus decline to take any action on the ""lead plaintiffs counsel"" motion filed in Calderon until I have entertained any motions addressed to the complaints that may be filed by the defendants. In that regard, the cases shall be consolidated, and a single motion shall be filed under each docket number, addressed to the pleadings as they have been filed. The allegations against the common defendant (Clearview) are in all relevant respects identical; there is no need for separate motions in the two cases.""

Mutnick's motion to intervene was denied, and this case did not see any motion to dismiss from Clearview before it was transferred.","MDL Transfer Out","1/12/2021","Calderon v. Clearview AI, Inc. Violates BIPA; seeking injunctive relief (including deletion of data), statutory damages, and litigation costs Like other Illinois cases, this complaint is brought against both Clearview and CDW. However, a complaint was filed in both Illinois and SDNY on the same day. Mutnick's motion to intervene was denied on May 29, 2020. The plaintiffs filed complaint in SDNY even though they are residetn and citizens of Illinois. The complaint alleges that the photographs of the plaintiffs contained metadata reflecting the location of Ilinois, and thus plaintiffs are ""informed and believes"" that their facial biometrics are contained in Clearview's database and have been disclosed to and used by CDW and CPD. 

On April 14, the Judge issued a directive to consolidate the two New York cases before her, also indicating that the cases were better suited for Illinois because they were about Illinois statutes. Judge said: ""There are only two related cases pending before me. Should this New York court end up being the place where this Illinois statute gets interpreted, and where alleged violations of Illinois law are litigated, my inclination would be to consolidate the two cases and allow the three law firms involved for the plaintiffs to divide the laboring oar, on the understanding that I would not be paying three, or even two, sets of lawyers to appear and do the work of one at any conference, hearing, deposition, or other event. ... I simply have two related but identical class actions in front of me, as to which attorneys' fees will be parceled out eventually (should plaintiffs prevail) as though it were a single case. I thus decline to take any action on the ""lead plaintiffs counsel"" motion filed in Calderon until I have entertained any motions addressed to the complaints that may be filed by the defendants. In that regard, the cases shall be consolidated, and a single motion shall be filed under each docket number, addressed to the pleadings as they have been filed. The allegations against the common defendant (Clearview) are in all relevant respects identical; there is no need for separate motions in the two cases.""

Mutnick's motion to intervene was denied, and this case did not see any motion to dismiss from Clearview before it was transferred.  Clearview Facial Recognition BIPA Privacy"
"46","46","In the Matter of HireVue, Inc.","EPIC filed a complaint and request for investigation, injunction, and other relief with the FTC, arguing HireVue's opaque and proprietary tools were unproven, biased, and invasive as it claimed to measure ""cognitive ability,"" ""psychological traits,"" ""emotional intelligence,"" and ""social aptitudes"" of job applicants without using facial recognition technology.","'Employment','Facial Recognition','Hiring'","Employment; Hiring; Facial Recognition","'FTC Act','Public Policy','Unfair and Deceptive Trade Practices'","Unfair and Deceptive Trade Practices; FTC Act; Public Policy","'Lack of Scholarly Review','Programmer Bias','Transparency/Trade Secrecy','Use of Race','User of Gender'","Use of Race; Use of Gender; Programmer Bias; Trade Secrecy / Transparency; Lack of Scholarly Review","'HireVue'","HireVue","","No","EPIC; HireVue","Government: FTC","11/9/2019","No","0","Active","3/6/2021","3/17/2021","RA Done; Check for New Activity","Jenna","HireVue provides a service to companies to evaluate their job candidates' facial expressions, gestures, posture, and tone. Candidates do not have access to the data or factors used to generate the algorithmic assessment. EPIC cites statistics that facial recognition technology discriminates based on skin tone, neurological differences with eye movement, gender. EPIC asserts that these algorithms were programmed with the top performers being white males, thus inherently biased. 

The main issues of the public policy principles are that HireVue's findings cannot be challenged, subject ot trade secrecy that candidates do not know how they are evaluated and cannot access that information, and that HireVue has not shown the accuracy and validity of its assessments.

EPIC's argument relies heavily on public policy and cites to the FTC's 2019 finding that Facebook's facial recognition technology was deceptive and misrepresented how much the consumer could control their privacy. 

In response to public outcry, HireVue announced on January 21, 2021 that it would stop relying on facial analysis for job assessment.","EPIC filed a complaint with the FTC on November 19, 2019 that HireVue has violated Section 5 of the FTC Act engaging in unfair and deceptive practices by making claims to consumers without a reasonable basis for the claims, and causes or is likely to cause substantial injury ot ht consumer, and misrepresented the amount of control consumers had over their privacy. 

HireVue uses both an applicant-recorded video interview and online games to evaluate ""thousands of data points"" from a candidate, then using predictive algorithms to calculate the job candidate's employability. EPIC notes that job candidates do not have access to the ""training data, factors, logic, or techniques used to generate each algorithmic assessment. In some cases, even HireVue is unaware of the basis for an algorithmic assessment."" EPIC claims that HireVue is incorrect to say it does not engage facial recognition technology. Next, EPIC claims that HireVue's recruiting tools are biased and discriminatory by gender, those with neurological disorders, by race, and attempting to identify sexual orientation.

Along with the FTC Act, EPIC brings this action citing to public policy AI Principles from the Organization for Economic Cooperation and Development (""OECD"") and the Universal Guidelines for Artificial Intelligence (""UGAI"") The complaint states HireVue violated the policies of Fairness, Security/Safety, Transparency and Explainability, Accountability, Accuracy/REliability and Validity.

The FTC has not published any indication of where the investigation is into the matter.","Hirevue is under investigation and announced that it will stop relying on ""facial analysis"" to assess job candidate","1/21/2021","In the Matter of HireVue, Inc. EPIC filed a complaint and request for investigation, injunction, and other relief with the FTC, arguing HireVue's opaque and proprietary tools were unproven, biased, and invasive as it claimed to measure ""cognitive ability,"" ""psychological traits,"" ""emotional intelligence,"" and ""social aptitudes"" of job applicants without using facial recognition technology. HireVue provides a service to companies to evaluate their job candidates' facial expressions, gestures, posture, and tone. Candidates do not have access to the data or factors used to generate the algorithmic assessment. EPIC cites statistics that facial recognition technology discriminates based on skin tone, neurological differences with eye movement, gender. EPIC asserts that these algorithms were programmed with the top performers being white males, thus inherently biased. 

The main issues of the public policy principles are that HireVue's findings cannot be challenged, subject ot trade secrecy that candidates do not know how they are evaluated and cannot access that information, and that HireVue has not shown the accuracy and validity of its assessments.

EPIC's argument relies heavily on public policy and cites to the FTC's 2019 finding that Facebook's facial recognition technology was deceptive and misrepresented how much the consumer could control their privacy. 

In response to public outcry, HireVue announced on January 21, 2021 that it would stop relying on facial analysis for job assessment. EPIC filed a complaint with the FTC on November 19, 2019 that HireVue has violated Section 5 of the FTC Act engaging in unfair and deceptive practices by making claims to consumers without a reasonable basis for the claims, and causes or is likely to cause substantial injury ot ht consumer, and misrepresented the amount of control consumers had over their privacy. 

HireVue uses both an applicant-recorded video interview and online games to evaluate ""thousands of data points"" from a candidate, then using predictive algorithms to calculate the job candidate's employability. EPIC notes that job candidates do not have access to the ""training data, factors, logic, or techniques used to generate each algorithmic assessment. In some cases, even HireVue is unaware of the basis for an algorithmic assessment."" EPIC claims that HireVue is incorrect to say it does not engage facial recognition technology. Next, EPIC claims that HireVue's recruiting tools are biased and discriminatory by gender, those with neurological disorders, by race, and attempting to identify sexual orientation.

Along with the FTC Act, EPIC brings this action citing to public policy AI Principles from the Organization for Economic Cooperation and Development (""OECD"") and the Universal Guidelines for Artificial Intelligence (""UGAI"") The complaint states HireVue violated the policies of Fairness, Security/Safety, Transparency and Explainability, Accountability, Accuracy/REliability and Validity.

The FTC has not published any indication of where the investigation is into the matter. EPIC; HireVue HireVue Employment; Hiring; Facial Recognition Unfair and Deceptive Trade Practices; FTC Act; Public Policy Use of Race; Use of Gender; Programmer Bias; Trade Secrecy / Transparency; Lack of Scholarly Review"
"65","65","LivePerson, Inc. v. 24/7 Customer, Inc.","A federal jury awarded LivePerson Inc. an award of $30 million against 24/7ai misuse of trade secrets claims from online chat platform and customer engagement technology","'Copyright','Intellectual Property','Patent'","","'Copyright Infringement'","","'Predictive Policing','Transparency/Trade Secrecy'","","","","","","","Federal: District Court S.D. New York; Transferred to District Court N.D. California","03/06/2014","","0","Active","10/28/2021","11/21/2021","RA Done","Jenna","The federal jury found that 24/7 misappropriated all 15 of LivePerson’s alleged trade secrets, and awarded more than $6.7 million in compensatory damages and over $23.5 million in punitive damages. The two types of trade secrets at issue were: (1) “rules” trade secrets, the rules and variables specific to each customer and  (2) “data” trade secrets, the XML data gathered during users’ visits to LivePerson’s customers’ websites. 24/7 had tried to exclude LivePerson's expert William Choi, and the court denied this motion using the Daubert standard that Choi's calculations for trade secret damages. The court explained, ""The amount of predictive information contained within each trade secret, according to Dr. Choi, is reflected by the number of individual rules utilized by that trade secret, because the time and cost of generating the trade secret increases with the number of rules.""","The complaint arises out of a 2006 agreement between LivePerson and 24/7. LivePerson is an online chat service that sells its real time chat engagement to its customers who will use the services for sales. LivePerson contracts with each customer and creates an agreement that establishes rules and variables, and that LivePerson collects the data from the exchanges. LivePerson offered up its digital chat platform for 24/7, who would staff the platform with chat agents. This Master Services Agreement (""MSA"") entered into two customer agreements with Adobe and Hoover. After these two customer agreements expired, LivePerson and 24/7 continued its working relationship with Capitol One, Sears, and Optus. Each customer signed a separate agreement to use LivePerson's digital chat platform and to use 24/7's chat agents. However, in 2013, 24/7 introduced its own chat platform. In March of 2014, LivePerson filed its complaint in New York and amended in May to add a Jury Demand that 24/7 gained access to LivePerson's trade secrets during the time of their 2006-2010 agreements. This agreement allowed 24/7 to market LivePerson’s technology to prospective clients.   Both parties agreed that the agreement allowed 24/7 access to LivePerson's technology, 24/7 rejects the argument that they used the trade secrets to develop their own platform that would compete with LivePerson, and take LivePerson's customers of  Capital One, Optus and Sears.The first ruling came on January 13, 2015, where the judge denied in part and granted in part defendants motion to dismiss for failure to state a claim or motion for more definite statement. LivePerson was granted 20 days to replead the inadequately pled sections, and was asked to give a more definite statement about its Lanham Act claims. LivePerson filed a second amended complaint on February 4, 2015. The court granted a motion for extended time to file a protective order to protect electronically stored information including software code during discovery. On July 31, 2015, the court ruled published an opinion that (1) denied defendant's motion to compel and (2) modified the the PPO to include the proposed Expert Disclosure, Source Code and Patent Prosecution Provisions and (3) provided that the parties shall meet and confer to generate a list of competitors to be used in conjunction with the Expert Disclosure Provision. The subsequent motion to compel discovery was litigated for the first half of 2016, with numerous memoranda in support of motion to compel and in opposition, discovery requests, hearings on updates. On September 6, 2016, the court ruled on the motion to compel in a sealed opinion: Defendant's motion to compel identification of alleged trade secrets and for a protective order is denied, Plaintiff's cross-motion to compel production of source code is granted, and Plaintiff's motion to compel Defendant to collect and produce documents and identify employment status and locations is granted in part and denied in part. The parties agreed to transfer venue on March 9, 2017 to Northern District of California to consolidate with litigation filed there. After failed ADR attempts, 24/7 responded with a first amended answer to the second amended complaint. Deposition hours were approved by the court on December 13, 2017. On July 13, 2018, 24/7 filed a motion for summary judgement, which the court granted in part on the Lanham Act claim and denied in part on the trade secrets claims on November 7. The case underwent pretrial motions and deadlines for the first half of 2019. On July 19, 2019, the court denied 24/7's motion to exclude LivePerson's expert witness. The jury intstructions were approved in September 10, 2019. The trial was delayed until 2021 due to the pandemic. The jury verdict was June 17, 2021. On October 14, both LivePerson and 24/7 filed proposed orders for Post-Trial Relief, with LivePerson requesting a permanent injunction.","Response to Stipulation to Permanent Injunction","11/11/2021","LivePerson, Inc. v. 24/7 Customer, Inc. A federal jury awarded LivePerson Inc. an award of $30 million against 24/7ai misuse of trade secrets claims from online chat platform and customer engagement technology The federal jury found that 24/7 misappropriated all 15 of LivePerson’s alleged trade secrets, and awarded more than $6.7 million in compensatory damages and over $23.5 million in punitive damages. The two types of trade secrets at issue were: (1) “rules” trade secrets, the rules and variables specific to each customer and  (2) “data” trade secrets, the XML data gathered during users’ visits to LivePerson’s customers’ websites. 24/7 had tried to exclude LivePerson's expert William Choi, and the court denied this motion using the Daubert standard that Choi's calculations for trade secret damages. The court explained, ""The amount of predictive information contained within each trade secret, according to Dr. Choi, is reflected by the number of individual rules utilized by that trade secret, because the time and cost of generating the trade secret increases with the number of rules."" The complaint arises out of a 2006 agreement between LivePerson and 24/7. LivePerson is an online chat service that sells its real time chat engagement to its customers who will use the services for sales. LivePerson contracts with each customer and creates an agreement that establishes rules and variables, and that LivePerson collects the data from the exchanges. LivePerson offered up its digital chat platform for 24/7, who would staff the platform with chat agents. This Master Services Agreement (""MSA"") entered into two customer agreements with Adobe and Hoover. After these two customer agreements expired, LivePerson and 24/7 continued its working relationship with Capitol One, Sears, and Optus. Each customer signed a separate agreement to use LivePerson's digital chat platform and to use 24/7's chat agents. However, in 2013, 24/7 introduced its own chat platform. In March of 2014, LivePerson filed its complaint in New York and amended in May to add a Jury Demand that 24/7 gained access to LivePerson's trade secrets during the time of their 2006-2010 agreements. This agreement allowed 24/7 to market LivePerson’s technology to prospective clients.   Both parties agreed that the agreement allowed 24/7 access to LivePerson's technology, 24/7 rejects the argument that they used the trade secrets to develop their own platform that would compete with LivePerson, and take LivePerson's customers of  Capital One, Optus and Sears.The first ruling came on January 13, 2015, where the judge denied in part and granted in part defendants motion to dismiss for failure to state a claim or motion for more definite statement. LivePerson was granted 20 days to replead the inadequately pled sections, and was asked to give a more definite statement about its Lanham Act claims. LivePerson filed a second amended complaint on February 4, 2015. The court granted a motion for extended time to file a protective order to protect electronically stored information including software code during discovery. On July 31, 2015, the court ruled published an opinion that (1) denied defendant's motion to compel and (2) modified the the PPO to include the proposed Expert Disclosure, Source Code and Patent Prosecution Provisions and (3) provided that the parties shall meet and confer to generate a list of competitors to be used in conjunction with the Expert Disclosure Provision. The subsequent motion to compel discovery was litigated for the first half of 2016, with numerous memoranda in support of motion to compel and in opposition, discovery requests, hearings on updates. On September 6, 2016, the court ruled on the motion to compel in a sealed opinion: Defendant's motion to compel identification of alleged trade secrets and for a protective order is denied, Plaintiff's cross-motion to compel production of source code is granted, and Plaintiff's motion to compel Defendant to collect and produce documents and identify employment status and locations is granted in part and denied in part. The parties agreed to transfer venue on March 9, 2017 to Northern District of California to consolidate with litigation filed there. After failed ADR attempts, 24/7 responded with a first amended answer to the second amended complaint. Deposition hours were approved by the court on December 13, 2017. On July 13, 2018, 24/7 filed a motion for summary judgement, which the court granted in part on the Lanham Act claim and denied in part on the trade secrets claims on November 7. The case underwent pretrial motions and deadlines for the first half of 2019. On July 19, 2019, the court denied 24/7's motion to exclude LivePerson's expert witness. The jury intstructions were approved in September 10, 2019. The trial was delayed until 2021 due to the pandemic. The jury verdict was June 17, 2021. On October 14, both LivePerson and 24/7 filed proposed orders for Post-Trial Relief, with LivePerson requesting a permanent injunction.     "
"82","82","Andersen v. Stability AI Ltd.","Three artists file class action lawsuit alleging copyright infringement, violation of rights of publicity, and other causes of action based on use of their visual art as training data for an artificial intelligence image generation tool.","'Copyright','Generative AI','Intellectual Property'","Copyright, Generative AI, Intellectual Property","'Copyright Infringement','Unfair Competition','Right of Publicity','17 U.S.C. 1202 Removal of Copyright Management Information'","Copyright Infringement, Unfair Competition, Right of Publicity, 17 U.S.C. 1202 Removal of Copyright Management Information","'Misuse of AI'","Misuse of AI","'Stable Diffusion'","Stable Diffusion","'Yes'","","Stability AI, Ltd.; Stability AI, Inc.; Midjourney, Inc.; DeviantArt, Inc.","Federal: US Dist. Ct. N.D. Ca.","01/13/23","","0","","1/16/2023","1/16/2023","","Bob","This is the first lawsuit filed in the United States alleging that an artificial intelligence image generation tool infringed the copyright and the rights of publicity of artists by using their works as training data.","Three artists -- Sarah Andersen, Kelly McKernan, and Karla Ortiz -- filed this lawsuit on behalf of a class of artists against four defendants -- Stability AI, Ltd. Stability AI, Inc., Midjourney, Inc., and DevantArt, Inc. -- alleging that visual art that the artists created were used as training data for an artificial intelligence image generation tool called Stable Diffusion, also used by the public under the names Midjourney, DreamStudio, and DreamUp.  Plaintiffs allege use of their visual art infringed their copyright in that art, violated their rights of publicity, involved unlawful removal of copyright management information, and amounted to unfair competition.

The complaint alleges that defendants copied their images to use as training data for Stable Diffusion, and also alleges that Stable Diffusion maintains what are effectively copies of their images, because they are files that allow the images to be reconstructed from random noise. The complaint also alleges that the resulting AI image generation tools, all of which are based on Stable Diffusion, allow users to create art ""in the style"" of particular artists, and that that capability violations both the Copyright Act and the artists' right of publicity.","Complaint filed","1/13/2023","Andersen v. Stability AI Ltd. Three artists file class action lawsuit alleging copyright infringement, violation of rights of publicity, and other causes of action based on use of their visual art as training data for an artificial intelligence image generation tool. This is the first lawsuit filed in the United States alleging that an artificial intelligence image generation tool infringed the copyright and the rights of publicity of artists by using their works as training data. Three artists -- Sarah Andersen, Kelly McKernan, and Karla Ortiz -- filed this lawsuit on behalf of a class of artists against four defendants -- Stability AI, Ltd. Stability AI, Inc., Midjourney, Inc., and DevantArt, Inc. -- alleging that visual art that the artists created were used as training data for an artificial intelligence image generation tool called Stable Diffusion, also used by the public under the names Midjourney, DreamStudio, and DreamUp.  Plaintiffs allege use of their visual art infringed their copyright in that art, violated their rights of publicity, involved unlawful removal of copyright management information, and amounted to unfair competition.

The complaint alleges that defendants copied their images to use as training data for Stable Diffusion, and also alleges that Stable Diffusion maintains what are effectively copies of their images, because they are files that allow the images to be reconstructed from random noise. The complaint also alleges that the resulting AI image generation tools, all of which are based on Stable Diffusion, allow users to create art ""in the style"" of particular artists, and that that capability violations both the Copyright Act and the artists' right of publicity. Stability AI, Ltd.; Stability AI, Inc.; Midjourney, Inc.; DeviantArt, Inc. Stable Diffusion Copyright, Generative AI, Intellectual Property Copyright Infringement, Unfair Competition, Right of Publicity, 17 U.S.C. 1202 Removal of Copyright Management Information Misuse of AI"
"1","1","Loomis v. Wisconsin","Wisconsin Supreme Court rejects post-conviction Due Process challenge to the state's criminal sentencing use of COMPAS risk assessment algorithm, which was proprietary and which took gender into account","'Criminal Justice'","Criminal Justice; Sentencing","'Due Process','Petition for Post-Conviction Relief'","Petition for Post-Conviction Relief; Due Process","'Individualized Assessment','Transparency/Trade Secrecy','User of Gender'","Transparency / Trade Secrecy; Use of Gender; Individualized Assessment","'COMPAS'","COMPAS","","No","","State: Wisconsin","2/13/2013","Yes","0","Inactive: Judgement for D","1/30/2021","3/19/2021","Done","","COMPAS is a proprietary predictive algorithm used to assess the risk of recidivism. The Wisconsin Supreme Court held that the use of the proprietary algorithm does not violate a defendant's due process rights.  

First, it held that the use of COMPAS does not violate the right to be sentenced based upon accurate information, even though the proprietary nature of COMPAS prevents a defendant from assessing its accuracy.  The court held that it was sufficient that judges presented with COMPAS risk scores be cautioned that (1) there is no disclosure of how factors are weighed or risk scores are determined; (2) that the assessment compares defendants to a national sample and no cross-validation study of Wisconsin defendants has been completed, (3) some studies have raised questions about whether COMPAS disproportionately gives minorities higher risk scores; and (4) risk assessment tools must be updated due to changing populations.

Second, the court held that the use of COMPAS does not deny a defendant's right to an individualized sentence, because although the risk score is determined on a group basis, the court ultimately imposes the sentence on the basis of all of its knowledge of the defendant.  Third, the court held that the algorithm does not improperly use gendered assessments in sentencing, even though it takes the defendant's gender into account.  Because men have a higher risk of recidivism, use of gender promotes accuracy rather than discriminating.","Eric Loomis was charged with five crimes; he entered into a plea agreement under which he pled guilty to two crimes. Before sentencing, the court ordered a presentence report that included an algorithmic assessment using a tool called COMPAS, developed by Northpointe, Inc.  The COMPAS risk assessment is based on data gathered from a defendant's criminal file and from an interview with defendant. The challenged assessment predicts the risk of pretrial recidivism, general recidivism, and violent recidivism.  Loomis scored high on all three risk measures. In rejecting a sentence of probation, and sentencing Loomis to a prison term, the Circuit Court referenced the COMPAS risk assessment.   Loomis filed a motion for post-conviction relief requesting a new sentencing hearing, arguing that the use of the COMPAS risk assessment violated his right to due process.  All three levels of Wisconsin courts denied his motion, and the U.S. Supreme Court denied certiorari.","Denial of Certiorari by U.S. Supreme Court","6/26/2017","Loomis v. Wisconsin Wisconsin Supreme Court rejects post-conviction Due Process challenge to the state's criminal sentencing use of COMPAS risk assessment algorithm, which was proprietary and which took gender into account COMPAS is a proprietary predictive algorithm used to assess the risk of recidivism. The Wisconsin Supreme Court held that the use of the proprietary algorithm does not violate a defendant's due process rights.  

First, it held that the use of COMPAS does not violate the right to be sentenced based upon accurate information, even though the proprietary nature of COMPAS prevents a defendant from assessing its accuracy.  The court held that it was sufficient that judges presented with COMPAS risk scores be cautioned that (1) there is no disclosure of how factors are weighed or risk scores are determined; (2) that the assessment compares defendants to a national sample and no cross-validation study of Wisconsin defendants has been completed, (3) some studies have raised questions about whether COMPAS disproportionately gives minorities higher risk scores; and (4) risk assessment tools must be updated due to changing populations.

Second, the court held that the use of COMPAS does not deny a defendant's right to an individualized sentence, because although the risk score is determined on a group basis, the court ultimately imposes the sentence on the basis of all of its knowledge of the defendant.  Third, the court held that the algorithm does not improperly use gendered assessments in sentencing, even though it takes the defendant's gender into account.  Because men have a higher risk of recidivism, use of gender promotes accuracy rather than discriminating. Eric Loomis was charged with five crimes; he entered into a plea agreement under which he pled guilty to two crimes. Before sentencing, the court ordered a presentence report that included an algorithmic assessment using a tool called COMPAS, developed by Northpointe, Inc.  The COMPAS risk assessment is based on data gathered from a defendant's criminal file and from an interview with defendant. The challenged assessment predicts the risk of pretrial recidivism, general recidivism, and violent recidivism.  Loomis scored high on all three risk measures. In rejecting a sentence of probation, and sentencing Loomis to a prison term, the Circuit Court referenced the COMPAS risk assessment.   Loomis filed a motion for post-conviction relief requesting a new sentencing hearing, arguing that the use of the COMPAS risk assessment violated his right to due process.  All three levels of Wisconsin courts denied his motion, and the U.S. Supreme Court denied certiorari.  COMPAS Criminal Justice; Sentencing Petition for Post-Conviction Relief; Due Process Transparency / Trade Secrecy; Use of Gender; Individualized Assessment"
"17","17","Houston Federation of Teachers v. Houston Independent School District","Texas Supreme Court rules in favor of teachers' procedural due process objections to the school district not turning over the code of how the teacher VAM (value added model) ratings were calculated that resulting in employment terminations, pay raises, and tenure","'Constitutional Law','Employment','Performance Assessment','Termination'","Employment; Termination; Performance Asessment","'42 USC 1983','Procedural Due Process'","42 USC 1983; Procedural Due Process","'Accountability','Transparency/Trade Secrecy'","Transparency / Trade Secrecy; Accountability","'EVAAS'","EVAAS","","","American Federation of Teachers; SAS","Federal: US Dist. Ct. S.D. Texas","4/30/2014","Yes","-1","Inactive: Judgement for P","2/7/2021","3/10/2021","RA Done","Jenna","Key to this case was the transparency of the proprietary value-added algorithm from a private enterprise, namely the ability for the teachers to access and thus understand how they were evaluated. HISD provided the data to SAS who generates the EVAAS scores and reports, of which HISD does not independently verify the results. The issue arises that teachers are not allowed to wait to challenge their EVAAS score once their contract has been terminated/not renewed.

Plaintiffs bring issue with the HISD using the value-added measure and comparative growth measures on student test scores to evaluate if the teacher has added a value to the student's learning and performance on the state test. In their complaint, plaintiffs note the lack of scholarship supported value added models for individual teachers, citing: 1. VAMs for effectiveness are highly unstable, 2. teacher ratings significantly affected by the students assigned to them, and 3. VAM do not portray all the influences on a student's progress. Plaintiffs asserted that value added models merely predict how well a student will perform in the future based on past performance and can have large errors even with years of data.

Plaintiffs also bring issue with the private company SAS whose algorithm HISD employed. This SAS VAM provides only a statistical estimate for what it dubbed the ""Teacher Gain Index"": it predicts the level of growth for a student, then evaluates if the student met that growth. The growth in 2013 was calculated compared to nationwide, which could result in negative or positive TGI scores for each student's class. The possible negative or positive results are translated into five categories as its ""value added rating"": TGI 2 or above is well above value added, and TGI -2 or below is well below, with the median greater than -1 but less than 1 meaning ""no detectable difference."" 

The teachers below the value-added rating were placed on growth plans to increase their scores, while not defining what is necessary growth as the scores are calculated after spring exams and teachers instruct new students in the fall. The teachers receive only vague generalities of their scores, not what they are doing that impacted the scores. Plaintiffs allege that administrators would conduct classroom observations of low scoring EVAAS teachers to find deficiencies to justify the low score. Plaintiffs cite that 74% of principals responded they were pressured to give teachers lower scores than they deserved.

In the partial summary judgement order, the court noted that while procedural due process standards do not require exact replication, since EVAAS scores were calculated to the second decimal so an error could create a different VAM rating, so because teachers have no way of verification of their scores they are subject to mistaken deprivation of property interests in their jobs. The substantive due process summary judgement motion was granted because even though EVAAS falls short in many ways, under the constitutional standard of rationality government entities can use ""blunt tools which may produce only marginal results"" and did not meet the constitutional standard of vagueness simply because it may be prone to error. The court concluded that the EVAAS tool did not meet the equal protection claim, and even if it did, it already passed the rational basis substantive due process review.

The settlement agreement determined that HISD would cancel its contract for EVAAS and only use the model for ""informational purposes"" and instead form an instructional consultation committee to recommend how to evaluate and appraise teachers.","The Houston Independent School District contracts teachers for a three-year probation, and then a term contract, except for continuing contracts decided prior to 1996. In 2012-2013, on top of evaluating teacher instructional practice through classroom observations, HISD began appraising teachers by their students' success on end of year State of Texas exam, measuring growth and achievement. HISD then evaluates teachers of core subjects under value added and comparative growth measures under the EVAAS system. This value-added calculation impacts teacher contracts, retirement, and teaching plans, with no explanation of the scores. Other issues include that 1. the end of year Texas state exams do not test middle school science/social studies, so the teachers are evaluated compared to national standards, 2. the end of year exams are in English which disadvantage English language learners, and 3. high achieving students are less likely to show """"improvement."""" 

The plaintiffs, including the labor union Houston Federation of Teachers, sued under both equal protection and due process under the 14th amendment, and that the teachers had a continued property interest in their employment, over termination of employment based on the value-added models.

On September 28, 2015, the court granted a protective order for the plaintiffs. 

The court granted partial summary judgement for HISD on the substantive due process and the equal protection claims but denied summary judgement on the procedural due process claims as the lack of verification lead to deprivation of property interests on May 4, 2017. 

In the settlement agreement, both parties agreed to settle without admission on any of the merits of the claims and contentions, with HISD specifically still denying plaintiff's claims. It provided: 1. future VAM scores would not be used as the basis to terminate contracts, 2. HISD forms an instructional consultation committee to make recommendations on teacher evaluation process, 3. HISD pays attorney’s fees, 4. plaintiffs dismiss lawsuit with no pending claims and no admission of liability.","Order granting motion to abate because of settlement","8/13/2017","Houston Federation of Teachers v. Houston Independent School District Texas Supreme Court rules in favor of teachers' procedural due process objections to the school district not turning over the code of how the teacher VAM (value added model) ratings were calculated that resulting in employment terminations, pay raises, and tenure Key to this case was the transparency of the proprietary value-added algorithm from a private enterprise, namely the ability for the teachers to access and thus understand how they were evaluated. HISD provided the data to SAS who generates the EVAAS scores and reports, of which HISD does not independently verify the results. The issue arises that teachers are not allowed to wait to challenge their EVAAS score once their contract has been terminated/not renewed.

Plaintiffs bring issue with the HISD using the value-added measure and comparative growth measures on student test scores to evaluate if the teacher has added a value to the student's learning and performance on the state test. In their complaint, plaintiffs note the lack of scholarship supported value added models for individual teachers, citing: 1. VAMs for effectiveness are highly unstable, 2. teacher ratings significantly affected by the students assigned to them, and 3. VAM do not portray all the influences on a student's progress. Plaintiffs asserted that value added models merely predict how well a student will perform in the future based on past performance and can have large errors even with years of data.

Plaintiffs also bring issue with the private company SAS whose algorithm HISD employed. This SAS VAM provides only a statistical estimate for what it dubbed the ""Teacher Gain Index"": it predicts the level of growth for a student, then evaluates if the student met that growth. The growth in 2013 was calculated compared to nationwide, which could result in negative or positive TGI scores for each student's class. The possible negative or positive results are translated into five categories as its ""value added rating"": TGI 2 or above is well above value added, and TGI -2 or below is well below, with the median greater than -1 but less than 1 meaning ""no detectable difference."" 

The teachers below the value-added rating were placed on growth plans to increase their scores, while not defining what is necessary growth as the scores are calculated after spring exams and teachers instruct new students in the fall. The teachers receive only vague generalities of their scores, not what they are doing that impacted the scores. Plaintiffs allege that administrators would conduct classroom observations of low scoring EVAAS teachers to find deficiencies to justify the low score. Plaintiffs cite that 74% of principals responded they were pressured to give teachers lower scores than they deserved.

In the partial summary judgement order, the court noted that while procedural due process standards do not require exact replication, since EVAAS scores were calculated to the second decimal so an error could create a different VAM rating, so because teachers have no way of verification of their scores they are subject to mistaken deprivation of property interests in their jobs. The substantive due process summary judgement motion was granted because even though EVAAS falls short in many ways, under the constitutional standard of rationality government entities can use ""blunt tools which may produce only marginal results"" and did not meet the constitutional standard of vagueness simply because it may be prone to error. The court concluded that the EVAAS tool did not meet the equal protection claim, and even if it did, it already passed the rational basis substantive due process review.

The settlement agreement determined that HISD would cancel its contract for EVAAS and only use the model for ""informational purposes"" and instead form an instructional consultation committee to recommend how to evaluate and appraise teachers. The Houston Independent School District contracts teachers for a three-year probation, and then a term contract, except for continuing contracts decided prior to 1996. In 2012-2013, on top of evaluating teacher instructional practice through classroom observations, HISD began appraising teachers by their students' success on end of year State of Texas exam, measuring growth and achievement. HISD then evaluates teachers of core subjects under value added and comparative growth measures under the EVAAS system. This value-added calculation impacts teacher contracts, retirement, and teaching plans, with no explanation of the scores. Other issues include that 1. the end of year Texas state exams do not test middle school science/social studies, so the teachers are evaluated compared to national standards, 2. the end of year exams are in English which disadvantage English language learners, and 3. high achieving students are less likely to show """"improvement."""" 

The plaintiffs, including the labor union Houston Federation of Teachers, sued under both equal protection and due process under the 14th amendment, and that the teachers had a continued property interest in their employment, over termination of employment based on the value-added models.

On September 28, 2015, the court granted a protective order for the plaintiffs. 

The court granted partial summary judgement for HISD on the substantive due process and the equal protection claims but denied summary judgement on the procedural due process claims as the lack of verification lead to deprivation of property interests on May 4, 2017. 

In the settlement agreement, both parties agreed to settle without admission on any of the merits of the claims and contentions, with HISD specifically still denying plaintiff's claims. It provided: 1. future VAM scores would not be used as the basis to terminate contracts, 2. HISD forms an instructional consultation committee to make recommendations on teacher evaluation process, 3. HISD pays attorney’s fees, 4. plaintiffs dismiss lawsuit with no pending claims and no admission of liability. American Federation of Teachers; SAS EVAAS Employment; Termination; Performance Asessment 42 USC 1983; Procedural Due Process Transparency / Trade Secrecy; Accountability"
"33","33","Roberson v. Clearview AI, Inc.","","'Facial Recognition'","Facial Recognition","","","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal: E.D. Va.; Transferred to Federal:  US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","2/3/20","","0","Active","2/15/2021","5/1/2022","","","Chronologically, this was the second case filed of the nine consolidated into In Re Clearview. It is the only case not filed in either Illinois or New York, and it was brought under the Virginia Code and the Virginia Computer Crimes Act. Unlike similar cases, Roberson only brought claims against Clearview and not its founders (and obviously not the Illinois company who acted as a third party contractor).","Roberson filed complaint on February 3, 2020 on behalf of a Virginia class whose photographs were unlawfully used by Clearview under the Virginia Computer Crimes Act.

The Virginia Code provides statutory damages for ""any person whose name, portrait, or picture is used without having first obtained the written consent of such person . . . for the purposes of trade"" and the Virginia Computer Crimes Act provides a private right of action regardless of any malicious intent. The specific claim against Clearview is obtaining the property of another without consent from the data scraping online, and then making copies of the data into their database, and third because the information collected is identifying personal information and then used trickery or deception by not obtaining consent.

Clearview filed its motion to transfer or dismiss in March.

Court transferred the case to SDNY on May 13, 2020, which the Virginia court granted.

On May 29, the SDNY Court denied Mutnick's motion to intervene and dismiss or transfer the cases to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.","MDL Transfer","1/12/2021","Roberson v. Clearview AI, Inc.  Chronologically, this was the second case filed of the nine consolidated into In Re Clearview. It is the only case not filed in either Illinois or New York, and it was brought under the Virginia Code and the Virginia Computer Crimes Act. Unlike similar cases, Roberson only brought claims against Clearview and not its founders (and obviously not the Illinois company who acted as a third party contractor). Roberson filed complaint on February 3, 2020 on behalf of a Virginia class whose photographs were unlawfully used by Clearview under the Virginia Computer Crimes Act.

The Virginia Code provides statutory damages for ""any person whose name, portrait, or picture is used without having first obtained the written consent of such person . . . for the purposes of trade"" and the Virginia Computer Crimes Act provides a private right of action regardless of any malicious intent. The specific claim against Clearview is obtaining the property of another without consent from the data scraping online, and then making copies of the data into their database, and third because the information collected is identifying personal information and then used trickery or deception by not obtaining consent.

Clearview filed its motion to transfer or dismiss in March.

Court transferred the case to SDNY on May 13, 2020, which the Virginia court granted.

On May 29, the SDNY Court denied Mutnick's motion to intervene and dismiss or transfer the cases to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.  Clearview Facial Recognition  Privacy"
"49","49","Velesaca v. Decker","Class action filed by non citizens detained in New York challenging the ""no release policy,"" arguing that a change to the assessment algorithm resulted in a lack of ICE bond hearings and solely recommending detention, with preliminary injunction granted to return to individualized assessment due to COVID safety","'Detention and Release','Immigration'","Immigration; Detention and Release","'5th Amendment','Administrative Procedure Act','Due Process Clause','Immigration and Nationality Act','Preliminary Injunction','Rehabilitation Act'","Immigration and Nationality Act; Due Process Clause; Fifth Amendment; Administrative Procedure Act;  Rehabilitation Act; Preliminary Injunction","'Programmer Bias','Use of Race'","Use of Race; Programmer Bias","'Risk Classification Assessment Tool'","Risk Classification Assessment Tool","","Yes","ICE; NYCLU; Bronx Defenders","Federal: US Dist. Ct. S.D. New York","2/28/2020","Yes","-1","Active: Settlement Negotiations","5/3/2021","6/12/2021","RA Done; Check for New Activity","Jenna","The switch to the risk assessment algorithm from individualized assessments is at the center of this case, and that ICE manipulated the algorithm to remove the release alternative so that detention was the only option. The complaint illustrates this with the statistics: 47% of low risk individuals were granted release from 2013 to 2017, but only 3% of low risk individuals were granted release from June 2017 to September 2019.","Before 2017, ICE conducted individual assessments to determine detention or release, but in 2017 it switched to its Risk Classification Assessment Tool, which the complaint argues always determines detention is necessary. On February 28, 2020, a noncitizen filed this class action against ICE for the lack of bond hearings that are required within 48 hours of arrest in New York City. Now those detained in local jails have to wait months in inadequate conditions before going before an immigration judge.

The two subclasses are the Petitioner subclass who were eligible to be considered for bond or release who have been or will be detained without bond, and the Rehabilitation Act subclass who are individuals with a disability eligible for bond or release consideration who have been or will be detained without bond. 

Preliminary injunction was granted even with defendants arguing that the no release policy does not exist, and that plaintiffs have not exhausted all other remedies before filing this complaint. The court granted the PI on expedited circumstances on March 31, and filed its reasoning on May 4. In its reasoning, the court ordered ICE to return to its pre-2017 policy and conduct individualized release assessments for the named plaintiffs and proposed classes. Citing medical experts who testified that the risk of COVID is more intense in ICE facilities, and a Stanford statistician who verified the change in release rate, the court directed ICE to file a report with the court by April 17 about each individual held without bond.

The court denied defendant's motion to amend the PI, stating that ICE now had until May 22 and every week thereafter to report on its progress of identifying and individually assessing each individual held without bond. 

On July 1, 2020 the court issued a protective order.

The court denied defendant's motion to clarify the PI in July 2020. ICE argued that the injunction was ""insufficiently specific as to what ICE must do, unduly broad as to its coverage, and not applicable to persons detained as of April 10, 2020"" but the court denied this order it was clearly meant to apply to those ""now or hereafter arrested"" so including those as of April 10. Defendants filed an appeal but withdrew by October. 

On August 25 the court ordered defendants to provide custody worksheets of all detainees to petitioners no later than September 8, along with all written correspondence to and from ICE officers after March 31, 2020 and written guidance on court's injunction. By September 1 the defendants were ordered to produce a full administrative record.

In September the court granted plaintiff's deposition order about personnel training related to the injunction, set an October deadline for any remaining discovery disputes, and denied ICE's request for extension of time.

The court ordered defendants to respond in November, and then submitted on December 4 an order requiring parties to submit their recommended discovery order for Court's consideration, and defendants filed their opposition to enforcing the PI.

The case was directed to a magistrate judge for settlement proceedings, and scheduled on March 18.","Settlement proceedings","3/8/2021","Velesaca v. Decker Class action filed by non citizens detained in New York challenging the ""no release policy,"" arguing that a change to the assessment algorithm resulted in a lack of ICE bond hearings and solely recommending detention, with preliminary injunction granted to return to individualized assessment due to COVID safety The switch to the risk assessment algorithm from individualized assessments is at the center of this case, and that ICE manipulated the algorithm to remove the release alternative so that detention was the only option. The complaint illustrates this with the statistics: 47% of low risk individuals were granted release from 2013 to 2017, but only 3% of low risk individuals were granted release from June 2017 to September 2019. Before 2017, ICE conducted individual assessments to determine detention or release, but in 2017 it switched to its Risk Classification Assessment Tool, which the complaint argues always determines detention is necessary. On February 28, 2020, a noncitizen filed this class action against ICE for the lack of bond hearings that are required within 48 hours of arrest in New York City. Now those detained in local jails have to wait months in inadequate conditions before going before an immigration judge.

The two subclasses are the Petitioner subclass who were eligible to be considered for bond or release who have been or will be detained without bond, and the Rehabilitation Act subclass who are individuals with a disability eligible for bond or release consideration who have been or will be detained without bond. 

Preliminary injunction was granted even with defendants arguing that the no release policy does not exist, and that plaintiffs have not exhausted all other remedies before filing this complaint. The court granted the PI on expedited circumstances on March 31, and filed its reasoning on May 4. In its reasoning, the court ordered ICE to return to its pre-2017 policy and conduct individualized release assessments for the named plaintiffs and proposed classes. Citing medical experts who testified that the risk of COVID is more intense in ICE facilities, and a Stanford statistician who verified the change in release rate, the court directed ICE to file a report with the court by April 17 about each individual held without bond.

The court denied defendant's motion to amend the PI, stating that ICE now had until May 22 and every week thereafter to report on its progress of identifying and individually assessing each individual held without bond. 

On July 1, 2020 the court issued a protective order.

The court denied defendant's motion to clarify the PI in July 2020. ICE argued that the injunction was ""insufficiently specific as to what ICE must do, unduly broad as to its coverage, and not applicable to persons detained as of April 10, 2020"" but the court denied this order it was clearly meant to apply to those ""now or hereafter arrested"" so including those as of April 10. Defendants filed an appeal but withdrew by October. 

On August 25 the court ordered defendants to provide custody worksheets of all detainees to petitioners no later than September 8, along with all written correspondence to and from ICE officers after March 31, 2020 and written guidance on court's injunction. By September 1 the defendants were ordered to produce a full administrative record.

In September the court granted plaintiff's deposition order about personnel training related to the injunction, set an October deadline for any remaining discovery disputes, and denied ICE's request for extension of time.

The court ordered defendants to respond in November, and then submitted on December 4 an order requiring parties to submit their recommended discovery order for Court's consideration, and defendants filed their opposition to enforcing the PI.

The case was directed to a magistrate judge for settlement proceedings, and scheduled on March 18. ICE; NYCLU; Bronx Defenders Risk Classification Assessment Tool Immigration; Detention and Release Immigration and Nationality Act; Due Process Clause; Fifth Amendment; Administrative Procedure Act;  Rehabilitation Act; Preliminary Injunction Use of Race; Programmer Bias"
"68","68","Flores v. Stanford","Action claiming that parole procedures violate due process because they are based in part on risk assessment algorithms and do not involve the assessment of individual files","'Criminal Justice','Detention and Release'","","'Due Process'","","'Individualized Assessment','Lack of Human Review'","","","","","","","Federal: U.S. District Court, S.D. New York","03/20/2018","","0","Active","10/28/2021","4/11/2022","","","The plaintiffs will have access to COMPAS and examine whether the programming holds young offenders' ages against them by treating youth as an aggravating factor in various ways and thus discriminates against them in the parole hearing.","This is a class action against the New York State Board of Parole. Each plaintiff was convicted by a New York State court of committing homicide as a juvenile. Each received an indeterminate prison sentence up to a maximum term of life with the possibility of parole, to be served in the custody of the
New York State Department of Corrections and Community
Supervision (“DOCCS”). The Board assigns a “lead” commissioner for each parole interview. During the interview, only that lead commissioner has a
complete copy of the offender's parole file. Non-lead commissioners allegedly receive only a partial, “book copy” of the offender's file, one of which is “COMPAS report”—a
report applying Correctional Offender Management Profiling for Alternative Sanctions (“COMPAS”), which DOCCS allegedly uses as a predictive risk assessment tool.
The plaintiffs argue COMPAS holds young offenders' ages against them by treating youth as an aggravating factor in various ways. They seek to have access to COMPAS as the part of the discovery.","","4/11/2022","Flores v. Stanford Action claiming that parole procedures violate due process because they are based in part on risk assessment algorithms and do not involve the assessment of individual files The plaintiffs will have access to COMPAS and examine whether the programming holds young offenders' ages against them by treating youth as an aggravating factor in various ways and thus discriminates against them in the parole hearing. This is a class action against the New York State Board of Parole. Each plaintiff was convicted by a New York State court of committing homicide as a juvenile. Each received an indeterminate prison sentence up to a maximum term of life with the possibility of parole, to be served in the custody of the
New York State Department of Corrections and Community
Supervision (“DOCCS”). The Board assigns a “lead” commissioner for each parole interview. During the interview, only that lead commissioner has a
complete copy of the offender's parole file. Non-lead commissioners allegedly receive only a partial, “book copy” of the offender's file, one of which is “COMPAS report”—a
report applying Correctional Offender Management Profiling for Alternative Sanctions (“COMPAS”), which DOCCS allegedly uses as a predictive risk assessment tool.
The plaintiffs argue COMPAS holds young offenders' ages against them by treating youth as an aggravating factor in various ways. They seek to have access to COMPAS as the part of the discovery.     "
"85","85","United States v. Wilson","The 9th Circuit found that the defendant's Fourth Amendment rights were violated when Google's algorithm—without opening the email—detected child pornography attached to one of the emails he sent and reported it to law enforcement.","'Constitutional Law','Criminal Justice','Privacy','Search and Seizure'","Criminal Justice, Privacy, Search and Seizure, Constitutional Law","'Fourth Amendment'","Fourth Amendment","'Law Enforcement','Privacy'","Law Enforcement, Privacy","","Image matching system","'No'","","EPIC; EFF; ACLU; Google; Facebook","9th Cir.","06/27/2023","","-1","Inactive: Judgment for D","3/4/2023","3/4/2023","","Allie","","","","","United States v. Wilson The 9th Circuit found that the defendant's Fourth Amendment rights were violated when Google's algorithm—without opening the email—detected child pornography attached to one of the emails he sent and reported it to law enforcement.   EPIC; EFF; ACLU; Google; Facebook Image matching system Criminal Justice, Privacy, Search and Seizure, Constitutional Law Fourth Amendment Law Enforcement, Privacy"
"12","12","Tyndaris v. VWM Limited","Suit by Tyndaris for unpaid fees, countersuit by VWM for misrepresentation and breach of contract, first determining if under civil liabilty Tyndaris is responsible as a custodian for the algorithm's mistakes, expected to be landmark case as first UK case to discuss machine learning","'Investment','Portfolio Management','Trading'","Investment; Portfolio Management; Trading","'Article 1465 of the Civil Code of Quebec','Breach of Contract'","Article 1465 of the Civil Code of Quebec; Breach of Contract","'Misrepresentation to Client','Underperformance'","Underperformance; Misrespresentation to Client","","","","","","International: London Commercial Court: the UK site is horrendously difficult to navigate, need a link to the case docket","5/1/2018","Yes","-1","Active","2/4/2021","2/12/2021","","","","","","","Tyndaris v. VWM Limited Suit by Tyndaris for unpaid fees, countersuit by VWM for misrepresentation and breach of contract, first determining if under civil liabilty Tyndaris is responsible as a custodian for the algorithm's mistakes, expected to be landmark case as first UK case to discuss machine learning     Investment; Portfolio Management; Trading Article 1465 of the Civil Code of Quebec; Breach of Contract Underperformance; Misrespresentation to Client"
"28","28","Carmean v. Macy's Retail Holdings, Inc","Macy's use of Clearview violates BIPA, Ill. UDAP (both unfair and deceptive), Ill. invasion of privacy; seeking injunctive relief (including deletion of data and compliance monitoring), damages, litigation costs, and was not consolidated in the Clearview MDL.","'Facial Recognition'","Facial Recognition","'Illinois Biometric Information Privacy Act','Illinois Unfair and Deceptive Acts'","Illinois Biometic Information Privacy Act; Illinios Unfair and Deceptive Acts;","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. N.D. Illinois","8/5/2020","","0","Active","2/15/2021","5/1/2022","In Progress","Jenna","This case was not combined with the other nine cases for in re Clearview litigation in the Northern District of Illinois because Clearview was not a defendant, as it was about Macy's use of Clearview.

The complaints mentions that a 2020 article shed light on 2,200 of Clearview clientele, which included department stores, and that Macy had run 6,000 customers through the database, which is illegal in Illinois without notice and consent.","Originally filed under the incorrect name Carmine.

The complaint contends that Macy's use of Clearview to run through 6,000 customers violates the Biometric Information Privacy Act (""BIPA"") and the Illinois Consumer Fraud and Deceptive Business Practices (""ICFA""). Under both BIPA and ICFA, the complaint argues: 1. plaintiff posted pictures of herself on social media, and others posted pictures of her on social media, 2. Macy's never notified or procured a written release from the class members to collect, obtain, or use their Clearview positive identifications, 3. violation of privacy with punitive and actual damages. 

The complaint admits: ""Because Carmine has such a widespread and active social media presence, on information and belief, Carmine’s biometric information and identifiers and her personal and private information are contained in Clearview’s database."" 

The complaint sought relief: 1. Macy's expunge/delete/remove all information and data about the class members, 2. Macy's will not use its Clearview positive identification information in the future, and 3. submit and pay for court-supervised monitoring of their database for BIPA compliance.","Continued Hearing","12/10/2020","Carmean v. Macy's Retail Holdings, Inc Macy's use of Clearview violates BIPA, Ill. UDAP (both unfair and deceptive), Ill. invasion of privacy; seeking injunctive relief (including deletion of data and compliance monitoring), damages, litigation costs, and was not consolidated in the Clearview MDL. This case was not combined with the other nine cases for in re Clearview litigation in the Northern District of Illinois because Clearview was not a defendant, as it was about Macy's use of Clearview.

The complaints mentions that a 2020 article shed light on 2,200 of Clearview clientele, which included department stores, and that Macy had run 6,000 customers through the database, which is illegal in Illinois without notice and consent. Originally filed under the incorrect name Carmine.

The complaint contends that Macy's use of Clearview to run through 6,000 customers violates the Biometric Information Privacy Act (""BIPA"") and the Illinois Consumer Fraud and Deceptive Business Practices (""ICFA""). Under both BIPA and ICFA, the complaint argues: 1. plaintiff posted pictures of herself on social media, and others posted pictures of her on social media, 2. Macy's never notified or procured a written release from the class members to collect, obtain, or use their Clearview positive identifications, 3. violation of privacy with punitive and actual damages. 

The complaint admits: ""Because Carmine has such a widespread and active social media presence, on information and belief, Carmine’s biometric information and identifiers and her personal and private information are contained in Clearview’s database."" 

The complaint sought relief: 1. Macy's expunge/delete/remove all information and data about the class members, 2. Macy's will not use its Clearview positive identification information in the future, and 3. submit and pay for court-supervised monitoring of their database for BIPA compliance.  Clearview Facial Recognition Illinois Biometic Information Privacy Act; Illinios Unfair and Deceptive Acts; Privacy"
"44","44","Cahoo v. Fast Enters.","Court denied granting Fast Enterprises' motion for dismissal on lack of subject matter jurisdiction","'Agency','Constitutional Law','Fraud','Unemployment Insurance'","Unemployment Insurance; Fraud; Agency","'Due Process'","","'Accountability','Lack of Human Review','Lack of Remedy','Notice','Role of Expert Testimony','Socioeconomics Bias','Use of Race','Miscalculation'","Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy","'MIDAS'","MiDAS","","No","","Federal: US Dist. Ct. E. D. Michigan","3/2/2017 but dismissal against SAS on 8/11/2020 so this became Cahoo v. Fast","Yes","-1","Active","3/3/2021","3/19/2021","Check for Recent Activity","","","","Order","3/18/2021","Cahoo v. Fast Enters. Court denied granting Fast Enterprises' motion for dismissal on lack of subject matter jurisdiction    MiDAS Unemployment Insurance; Fraud; Agency  Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy"
"62","62","McRO, Inc. v. Bandai Namco Games America, Inc.","A patent infringement case of video game design involving software applications to automatically animate lip synchronization and facial expression, the court found no infringement and found invalidity based on the lack of specificity in enablement","'Intellectual Property','Patent'","","'Patent Application'","","'Functionality'","","","","","No","","Federal: U.S. District Court, C.D. California","12/04/2012","Yes","-1","Inactive","10/14/2021","11/24/2021","In Progress","Jenna","","","Judgement","9/13/2016","McRO, Inc. v. Bandai Namco Games America, Inc. A patent infringement case of video game design involving software applications to automatically animate lip synchronization and facial expression, the court found no infringement and found invalidity based on the lack of specificity in enablement       "
"80","80","Ogletree v. Cleveland State University","A student sued his university arguing that the use of remote proctoring tools violated his Fourth Amendment rights. The court found that the room scans were a search and that the student's privacy interests outweighed the university's interests in conducting the scans.","'Constitutional Law','Privacy'","Privacy, Constitutional Law","'Fourth Amendment'","Fourth Amendment","'Privacy'","Privacy","","Rospondus; Honorlock","'No'","","","U.S Distr. Ct. N.D. Ohio","03/02/2021","","-1","Active: Appeal Filed","10/10/2022","10/10/2022","","Allie Schiele","","","District Court Opinion","9/25/2022","Ogletree v. Cleveland State University A student sued his university arguing that the use of remote proctoring tools violated his Fourth Amendment rights. The court found that the room scans were a search and that the student's privacy interests outweighed the university's interests in conducting the scans.    Rospondus; Honorlock Privacy, Constitutional Law Fourth Amendment Privacy"
"96","96","Walters v. OpenAI, L.L.C.","Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court.","'Generative AI'","Generative AI","'Defamation'","Defamation","'Unreliability'","Unreliability","'ChatGPT'","ChatGPT","'No'","","OpenAI, LLC","Federal: US Dist. Ct. N.D. Ga.","07/14/2023","","0","Active","7/27/2023","7/27/2023","","Bob","","Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court.","Filing of Notice of Removal","7/14/2023","Walters v. OpenAI, L.L.C. Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court.  Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court. OpenAI, LLC ChatGPT Generative AI Defamation Unreliability"
"11","11","In re BlueCrest Capital Mgmt Ltd.","SEC found both negligent and willful violations against BlueCrest for omissions and misstatements to both potential and existing investors and indpendent directors about the use of their Rates Management Trading in that it underperformed compared to live traders and misrepresented its high usage of the algorithm it had told investors was merely experimental.","'Investment','Trading'","Investment; Trading","'Negligence','Securities Act Section 17A','Willful Violation'","Securities Act Section 17A; Negligence; Willful Violation","'Conflict of Interest','Failure to Disclosure','Misrepresentation to Client','Unaware of Use of Algorithm','Underperformance'","Underperformance; Failure to Disclose; Misrepresentation to Client; Conflict of Interest; Unaware of Use of Algorithm","'RMT'","RMT","","","","Government: SEC Adjudication","12/8/2020","No","0","Active","2/4/2021","2/12/2021","","","","","","","In re BlueCrest Capital Mgmt Ltd. SEC found both negligent and willful violations against BlueCrest for omissions and misstatements to both potential and existing investors and indpendent directors about the use of their Rates Management Trading in that it underperformed compared to live traders and misrepresented its high usage of the algorithm it had told investors was merely experimental.    RMT Investment; Trading Securities Act Section 17A; Negligence; Willful Violation Underperformance; Failure to Disclose; Misrepresentation to Client; Conflict of Interest; Unaware of Use of Algorithm"
"27","27","Nilsson v. General Motors","General Motors settled with motorcyclist injured in crash with a self-driving car, arguing GM negligently breached the duty of care for obeying traffic laws by swerving into another lane","'Autonomous Vehicles'","Autonomous Vehicles","'Negligence'","Negligence","'Product Liability','Underperformance'","Product Liability; Underperformance","","","","","","Federal: US Dist.Ct. N.D. California","1/22/2018","No","0","Inactive: Settled","2/14/2021","9/18/2021","","Jenna","Personal injury complaint by a motorcyclist injured y a self-driving car","Nilson was driving in the middle lane on his motorcycle and Salazar was driving ahead of him in a 2016 Chevrolet bolt Vehicle. The car was in ""self-driving mode"" so Salazar kept his hands off the wheel. Salazar commanded the car to change lanes to the left. The car changed lanes, Salazar proceeds to travel straight, however at the same time the self-driving car suddenly veered back into Nilsons lane, sticking him and knocking him to the ground. Nilson suffered neck and shoulder injuries and was forced to take disability leave form his work. The case eventually settled.","Dismissed","6/26/2018","Nilsson v. General Motors General Motors settled with motorcyclist injured in crash with a self-driving car, arguing GM negligently breached the duty of care for obeying traffic laws by swerving into another lane Personal injury complaint by a motorcyclist injured y a self-driving car Nilson was driving in the middle lane on his motorcycle and Salazar was driving ahead of him in a 2016 Chevrolet bolt Vehicle. The car was in ""self-driving mode"" so Salazar kept his hands off the wheel. Salazar commanded the car to change lanes to the left. The car changed lanes, Salazar proceeds to travel straight, however at the same time the self-driving car suddenly veered back into Nilsons lane, sticking him and knocking him to the ground. Nilson suffered neck and shoulder injuries and was forced to take disability leave form his work. The case eventually settled.   Autonomous Vehicles Negligence Product Liability; Underperformance"
"43","43","Cahoo v. SAS Indus.","Court dismissed case against SAS for lack of subject matter jurisdiction","'Agency','Constitutional Law','Fraud','Unemployment Insurance'","Unemployment Insurance; Fraud; Agency","'Due Process'","","'Accountability','Lack of Human Review','Lack of Remedy','Notice','Role of Expert Testimony','Socioeconomics Bias','Use of Race','Miscalculation'","Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy","'MIDAS'","MiDAS","","No","SAS","Federal: US Dist. Ct. E. D. Michigan","3/2/2017","Yes","-1","Inactive: Dismissed","3/3/2021","3/5/2021","","","This case is continued in Cahoo v. Fast, as the court recognized the claim for negligence in the software design and monitoring, but granted SAS's motion to dismiss because inadequate damages pled.","","Dismissed against SAS","8/11/2020","Cahoo v. SAS Indus. Court dismissed case against SAS for lack of subject matter jurisdiction This case is continued in Cahoo v. Fast, as the court recognized the claim for negligence in the software design and monitoring, but granted SAS's motion to dismiss because inadequate damages pled.  SAS MiDAS Unemployment Insurance; Fraud; Agency  Miscalculation; Accountability; Notice; Use of Race; Socioeconomic Bias; Lack of Human Review; Role of Expert Testimony; Lack of Remedy"
"60","60","Nevarez v. Forty Niners Football Co., LLC","In a mobility disability access class action, a trial court ruled that the Federal Rules of Evidence would prohibit the use of AI to identify non-responsive documents without identifying a “cut-off” point during review","'Disabilities Benefits'","Disability Benefits","'Evidence'","","'Transparency/Trade Secrecy'","","","","","Yes","","Federal: U.S. District Court N.D. California","12/07/2016","Yes","-1","Inactive: Settlement","10/14/2021","11/10/2021","RA Done","Jenna","The issue of machine learning programs came up in October 2018 regarding discovery in ORDER REGARDING DISCOVERY SUBMISSIONS ECF 244, ECF 245 AND ECF 246. Plaintiffs requested almost 300,000 documents from third parties Live Nation and Ticketmaster. The defendants pushed back that the unreviewed documents that had been identified could have been no-responsive documents protected by privilege. The court says: ""This dilemma is not uncommon in ESI productions. Defendants have, constructively, adopted the use of predictive artificial intelligence programs to assist in the identification of non-responsive documents en masse within the unreviewed documents However, Defendants do not have sufficient data from those programs to argue for a supportable “cut-off” point among the unreviewed documents to avoid producing, and thus reviewing, some portion of the 297,000 documents. Given that the Parties are already well past the close of discovery, there is not time to develop such an argument, and the Court will not permit Defendants to adopt such a cut-off point arbitrarily. Fortunately, the Parties have other safeguards in place to prevent the mis-use of produced documents that contain the agreed upon search terms but are either unresponsive, privileged or otherwise protected, such as the Protective Order (ECF 97) and Federal Rule of Evidence 502(b) protections against inadvertent disclosures, which the Parties have agreed will apply under these circumstances. The Parties may, at Defendants discretion, continue to meet and confer regarding the use of predictive coding as a means of identifying documents that are unlikely to be responsive and thus do not need to be produced in this action. However, absent any agreement on such identification, Defendants’ entire ESI production, whether or not Defendants have been able to review all of the documents in advance of production, must be turned over.""","This class action was filed on behalf of three classes: the Injunctive Relief Class; the Companion Injunctive Relief Class; and the Damages Class. The three classes are those with mobility disabilities who were allegedly denied ""full and equal access"" to Levi’s Stadium’s facilities, services, accessible seating, parking, and other amenities because Levi Stadium and defendants did not construct the Stadium in compliance with disability access standards. The final class settlement was accepted on July 23, 2020. The terms included the Stadium updating thousands of barriers at the Stadium: the parking lot, the pedestrian right of way, shuttle access, and ticket access.  On top of the Stadium changes, the 49ers also created a $24 million Damages Fund distributed to the Damages class  under California Civil Rights Act for incidents of discrimination they suffered between April 13, 2015 and March 9, 2020.","Settlement Approved","7/23/2020","Nevarez v. Forty Niners Football Co., LLC In a mobility disability access class action, a trial court ruled that the Federal Rules of Evidence would prohibit the use of AI to identify non-responsive documents without identifying a “cut-off” point during review The issue of machine learning programs came up in October 2018 regarding discovery in ORDER REGARDING DISCOVERY SUBMISSIONS ECF 244, ECF 245 AND ECF 246. Plaintiffs requested almost 300,000 documents from third parties Live Nation and Ticketmaster. The defendants pushed back that the unreviewed documents that had been identified could have been no-responsive documents protected by privilege. The court says: ""This dilemma is not uncommon in ESI productions. Defendants have, constructively, adopted the use of predictive artificial intelligence programs to assist in the identification of non-responsive documents en masse within the unreviewed documents However, Defendants do not have sufficient data from those programs to argue for a supportable “cut-off” point among the unreviewed documents to avoid producing, and thus reviewing, some portion of the 297,000 documents. Given that the Parties are already well past the close of discovery, there is not time to develop such an argument, and the Court will not permit Defendants to adopt such a cut-off point arbitrarily. Fortunately, the Parties have other safeguards in place to prevent the mis-use of produced documents that contain the agreed upon search terms but are either unresponsive, privileged or otherwise protected, such as the Protective Order (ECF 97) and Federal Rule of Evidence 502(b) protections against inadvertent disclosures, which the Parties have agreed will apply under these circumstances. The Parties may, at Defendants discretion, continue to meet and confer regarding the use of predictive coding as a means of identifying documents that are unlikely to be responsive and thus do not need to be produced in this action. However, absent any agreement on such identification, Defendants’ entire ESI production, whether or not Defendants have been able to review all of the documents in advance of production, must be turned over."" This class action was filed on behalf of three classes: the Injunctive Relief Class; the Companion Injunctive Relief Class; and the Damages Class. The three classes are those with mobility disabilities who were allegedly denied ""full and equal access"" to Levi’s Stadium’s facilities, services, accessible seating, parking, and other amenities because Levi Stadium and defendants did not construct the Stadium in compliance with disability access standards. The final class settlement was accepted on July 23, 2020. The terms included the Stadium updating thousands of barriers at the Stadium: the parking lot, the pedestrian right of way, shuttle access, and ticket access.  On top of the Stadium changes, the 49ers also created a $24 million Damages Fund distributed to the Damages class  under California Civil Rights Act for incidents of discrimination they suffered between April 13, 2015 and March 9, 2020.   Disability Benefits  "
"79","79","Rodriguez v. Massachusetts Parole Board","Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights. The Supreme Judicial Court of Massachusetts held that the board had appropriately considered the relevant factors and affirmed its decision to deny parole.","'Civil Rights','Criminal Justice'","Civil Rights, Criminal Justice","'5th Amendment'","5th Amendment","'Individualized Assessment','Misuse of AI','Transparency/Trade Secrecy'","Individualized Assessment, Misuse of AI, Transparency/Trade Secrecy","'Risk Classification Assessment Tool'","LS/CMI","","","EPIC","Massachusetts Supreme Judicial Court for the Commonwealth","11/23/2022","","-1","Inactive: Judgment for D","5/4/2022","3/4/2023","","Allie","Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights.","The Massachusetts Parole Board (“MPB”) has started using a predictive analytical tool from a third-party contractor. The MPB uses a tool called the Level of Service/Case Management Inventory (“LS/CMI”) to generate risk scores that purport to predict how likely a parole applicant is to end up back in prison. Mr. Jose Rodriguez, has been consistently denied parole based on the high risk score that LS/CMI gives him. Mr. Rodriguez is challenging the Parole Board’s use of LS/CMI to give him a high risk score, and the Parole Board’s refusal to share any useful information about how his score was calculated. ","Opinion Issued","3/7/2022","Rodriguez v. Massachusetts Parole Board Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights. The Supreme Judicial Court of Massachusetts held that the board had appropriately considered the relevant factors and affirmed its decision to deny parole. Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights. The Massachusetts Parole Board (“MPB”) has started using a predictive analytical tool from a third-party contractor. The MPB uses a tool called the Level of Service/Case Management Inventory (“LS/CMI”) to generate risk scores that purport to predict how likely a parole applicant is to end up back in prison. Mr. Jose Rodriguez, has been consistently denied parole based on the high risk score that LS/CMI gives him. Mr. Rodriguez is challenging the Parole Board’s use of LS/CMI to give him a high risk score, and the Parole Board’s refusal to share any useful information about how his score was calculated.  EPIC LS/CMI Civil Rights, Criminal Justice 5th Amendment Individualized Assessment, Misuse of AI, Transparency/Trade Secrecy"
"95","95","Walters v. OpenAI, LLC","Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removed to federal court.","'Generative AI'","Generative AI","'Defamation'","Defamation","'Reliability'","Reliability","'ChatGPT'","ChatGPT","","","OpenAI, LLC","State: Georgia, Superior Ct. of Gwinnett County","06/05/2023","","0","Inactive","7/5/2023","7/27/2023","","Bob","","Plaintiff sued developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation.  Defendant OpenAI removed the action to federal court (the Northern District of Georgia)","Removal by defendant to Federal Court","7/14/2023","Walters v. OpenAI, LLC Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removed to federal court.  Plaintiff sued developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation.  Defendant OpenAI removed the action to federal court (the Northern District of Georgia) OpenAI, LLC ChatGPT Generative AI Defamation Reliability"
"16","16","C.S. et al v. Saiki:","Judge granted Oregon residents relying on in-home attendants an injunction against an aglorithm that vastly cut their hours, and ordered restoration of their previous algorithm that produced the expected hours for disabilities benefits while the state developed a new assessment algorithm","'Disabilities Benefits','Health','Public Benefits'","Health; Disabilities Benefits; Public Benefits","'Preliminary Injunction','Title II Americans with Disabilities Act'","Preliminary Injunction; Title II Americans with Disabilities Act; Medicaid Act","'Lack of Scholarly Review','Transparency in Change of Algorithm'","Transparency in Change of Algorithm; Lack of Remedy","'ANA-C','CNA-C'","ANA-C; CNA-C","","Yes","","Federal: US Dist. Ct. D. Oregon","4/1/2017","Yes","-1","Active","2/7/2021","4/30/2022","In Progress; Check for New Activity","Jenna","The Oregon Office of Developmental Disability Services implemented the ANA-C or CNA-C assessment tool to calculate authorized hours for in-home attendant hours for those with intellectual or developmental disabilities. The plaintiffs filed this action because they received a decrease in hours for services. The complaint filed for a preliminary injunction against the further use of this assessment tool, and was ordered to prospectively restore all hours by ANA-C or CNA-C and notify the affected people. 
The DDS could continue to use the ANA-C or CNA-C to evaluate those with intellectual or developmental disabilities but could not reduce in-home attendant care services below the “status quo” level of care that they received as of November 1, 2016.","On April 10, 2017, Plaintiffs filed a complaint, a Motion for a Preliminary Injunction, and Motion for Protective Order and to Proceed Anonymously. On April 19, 2017, the judge granted the preliminary injunction, and the following day granted Motion to Proceed Anonymously. The case stalled in the rest of 2017, with joint status report filed every six months in 2018, 2019, 2020, and 2021, with no real update other than 2019 the motion for a class action was denied as moot. The case was stayed until December 2021.","Case stayed","12/10/2021","C.S. et al v. Saiki: Judge granted Oregon residents relying on in-home attendants an injunction against an aglorithm that vastly cut their hours, and ordered restoration of their previous algorithm that produced the expected hours for disabilities benefits while the state developed a new assessment algorithm The Oregon Office of Developmental Disability Services implemented the ANA-C or CNA-C assessment tool to calculate authorized hours for in-home attendant hours for those with intellectual or developmental disabilities. The plaintiffs filed this action because they received a decrease in hours for services. The complaint filed for a preliminary injunction against the further use of this assessment tool, and was ordered to prospectively restore all hours by ANA-C or CNA-C and notify the affected people. 
The DDS could continue to use the ANA-C or CNA-C to evaluate those with intellectual or developmental disabilities but could not reduce in-home attendant care services below the “status quo” level of care that they received as of November 1, 2016. On April 10, 2017, Plaintiffs filed a complaint, a Motion for a Preliminary Injunction, and Motion for Protective Order and to Proceed Anonymously. On April 19, 2017, the judge granted the preliminary injunction, and the following day granted Motion to Proceed Anonymously. The case stalled in the rest of 2017, with joint status report filed every six months in 2018, 2019, 2020, and 2021, with no real update other than 2019 the motion for a class action was denied as moot. The case was stayed until December 2021.  ANA-C; CNA-C Health; Disabilities Benefits; Public Benefits Preliminary Injunction; Title II Americans with Disabilities Act; Medicaid Act Transparency in Change of Algorithm; Lack of Remedy"
"32","32","McPherson v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA and receives unjust enrichment. Sought injunctive relief, declaratory jt., restitution, damages, and litigation costs","'Facial Recognition'","Facial Recognition","'BIPA','Unjust Enrichment'","BIPA; unjust enrichment","'Privacy'","Privacy","'Clearview'","Clearview","","Yes","","Federal:  US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois","4/15/2020","","0","Active","2/15/2021","5/1/2022","","","One of the last complaints to be filed against Clearview in SDNY, it brought identical claims using almost identical wording. Unlike the other cases, which also included Clearview co-founders as defendants, McPherson also sued Does 1-10 who are other owners, directors, officers, and/or shareholders of Clearview to carry out the ""unlawful scheme""","Plaintiff filed its complaint on April 15 under BIPA but in SDNY. The two subclasses are the subclass one: the BIPA class and subclass two: the unjust enrichment class.

Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA. 

On May 29, Judge McMahon denied Mutnick's motion to intervene. However, like the other cases, the case was stayed in September to wait for the MDL decision.","MDL Transfer Out","1/12/2021","McPherson v. Clearview AI, Inc. Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA and receives unjust enrichment. Sought injunctive relief, declaratory jt., restitution, damages, and litigation costs One of the last complaints to be filed against Clearview in SDNY, it brought identical claims using almost identical wording. Unlike the other cases, which also included Clearview co-founders as defendants, McPherson also sued Does 1-10 who are other owners, directors, officers, and/or shareholders of Clearview to carry out the ""unlawful scheme"" Plaintiff filed its complaint on April 15 under BIPA but in SDNY. The two subclasses are the subclass one: the BIPA class and subclass two: the unjust enrichment class.

Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA. 

On May 29, Judge McMahon denied Mutnick's motion to intervene. However, like the other cases, the case was stayed in September to wait for the MDL decision.  Clearview Facial Recognition BIPA; unjust enrichment Privacy"
"48","48","In Re Clearview Litigation","The consolidation of ten multidistrict litigation class action lawsuits against Clearview AI for 1. violating BIPA 2. unjust enrichment and 3. violating the plaintiffs' civil rights: Calderon, Broccolino, McPherson, Burke, John, and Roberson from SDNY; Mutnick, Hall, and Marron in ND Ill; and Renderos in ND Cal. A case not consolidated was Carmean v. Macy's.","'Biometric Data','Facial Recognition'","Facial Recognition; Biometric Data","'BIPA','Civil Rights','Unjust Enrichment'","Civil Rights; BIPA; unjust enrichment","'Misrepresentation','Privacy'","Privacy; Misrepresenation","'Clearview'","Clearview","","Yes","","Federal: US Dist. Ct. N.D. Illinois","1/8/2021","Yes","-1","Active","3/22/2021","4/2/2021","RA Done; Check for Recent Activity","Jenna","Clearview intended to consolidate these cases because they each spurred from the same facts and allegations. The state law claims against Clearview for violating the Biometric information Privacy Act (""BIPA"") section 15(c) for profiting and sharing biometric data, but the claims do not include section 15(a) or 15(b) for consent and data retention. 

The current motion for injunction is to enjoin Clearview from future uses of its facial recognition software in a global context, particularly given its pending patent.","Eleven cases were brought in 2020 relating to Clearview and co-defendants unlawfully collecting and profiting off of biometric data from three million photographs online, violating BIPA, unjustly enriching Clearview, and violating the civil rights of these plaintiffs. The first case was filed in January 2020. 

Clearview intended to consolidate eleven cases in federal court in New York, but nine cases were consolidated in Illinois under a MultiDistrict Litigation Order in January 2021. Six of these cases came from SDNY and three from ND Illinois. Clearview had previously removed these claims to federal court under the Class Action Fairness Act. In addition, the cases Thornley and ACLU in Cook County of Illinois charge BIPA violations, and there is a California state case filed.

In late October 2020, the circuit judge ruled that because ""plaintiffs are seeking only statutory damages, not actual damages for “a concrete, particularized harm,” the suit fails to meet the criteria for standing in federal court."" Clearview appealed to the Seventh Circuit Court of Appeals in January, but the court rejected the appeal. Clearview filed a motion to rehear its appeal in February, arguing that they have federal standing because previous cases have ruled that data is a property harm.

The parties mediated throughout February, and filed a Joint Proposed Case Management and Discovery Plan on March 22. Plaintiffs are challenging ""Clearview's entire operation over multiple years"" and proposed six months for factual discovery whereas Clearview proposed one year and emphasized that the fact that other state law cases are being brought should not impact this discovery. Clearview also urged the court to reject the plaintiff's request to reserve the right to file for class certification prior to defendant's ""anticipated"" motion to dismiss.","Summons and answers due May 6, 2021","4/15/2021","In Re Clearview Litigation The consolidation of ten multidistrict litigation class action lawsuits against Clearview AI for 1. violating BIPA 2. unjust enrichment and 3. violating the plaintiffs' civil rights: Calderon, Broccolino, McPherson, Burke, John, and Roberson from SDNY; Mutnick, Hall, and Marron in ND Ill; and Renderos in ND Cal. A case not consolidated was Carmean v. Macy's. Clearview intended to consolidate these cases because they each spurred from the same facts and allegations. The state law claims against Clearview for violating the Biometric information Privacy Act (""BIPA"") section 15(c) for profiting and sharing biometric data, but the claims do not include section 15(a) or 15(b) for consent and data retention. 

The current motion for injunction is to enjoin Clearview from future uses of its facial recognition software in a global context, particularly given its pending patent. Eleven cases were brought in 2020 relating to Clearview and co-defendants unlawfully collecting and profiting off of biometric data from three million photographs online, violating BIPA, unjustly enriching Clearview, and violating the civil rights of these plaintiffs. The first case was filed in January 2020. 

Clearview intended to consolidate eleven cases in federal court in New York, but nine cases were consolidated in Illinois under a MultiDistrict Litigation Order in January 2021. Six of these cases came from SDNY and three from ND Illinois. Clearview had previously removed these claims to federal court under the Class Action Fairness Act. In addition, the cases Thornley and ACLU in Cook County of Illinois charge BIPA violations, and there is a California state case filed.

In late October 2020, the circuit judge ruled that because ""plaintiffs are seeking only statutory damages, not actual damages for “a concrete, particularized harm,” the suit fails to meet the criteria for standing in federal court."" Clearview appealed to the Seventh Circuit Court of Appeals in January, but the court rejected the appeal. Clearview filed a motion to rehear its appeal in February, arguing that they have federal standing because previous cases have ruled that data is a property harm.

The parties mediated throughout February, and filed a Joint Proposed Case Management and Discovery Plan on March 22. Plaintiffs are challenging ""Clearview's entire operation over multiple years"" and proposed six months for factual discovery whereas Clearview proposed one year and emphasized that the fact that other state law cases are being brought should not impact this discovery. Clearview also urged the court to reject the plaintiff's request to reserve the right to file for class certification prior to defendant's ""anticipated"" motion to dismiss.  Clearview Facial Recognition; Biometric Data Civil Rights; BIPA; unjust enrichment Privacy; Misrepresenation"
"67","67","Brooks v. Commonwealth","The court dismissed the Virginia ACLU’s challenge to the risk assessment tool because the algorithm was only advisory in nature","'Criminal Justice','Recidivism','Sentencing'","","'Due Process'","","'Use of Race','AI Adjacent'","","","","","","ACLU","State:  Circuit Court of the City of Waynesboro Virginia","2004","Yes","-1","Inactive","10/28/2021","11/10/2021","RA Done","Jenna","In a case involving risk assessment calculation tools, the Court of Appeals of Virginia notes that the General Assembly created the Virginia Criminal Sentencing Commission in 1994 to develop and implement ""discretionary sentencing guidelines"" to assist the judiciary in imposing sentences. The sex offense risk assessment guidelines of factors that were statistically significant to recidivism predictions.  The general assembly then ""developed a risk assessment instrument that scored risk factors according to their relative importance in the statistical model.""","Defendant Drew Brooks was arrested and charged with statutory rape. Brooks pleaded guilty, and the judge ordered a pre-sentence report: ""The sentencing guidelines worksheets prepared with the pre-sentence report calculated an active sentence of 7 to 16 months. After adjusting the recommendation for the defendant's risk assessment score, the upper limit of the recommendation increased to 24 months. The trial court imposed an active sentence of 18 months."" The risk assessment guidelines were a tool for the judge to consider but was not required to follow. The trial court sentenced him to ten years in prison, relying heavily on risk assessment factors to calculate recidivism. Brooks appealed this use. in affirming the trial court's use of the risk assessment factors,  The Court of Appeals notes that the court wil noht inerfere when the sentence is within the legislature set statutory limits.  Because satutory rape is subject to imprisonment of 2 to 10 years, and 10 years was within the statutory limits, the trial court did not err in sentencing. Even though the judge heavily relied on the risk assessment factors, the court properly exercised discretion.","","","Brooks v. Commonwealth The court dismissed the Virginia ACLU’s challenge to the risk assessment tool because the algorithm was only advisory in nature In a case involving risk assessment calculation tools, the Court of Appeals of Virginia notes that the General Assembly created the Virginia Criminal Sentencing Commission in 1994 to develop and implement ""discretionary sentencing guidelines"" to assist the judiciary in imposing sentences. The sex offense risk assessment guidelines of factors that were statistically significant to recidivism predictions.  The general assembly then ""developed a risk assessment instrument that scored risk factors according to their relative importance in the statistical model."" Defendant Drew Brooks was arrested and charged with statutory rape. Brooks pleaded guilty, and the judge ordered a pre-sentence report: ""The sentencing guidelines worksheets prepared with the pre-sentence report calculated an active sentence of 7 to 16 months. After adjusting the recommendation for the defendant's risk assessment score, the upper limit of the recommendation increased to 24 months. The trial court imposed an active sentence of 18 months."" The risk assessment guidelines were a tool for the judge to consider but was not required to follow. The trial court sentenced him to ten years in prison, relying heavily on risk assessment factors to calculate recidivism. Brooks appealed this use. in affirming the trial court's use of the risk assessment factors,  The Court of Appeals notes that the court wil noht inerfere when the sentence is within the legislature set statutory limits.  Because satutory rape is subject to imprisonment of 2 to 10 years, and 10 years was within the statutory limits, the trial court did not err in sentencing. Even though the judge heavily relied on the risk assessment factors, the court properly exercised discretion. ACLU    "
"84","84","e-ventures Worldwide, LLC v. Google, Inc.","This lawsuit, brought in the Middle District of Florida, alleges that Google's statement that it does not censor search results is ""false, deceptive, and misleading,"" and thus violates the Lanham Act and the Florida Deceptive and Unfair Trade Practices Act. The plaintiff company argues that Google made all of its websites disappear from search results, and because Google dominates the search engine market, essentially made the plaintiff's website disappear from the internet. The court ultimately dismissed, stating that the First Amendment protected Google's decision making when displaying search results.","'Advertising','Trading'","Advertising, Trading","'Unfair and Deceptive Practices','Unfair and Deceptive Trade Practices'","Lanham Act; Florida Deceptive and Unfair Trade Practices Act; First Amendment","'Targeted Advertising'","Unfair Trade Practices; Misleading Advertising","","SEO","'No'","","","M.D. Fla.","11/04/2014","","-1","Inactive: Judgment for D","3/4/2023","3/4/2023","","Allie","","","","","e-ventures Worldwide, LLC v. Google, Inc. This lawsuit, brought in the Middle District of Florida, alleges that Google's statement that it does not censor search results is ""false, deceptive, and misleading,"" and thus violates the Lanham Act and the Florida Deceptive and Unfair Trade Practices Act. The plaintiff company argues that Google made all of its websites disappear from search results, and because Google dominates the search engine market, essentially made the plaintiff's website disappear from the internet. The court ultimately dismissed, stating that the First Amendment protected Google's decision making when displaying search results.    SEO Advertising, Trading Lanham Act; Florida Deceptive and Unfair Trade Practices Act; First Amendment Unfair Trade Practices; Misleading Advertising"
