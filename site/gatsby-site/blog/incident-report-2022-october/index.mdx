---
title: 'AI Incident Roundup ‚Äì October ‚Äò22'
metaTitle: 'AI Incident Roundup ‚Äì October ‚Äò22'
metaDescription: 'Collection of AI incidents, developments, and ingestion in October of 2022, providing a digestible recap on the latest incidents and reports of the AIID.'
date: '2022-11-14'
image: './images/aiid-october.webp'
author: 'Janet Schwartz & Khoa Lam'
slug: '/blog/incident-report-2022-october'
---

Welcome to this month‚Äôs edition of _The Monthly Roundup_, a newsletter designed to give you a digestible recap on the latest incidents and reports of the AI Incident Database.

**Estimated reading time:** 5 minutes

## üóûÔ∏è New Incidents

_Emerging incidents that occurred last month:_

**Incident #377:** [Weibo Model Has Difficulty Detecting Shifts in Censored Speech](/cite/377)

* **What happened?** The Chinese social media site Weibo's user moderation model has difficulty keeping up with shifting user slang in defiance of Chinese state censors.
* **How is the AI _not_ working?** Although the site says it has refined its ‚Äúkeyword identification model‚Äù to be able to filter the use of intentionally misspelled words and homophones, the diversity and ever-evolving nature of online language in China makes it unlikely its model will be able to fully ban controversial language.
* **What was the impact of this incident?** Chinese citizens were able to undermine the efforts of Weibo to impose censorship of banned language, thus allowing them to discuss controversial topics such as government corruption.
* **Who was involved?** [Weibo](/entities/weibo) developed and deployed an AI system, which harmed Weibo and the [Chinese government](/entities/chinese-government).
* üö® **Editor's Note:** The definition of alleged "harm" to a party does not indicate it is the responsibility of the broader community to mitigate or prevent that harm. Although this incident meets the criteria, database editors are making no claims about whether this incident should be prevented from recurring. The AIID indexes all incidents meeting its incident [definition](/research/1-criteria); our responsibility is to make such incidents known (e.g., [Incident #13](/cite/13), where language toxicity models were shown to be easily fooled).

**Incident #383:** [Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud](/cite/383)

* **What happened?** Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title. It is unclear when or how Google's speakers stopped censoring the n-word.
* **Who was involved?** [Google Home](/entities/google-home) developed and deployed an AI system, which harmed [Black Google Home Mini users](/entities/black-google-home-mini-users) and [Google Home Mini users](/entities/google-home-mini-users).

**Incident #384:** [Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident](/cite/384)

* **What happened?** Delivery company Glovo's automated system sent an email terminating an employee for "non-compliance terms and conditions" after the employee was killed in a car accident while making a delivery on Glovo's behalf.
* **Who was involved?** [Glovo](/entities/glovo) developed and deployed an AI system, which harmed [Sebastian Galassi](/entities/sebastian-galassi) and [Sebastian Galassi's family](/entities/sebastian-galassi's-family).

**Incident #385:** [Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling](/cite/385)

* **What happened?** The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.
* **How does the AI work?** The AI system called Snapshot creates a composite facial sketch based on physical appearance attributes generated by DNA phenotyping is the process of predicting physical appearance and ancestry from unidentified DNA evidence.
* **How did this AI cause harm?** DNA phenotyping composites are approximations of appearance, and it is not clear that the Snapshot profiles match their subjects. In this case since the AI-generated suspect was Black, it raised concerns about racial profiling in a marginalized community.
* **Who was involved?** [Parabon Nanolabs](/entities/parabon-nanolabs) developed an AI system deployed by [Edmonton Police Service](/entities/edmonton-police-service), which harmed [Black residents in Edmonton](/entities/black-residents-in-edmonton).

<br/>

## üìé New Developments

_Older incidents that have new reports or updates._

<table className="border-1 border-gray-200 my-4">
 <tr>
  <th align="center">Original incident</th>
  <th align="center">New report(s)</th>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #376:</strong> <a href="/cite/376">RealPage's Algorithm Pushed Rent Prices High, Allegedly Artificially</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>How a Secret Rent Algorithm Pushes Rents Higher ‚Äì<em> <a href="https://www.propublica.org/article/yieldstar-rent-increase-realpage-rent">ProPublica</a>, October 15, 2022</em>
    </li>
    <li>Is an Algorithm Raising Your Rent? A New Class Action Lawsuit Says Yes - <em><a href="https://gizmodo.com/realpage-yieldstar-high-rent-housing-class-action-suit-1849683731">Gizmodo</a>, October 21, 2022</em>
    </li>
    <li>RealPage‚Äôs YieldStar Software May Be Driving Up Rents - <em><a href="https://therealdeal.com/2022/10/17/realpage-algorithm-could-be-driving-up-rents/">The Real Deal</a>, October 17, 2022</em>
    </li>
   </ul>
  </td>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #373:</strong> <a href="/cite/373">Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims for Thousands of People</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>The Seven-Year Struggle to Hold an Out-of-Control Algorithm to Account - <em><a href="https://themarkup.org/newsletter/hello-world/the-seven-year-struggle-to-hold-an-out-of-control-algorithm-to-account">The Markup</a>, October 8, 2022</em>
    </li>
    <li>Michigan will settle 2015 unemployment false fraud lawsuit for $20 million - <em><a href="https://www.freep.com/story/news/local/michigan/2022/10/20/michiganunemployment-false-fraud-lawsuit/69577567007/">Detroit Free Press</a>, October 20, 2022</em>
    </li>
   </ul>
  </td>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #267:</strong> <a href="/cite/267">Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
     <li>French regulator fines US face recognition firm Clearview AI ‚Ç¨20 million, <em><a href="https://www.lemonde.fr/en/pixels/article/2022/10/20/french-regulator-fines-us-face-recognition-firm-clearview-ai-20-million_6001116_13.html">Le Monde</a>, October 20, 2022</em>
     </li>
   </ul>
  </td>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #382:</strong> <a href="/cite/382">Instagram's Exposure of Harmful Content Contributed to Teenage Girl‚Äôs Suicide</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
     <li>British Ruling Pins Blame on Social Media for Teenager‚Äôs Suicide - <em><a href="https://www.nytimes.com/2022/10/01/business/instagram-suicide-ruling-britain.html">New York Times</a>, October 1, 2022</em>
     </li>
   </ul>
  </td>
 </tr>
</table>

## üóÑ From the Archives

_Every edition, we feature one or more historical incidents that we find thought-provoking._

While in October we saw humans outwitting an automated system to avoid state censorship in China, other historical incidents recently added to the database highlight AI systems violating privacy in furtherance of state or commercial interests. An incident from 2019 echoes the concerns of state surveillance with the Ugandan government reportedly using facial recognition software to monitor political opposition. Meanwhile in the private sector, Uber allegedly violated drivers‚Äô data privacy rights in order to monitor performance in 2020 and McDonald‚Äôs faced a lawsuit in 2021 for potentially violating Illinois privacy laws by collecting voice data through their drive-through chatbot.

Outside of the deliberate use of AI systems to collect and use private data, there are several previous examples of automated systems mistakenly collecting or sharing that data. In 2018, an Amazon Echo mistakenly sent a recorded private conversation between a husband and wife to one of the husband‚Äôs employees without either of their knowledge. GPT-2, the predecessor to GPT-3, was reportedly able to recite Personal Identifiable Information (PII) that it learned through training on massive amounts of data from the internet.

These occurrences from the last few years highlight common themes of privacy concerns that are increasingly concerns of legal systems providing rights to privacy and data protection.

_‚Äì by Janet Schwartz_

## üëá Diving Deeper

* All new incidents _added_ to the database in the last month, grouped by topic:
    - **Privacy & surveillance**: [#354](/cite/354), [#357](/cite/357), [#360](/cite/360), [#361](/cite/361), [#371](/cite/371), [#372](/cite/372), [#377](/cite/377)
    - **Facial recognition:** [#358](/cite/358), [#365](/cite/365), [#368](/cite/368), [#373](/cite/373), [#375](/cite/375), [#385](/cite/385)
    - **Bias & discrimination:** [#355](/cite/355), [#356](/cite/356), [#359](/cite/359), [#367](/cite/367), [#374](/cite/374), [#383](/cite/383/)
    - **Social media:** [#362](/cite/362), [#363](/cite/363), [#366](/cite/366), [#380](/cite/380), [#382](/cite/382)
    - **Impactful errors:** [#364](/cite/364), [#379](/cite/379), [#384](/cite/384)
    - **Unfair competition:** [#370](/cite/370), [#376](/cite/376)
    - **Autonomous vehicles:** [#378](/cite/378), [#381](/cite/381)
    - **Labor displacement:** [#369](/cite/369)
* Explore clusters of similar incidents in [Spatial Visualization](/summaries/spatial)
* Check out [Table View](/apps/incidents) for a complete view of all incidents
* Learn about alleged developers, deployers, and harmed parties in [Entities Page](/entities)

<hr className="my-4"/>

## ü¶æ Support our Efforts

Still reading? Help us change the world for the better!

1. Share this newsletter on [LinkedIn](https://www.linkedin.com/company/responsible-ai-collaborative), [Twitter](https://twitter.com/IncidentsDB), and [Facebook](https://www.facebook.com/IncidentsDB)
2. [Submit](/apps/submit) incidents to the database
3. [Contribute](https://github.com/responsible-ai-collaborative/aiid) to the database‚Äôs functionality

