---
title: "Acerca de"
metaTitle: "Los detalles sobre quién y por qué para la base de datos."
metaDescription: "¿Quiénes son las personas y organizaciones que desarrollan el AIID y por qué lo estamos desarrollando?"
slug: "/about"
---

import Leaderboards from '../../src/components/landing/Leaderboards';
import Sponsors from '../../src/components/landing/Sponsors';

# ¿Por qué "Incidentes de IA"?

Actualmente, los sistemas inteligentes son propensos a fallas imprevistas y, a menudo, peligrosas cuando se implementan en el mundo real. Al igual que el sector del transporte anterior (por ejemplo, [FAA](https://www.faa.gov/data_research/accident_incident/) y [FARS](https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars) y más recientemente [sistemas informáticos](https://cve.mitre.org/cve/), los sistemas inteligentes requieren un repositorio de problemas experimentados en el mundo real para que los futuros investigadores y desarrolladores puedan mitigar o evitar la repetición de malos resultados.

# ¿Qué es un incidente?

El conjunto inicial de más de 1000 informes de incidentes ha sido intencionalmente de naturaleza amplia. Los ejemplos actuales incluyen,

* Un *coche autónomo* [mata a un peatón](/cite/4)
* Un *algoritmo de negociación* provoca un mercado "[flash crash](/cite/28)" donde se transfieren miles de millones de dólares entre las partes
* Un *sistema de reconocimiento facial* [hace que una persona inocente sea arrestada](/cite/74)

Lo invitamos a [explorar los incidentes recopilados hasta la fecha](/apps/discover), [ver la lista completa](/summaries/incidents) y [enviar](/apps/submit) informes de incidentes adicionales. Se invita a los investigadores a revisar nuestra [definición de trabajo de incidentes de IA](/research/1-criteria).

# Usuarios actuales y futuros

La base de datos es un [producto de datos](/develop) y [una colección de aplicaciones](/apps) [en constante evolución](/research/2-roadmap).

* **Usuarios actuales** incluye arquitectos de sistemas, desarrolladores de productos industriales, gerentes de relaciones públicas, [investigadores](/research) e investigadores de políticas públicas. Se invita a estos usuarios a usar la aplicación [Discover](/apps/discover) para descubrir de manera proactiva cómo los sistemas inteligentes implementados recientemente han producido resultados inesperados en el mundo real. Al hacerlo, pueden evitar cometer errores similares en su desarrollo.
* **Los usos futuros** [evolucionarán](/research/2-roadmap) a través de las contribuciones de código de la comunidad [de código abierto](https://github.com/PartnershipOnAI/aiid), incluida la base de datos adicional [resúmenes](/apps/summaries) y [taxonomías](/research/2-roadmap).

# ¿Cuándo debe informar un incidente?

Cuando tenga dudas sobre si un evento califica como incidente, [envíelo](/apps/submit). Este proyecto pretende converger en una [definición compartida](/research/1-criteria) de "Incidente de IA" a través de la exploración de los incidentes candidatos presentados por la comunidad en general.

# Junta Directiva

La base de datos de incidentes es administrada de manera participativa por personas y organizaciones que aportan código, investigación e impactos más amplios. Si desea participar en la gobernanza del proyecto, [contactenos](/contact) con nosotros e incluya su contribución prevista a la base de datos de incidentes de AI.

**Miembros votantes**

* **[Helen Toner](https://cset.georgetown.edu/staff/helen-toner/):** Helen Toner es Directora de Estrategia en el Centro de Seguridad y Tecnología Emergente (CSET) de Georgetown. Anteriormente, trabajó como analista de investigación sénior en Open Philanthropy, donde asesoró a legisladores y donantes sobre políticas y estrategias de IA. Entre trabajar en Open Philanthropy y unirse a CSET, Helen vivió en Beijing y estudió el ecosistema chino de IA como investigadora afiliada del Centro para la Gobernanza de la IA de la Universidad de Oxford. Helen ha escrito para Foreign Affairs y otros medios sobre las implicaciones de seguridad nacional de la IA y el aprendizaje automático para China y los Estados Unidos, además de testificar ante la Comisión de Revisión Económica y de Seguridad de EE. UU.-China. Es miembro de la junta directiva de OpenAI. Helen tiene una Maestría en Estudios de Seguridad de Georgetown, así como una Licenciatura en Ingeniería Química y un Diplomado en Idiomas de la Universidad de Melbourne.
**Contribuciones:** [Investigación de incidentes de IA](https://cset.georgetown.edu/publication/ai-accidents-an-emerging-threat/) y supervisión de la [taxonomía CSET](https://incidentdatabase.ai/taxonomía/cset).

* **[Patrick Hall](https://business.gwu.edu/johnston-patrick-hall):** Patrick es científico principal en bnh.ai, una firma de abogados con sede en D.C. que se especializa en IA y análisis de datos. Patrick también se desempeña como profesor visitante en la Escuela de Negocios de la Universidad George Washington. Antes de cofundar bnh.ai, Patrick lideró los esfuerzos de inteligencia artificial responsable en la firma de software de aprendizaje automático H2O.ai, donde su trabajo resultó en una de las primeras soluciones comerciales del mundo para el aprendizaje automático explicable y justo. Entre otros escritos académicos y de medios tecnológicos, Patrick es el autor principal de libros electrónicos populares sobre aprendizaje automático explicable y responsable. Patrick estudió química computacional en la Universidad de Illinois antes de graduarse del Instituto de Analítica Avanzada de la Universidad Estatal de Carolina del Norte.
**Contribuciones:** Patrick es el colaborador [principal](https://incidentdatabase.ai/summaries/leaderboard) de informes de incidentes para el Proyecto de base de datos de incidentes de AI.

* **[Sean McGregor](https://seanbmcgregor.com/):** Sean McGregor fundó AI Incident Da