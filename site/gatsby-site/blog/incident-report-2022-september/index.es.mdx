---
title: 'Resumen de incidentes de IA para septiembre de 2022'
metaTitle: 'Resumen de incidentes de IA para septiembre de 2022'
metaDescription: 'Esta compilación de incidentes de IA publicados en septiembre de 2022 destaca los incidentes emergentes y proporciona un resumen de las adiciones recientes a la base de datos.'
date: '2022-10-17'
image: './images/aiid-september.webp'
author: 'Janet Schwartz y Khoa Lam'
slug: '/blog/incident-report-2022-september'
aiTranslated: true
---

Bienvenido a la edición de este mes de _The Monthly Roundup_, un boletín informativo diseñado para brindarle un resumen digerible de los últimos incidentes e informes de la base de datos de incidentes de AI.

**Tiempo estimado de lectura:** 5 minutos

## 🗞️ Nuevos incidentes

_Incidentes emergentes que ocurrieron el mes pasado:_

**Incidente n.º 339:** [Modelos generativos de código abierto abusado ​​por estudiantes para hacer trampa en las tareas](/cite/339)

* **¿Qué sucedió?** Según los informes, los estudiantes usaban modelos generativos de texto de código abierto, como GPT-3 de OpenAI, para hacer trampa en tareas como escribir informes y ensayos.
* **¿Cómo funciona la IA?** De manera similar a cómo funciona Autocompletar en los teléfonos, estos "modelos generativos" se entrenaron en fuentes ricas de texto como Internet para generar contenido nuevo basado en un mensaje inicial, pero están diseñados para completar oraciones completas o incluso ensayos completos en lugar de palabras.
* **¿Cómo causó daño esta IA?** La mayoría de los educadores ven este mal uso de la IA como una violación de la integridad académica y una ventaja injusta frente a otros estudiantes, aunque algunos también ven el potencial de la IA como una valiosa herramienta de ayuda al estudio para los estudiantes si se usa. responsablemente
* **¿Quien estaba involucrado? **[Sudowrite](/entities/sudowrite) y [OpenAI](/entities/openai) desarrollaron un sistema de IA implementado por [estudiantes](/entities/students), que perjudicó a [maestros](/entities/teachers), [alumnos tramposos](/entities/cheating-students) y [estudiantes no tramposos](/entities/non-cheating-students).

**Incidente n.º 350:** [Robot de reparto rodó por la escena del crimen](/cite/350)

* **¿Qué sucedió?** Un robot de reparto de Serve Robotics se mostró en un video rodando por la escena del crimen bloqueada por cinta policial.
* **¿Cómo estuvo involucrado el robot?** Cuando el robot autónomo se acercó a la intersección, según la política interna de la empresa, un operador humano tomó el control de forma remota y tomó la decisión de continuar y cruzar la cinta de precaución.
* **¿Cómo causó daño este robot?** El robot operado por humanos confundió a los transeúntes en la escena del crimen acerca de su intención y autonomía, e invadió el área de investigación de la policía local.
* **¿Quién estuvo involucrado?** [Serve Robotics](/entities/serve-robotics) desarrolló e implementó un sistema de IA que perjudicó a los investigadores policiales.

**Incidente n.º 351:** [Clip de "La Sirenita" manipulado usando IA generativa para reemplazar a la actriz negra con un personaje blanco](/cite/351)

* **¿Qué sucedió?** Según se informa, un usuario de Twitter modificó un breve clip de la versión 2022 de Disney de "La Sirenita" usando IA generativa, reemplazando a una actriz negra con un personaje digital blanco. Desde entonces, el usuario de Twitter fue expulsado de la plataforma.
* **¿Cómo funciona la IA?** Esta IA es un ejemplo de tecnología de falsificación profunda, en la que los cuadros de video se proporcionaron como entradas a un modelo que se entrenó previamente para crear nuevos cuadros, a menudo cambiando alguna característica en el original fotogramas: en este caso, el color de la cara y la piel del personaje del vídeo.
* **¿Cómo causó daño esta IA?** Este uso de la IA para cambiar el color de la piel de una actriz negra en una película fue visto como una forma de "blanqueo" y "cara negra" que refuerza la supresión de un grupo históricamente desfavorecido. .
* **¿Quién estuvo involucrado?** Una entidad desconocida desarrolló un sistema de IA implementado por [@TenGazillioinIQ](/entities/@tengazillioiniq), que perjudicó a [Halle Bailey](/entities/halle-bailey) y [actrices negras](/entities/black-actresses).

**Incidente n.° 352:** [Bot de Twitter basado en GPT-3 secuestrado mediante ataques de inyección inmediata](/cite/352)

* **¿Qué sucedió?** Se mostró que el bot de Twitter basado en GPT-3 de Remoteli.io fue secuestrado por usuarios de Twitter que lo redireccionaron para repetir o generar cualquier frase.
* **¿Cómo funciona la inyección de avisos?** Debido a que GPT-3 interpreta el aviso del usuario recopilado por el bot tal cual, los usuarios pueden crear avisos específicos para ordenar al modelo que ignore una instrucción anterior y realice otra acción en su lugar.
* **¿Cómo causó daño este bot?** Cuando el bot Remoteli.io fue secuestrado, el desarrollador lo usó para fines no previstos, como crear una amenaza, aunque hasta ahora los casos han ido más del lado del humor.
* **¿Quién estuvo involucrado?** [OpenAI](/entities/openai) y [Stephan de Vries](/entities/stephan-de-vries) desarrollaron un sistema de IA implementado por Stephan de Vries, que también perjudicó al desarrollador.

<br/>

## 📎 Nuevos desarrollos

_Incidentes antiguos que tienen nuevos informes o actualizaciones._

<table className="border-1 border-gray-200 my-4">
  <tr>
    <td align="center">
      <strong>Incidente original</strong>
    </td>
    <td align="center">
      <strong>Nuevo(s) informe(s)</strong>
    </td>
  </tr>
  <tr>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <strong>Incidente n.º 293: </strong>
      <a href="/cite/293">
        El automóvil autónomo de Cruise involucrado en una colisión con lesiones múltiples en una intersección de San Francisco
      </a>
    </td>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <ul>
        <li>
          Cruise de GM retira del mercado el software de conducción autónoma involucrado en el accidente de junio –
          <em>
            <a href="https://www.wired.com/story/gms-cruise-recalls-self-driving-software-involved-in-june-crash/">
              cableado
            </a>,
            1 de septiembre de 2022
          </em>
        </li>
        <li>
          Cruise retira del mercado su robotaxis después de que un pasajero resultó herido en un accidente –
          <em>
            <a href="https://www.cnn.com/2022/09/01/business/cruise-robotaxis-recall/index.html">
              CNN
            </a>,
            1 de septiembre de 2022
          </em>
        </li>
      </ul>
   </td>
  </tr>
  <tr>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <strong>Incidente n.º 183:</strong>
      <a href="/cite/183">
        El algoritmo de confiabilidad de Airbnb supuestamente prohibió a los usuarios sin explicación y discriminó a las trabajadoras sexuales
      </a>
    </td>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <ul>
        <li>
          Tuit: @bethanyhallam –
          <em>
            <a href="https://twitter.com/bethanyhallam/status/1569484512266194944">
              Gorjeo
            </a>,
            12 de septiembre de 2022
          </em>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <strong>Incidente n.º 353:</strong>
      <a href="/cite/353">
        Tesla en piloto automático se estrelló contra un camión de remolque en Florida, matando al conductor
      </a>
    </td>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <ul>
        <li>
          El piloto automático de Tesla se dirige a la prueba –
          <em>
            <a href="https://www.bloomberg.com/news/articles/2022-09-13/tesla-trial-on-fatal-florida-crash-to-test-musk-autopilot-claims">
              Bloomberg
            </a>,
            20 de septiembre de 2022
          </em>
        </li>
        <li>
          La función de piloto automático de Tesla en el centro de la demanda por homicidio culposo en el condado de Palm Beach –
          <em>
            <a href="https://cbs12.com/news/local/tesla-crash-lawsuit-jeremy-banner-delray-beach-model-3-sr7-richard-wood-elon-musk-firstfleet-septiembre">
              CBS12
            </a>,
            20 de septiembre de 2022
          </em>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <strong>Incidente n.º 254:</strong>
      <a href="/cite/254">
        La agrupación de rostros de Google supuestamente recopiló y analizó la estructura facial de los usuarios sin consentimiento, violó la BIPA
      </a>
    </td>
    <td className="align-top border-1 border-gray-200 px-4 py-2">
      <ul>
        <li>
          El sábado es el último día para que los residentes de Illinois reclamen una parte del acuerdo de privacidad de Google Photos de $ 100 millones:
          <em>
            <a href="https://www.chicagotribune.com/business/ct-biz-google-bipa-settlement-claim-deadline-20220923-engws4owujbnjc6ixwuflrh77a-story.html">
              Chicago Tribune
            </a>,
            23 de septiembre de 2022
          </em>
        </li>
      </ul>
    </td>
  </tr>
</table>

## 👇 Profundizando más

* Explore grupos de incidentes similares en [Visualización espacial](/summaries/spatial)
* Consulte [Vista de tabla](/apps/incidents) para obtener una vista completa de todos los incidentes
* Obtenga información sobre presuntos desarrolladores, implementadores y partes perjudicadas en [Página de entidades](/entities)
* Todos los nuevos incidentes _agregados_ a la base de datos en el último mes, agrupados por tema:
    - **Tesla:** [#323](/cite/323), [#333](/cite/333), [#337](/cite/337)
    - **Vehículos autónomos:** [#340](/cite/340), [#341](/cite/341), [#347](/cite/347)
    - **Deep-falsificaciones:** [#324](/cite/324), [#328](/cite/328)
    - **Redes sociales:** [#325](/cite/325), [#326](/cite/326), [#327](/cite/327), [#331](/cite/331 ), [#343](/citar/343)
    - **Recomendación y sistemas de recuperación de información:** [#329](/cite/329), [#330](/cite/330), [#332](/cite/332), [#342](/cite/342)
    - **Sesgo y discriminación:** [#335](/cite/335), [#336](/cite/336), [#344](/cite/344)
    - **Altas tasas de error:** [#345](/cite/345), [#346](/cite/346)
    - **Uber:** [#334](/cite/334)

<hr className="my-4"/>

## 🦾 Apoya nuestros esfuerzos

¿Seguir leyendo? ¡Ayúdanos a cambiar el mundo para mejor!

1. Comparta este boletín en [LinkedIn](https://www.linkedin.com/company/responsible-ai-collaborative), [Twitter](https://twitter.com/IncidentsDB) y [Facebook](https://www.facebook.com/IncidentsDB)
2. [Enviar](/apps/submit) incidentes a la base de datos
3. [Contribuir](https://github.com/responsible-ai-collaborative/aiid) a la funcionalidad de la base de datos

