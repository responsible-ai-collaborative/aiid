---
title: "Acerca de"
metaTitle: "Los detalles sobre quién y por qué para la base de datos."
metaDescription: "¿Quiénes son las personas y organizaciones que desarrollan el AIID y por qué lo estamos desarrollando?"
slug: "/about"
aiTranslated: true
---

import Leaderboards from '../../src/components/landing/Leaderboards';
import Sponsors from '../../src/components/landing/Sponsors';

## ¿Por qué "Incidentes de IA"?

Los sistemas inteligentes actualmente son propensos a fallas imprevistas y a menudo peligrosas cuando se implementan en el mundo real. Al igual que el sector del transporte antes que este (por ejemplo, [FAA](https://www.faa.gov/data_research/accident_incident/) y [FARS](https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars)) y más recientemente los [sistemas informáticos](https://cve.mitre.org/cve/), los sistemas inteligentes requieren un repositorio de problemas experimentados en el mundo real para que futuros investigadores y desarrolladores puedan mitigar o evitar resultados negativos repetidos.

## ¿Qué es un Incidente?

El conjunto inicial de más de 1,000 informes de incidentes ha sido intencionalmente amplio en naturaleza. Los ejemplos actuales incluyen:

* Un *automóvil autónomo* [mata a un peatón](/cite/4)
* Un *algoritmo de trading* causa un "[flash crash](/cite/28)" del mercado donde miles de millones de dólares se transfieren entre partes
* Un *sistema de reconocimiento facial* [causa que una persona inocente sea arrestada](/cite/74)

Se le invita a [explorar los incidentes recopilados hasta la fecha](/apps/discover), [ver el listado completo](/summaries/incidents), y [enviar](/apps/submit) informes de incidentes adicionales. Los investigadores están invitados a revisar nuestra [definición de trabajo de incidentes de IA](/research/1-criteria).

## Usuarios Actuales y Futuros

La base de datos es un producto de datos en constante evolución y una colección de aplicaciones.

* **Usuarios Actuales** incluyen arquitectos de sistemas, desarrolladores de productos industriales, gerentes de relaciones públicas, [investigadores](/research), investigadores de políticas públicas y el público en general. Estos usuarios están invitados a usar la aplicación [Descubrir](/apps/discover) para descubrir proactivamente cómo los sistemas inteligentes recientemente implementados han producido resultados inesperados en el mundo real. Al hacerlo, pueden evitar cometer errores similares en el futuro.
* **Usos Futuros** [evolucionarán](/research/2-roadmap) a través de las contribuciones de código de la comunidad de [código abierto](https://github.com/responsible-ai-collaborative/aiid), incluyendo [resúmenes](/about_apps/) adicionales de la base de datos y [taxonomías](/research/2-roadmap).

## ¿Cuándo Debería Reportar un Incidente?

Cuando tenga dudas sobre si un evento califica como un incidente, ¡por favor [envíelo](/apps/submit)! Este proyecto está destinado a converger en un [criterio compartido](/research/1-criteria) para ingerir incidentes a través de la exploración de los incidentes candidatos enviados por la comunidad en general.

## Junta Directiva

La base de datos de incidentes se gestiona de manera participativa por personas y organizaciones que contribuyen con código, investigación e impactos más amplios. Si desea participar en la gobernanza del proyecto, por favor [contáctenos](/contact) e incluya su contribución prevista a la Base de Datos de Incidentes de IA.

**Miembros con Derecho a Voto**

* **[Patrick Hall](https://www.hallresearch.ai/team-patrick-hall/):** Patrick fue recientemente científico principal en bnh.ai, un bufete de abogados con sede en D.C. especializado en IA y análisis de datos. Patrick también es profesor asistente en la Escuela de Negocios de la Universidad George Washington. Antes de cofundar bnh.ai, Patrick lideró los esfuerzos de IA responsable en la empresa de software de aprendizaje automático H2O.ai, donde su trabajo resultó en una de las primeras soluciones comerciales del mundo para el aprendizaje automático explicable y justo. Entre otros escritos académicos y de medios tecnológicos, Patrick es el autor principal de libros electrónicos populares sobre aprendizaje automático explicable y responsable. Patrick estudió química computacional en la Universidad de Illinois antes de graduarse del Instituto de Análisis Avanzado en la Universidad Estatal de Carolina del Norte.  
**Contribuciones:** Patrick es un contribuidor [líder](https://incidentdatabase.ai/summaries/leaderboard) de informes de incidentes a la Base de Datos de Incidentes de IA y proporciona liderazgo estratégico para la junta.

* **[Heather Frase](https://www.linkedin.com/in/heather-frase/):** Heather Frase, PhD es Senior Fellow en el [Centro para la Seguridad y la Tecnología Emergente](https://cset.georgetown.edu/) (CSET) de Georgetown, donde trabaja en Evaluación de IA. También sirve como asesora no remunerada del proyecto Open Loop de Meta, proporcionando experiencia en la implementación del Marco de Gestión de Riesgos de IA del Instituto Nacional de Estándares y Tecnología. Antes de unirse a CSET, Heather pasó ocho años proporcionando análisis de datos, modelado computacional, Aprendizaje Automático (ML) y soporte de Inteligencia Artificial (IA) para contratos de Inteligencia, Defensa y Federales. Además, Heather pasó 14 años en el Instituto de Análisis de Defensa (IDA), apoyando al Director, Prueba y Evaluación Operacional (DOT&E). En IDA, dirigió equipos de investigación analítica para aplicar experiencia científica, tecnológica y estadística para desarrollar métricas de datos y planes de recolección para pruebas operacionales de sistemas de defensa principales, analizar datos de prueba y producir evaluaciones de efectividad y adecuación operacional. Tiene un Ph.D. en Ciencia de Materiales del Instituto de Tecnología de California y una licenciatura en Física de la Universidad de Miami en Oxford, Ohio.  
**Contribuciones:** Heather desarrolla investigación sobre incidentes de IA además de su supervisión de la [taxonomía CSET](https://incidentdatabase.ai/taxonomies/cset).

* **[Kristian J. Hammond](https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/hammond-kristian.html):** Kris Hammond es el Profesor Bill y Cathy Osborn de Ciencias de la Computación en la Universidad Northwestern y cofundador de la empresa de Inteligencia Artificial Narrative Science, recientemente adquirida por Salesforce. También es el líder docente de la iniciativa CS + X de Northwestern, explorando cómo el pensamiento computacional puede usarse para transformar campos como el derecho, la medicina, la educación y los negocios. Es director de la Maestría en Ciencias en Inteligencia Artificial (MSAI) de Northwestern. Más recientemente, el Dr. Hammond fundó el Centro para el Avance de la Seguridad en la Inteligencia de Máquinas (CASMI), un centro de investigación financiado por Underwriter's Laboratories. CASMI se centra en operacionalizar el diseño y la evaluación de sistemas de IA desde la perspectiva de su impacto en la vida y seguridad humanas.
**Contribuciones:** Kris está desarrollando un proyecto colaborativo centrado en los estudios de casos de incidentes.

**Junta Emérita**

Los miembros eméritos de la junta son aquellos que se han distinguido particularmente en su servicio a la Colaboración de IA Responsable. No tienen ninguna posición de gobernanza dentro de la organización.

* **[Sean McGregor](https://seanbmcgregor.com/):** Sean McGregor fundó el proyecto de la Base de Datos de Incidentes de IA y recientemente se unió al [Instituto de Investigación de Seguridad Digital](https://ul.org/research/digital-safety) como director fundador. Antes de iniciar la Colaboración de IA Responsable, Sean dejó un puesto como arquitecto de aprendizaje automático en la startup de aceleradores neuronales Syntiant para poder centrarse en la garantía de sistemas inteligentes a tiempo completo. El trabajo del Dr. McGregor abarca aceleradores neuronales para inferencia eficiente en energía, aprendizaje profundo para el habla y heliofísica, y aprendizaje por refuerzo para políticas de supresión de incendios forestales. Fuera de su trabajo remunerado, Sean organizó una serie de talleres en las principales conferencias académicas de IA sobre el tema de "IA para el Bien" y ahora busca realizar de manera segura los beneficios de la IA conectando los registros de incidentes de IA con los programas de prueba de IA.

* **[Helen Toner](https://cset.georgetown.edu/staff/helen-toner/):** Helen Toner es Directora de Estrategia en el Centro para la Seguridad y la Tecnología Emergente (CSET) de Georgetown. Anteriormente trabajó como Analista de Investigación Senior en Open Philanthropy, donde asesoró a formuladores de políticas y donantes sobre política y estrategia de IA. Entre trabajar en Open Philanthropy y unirse a CSET, Helen vivió en Beijing, estudiando el ecosistema de IA chino como Afiliada de Investigación del Centro para la Gobernanza de IA de la Universidad de Oxford. Helen ha escrito para Foreign Affairs y otros medios sobre las implicaciones de seguridad nacional de la IA y el aprendizaje automático para China y Estados Unidos, además de testificar ante la Comisión de Revisión Económica y de Seguridad de EE.UU.-China. Es miembro de la junta directiva de OpenAI. Helen tiene una Maestría en Estudios de Seguridad de Georgetown, así como una Licenciatura en Ingeniería Química y un Diploma en Idiomas de la Universidad de Melbourne.  

## Colaboradores

**Colaboración de IA Responsable:** Personas que sirven a la organización detrás de la Base de Datos de Incidentes de IA.

* Los miembros de la junta incluyen a [Patrick Hall](https://www.hallresearch.ai/team-patrick-hall/), [Heather Frase](https://www.linkedin.com/in/heather-frase/), y [Kristian J. Hammond](https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/hammond-kristian.html). Las biografías se indican arriba.
* [Sean McGregor](https://seanbmcgregor.com/about) es el Director Ejecutivo.
* [Daniel Atherton](https://www.linkedin.com/in/daniel-atherton-167819251/) es el editor principal de incidentes de IA.

Muchas personas y organizaciones adicionales sin afiliaciones formales con la Colaboración de IA Responsable contribuyen al proyecto.

**Instituto de Investigación de Seguridad Digital (DSRI):** Personas afiliadas con [DSRI](https://ul.org/research/digital-safety), que proporciona apoyo sustancial al programa AIID.

* [Kevin Paeth](https://www.linkedin.com/in/kevinpaeth/) es líder en DSRI
* [César Varela](https://github.com/cesarvarela) es Ingeniero Full Stack
* [Luna McNulty](https://lmcnulty.me/) es Ingeniera UX
* [Pablo Costa](https://www.linkedin.com/in/pablo-costa/) es Ingeniero Full Stack
* [Clara Youdale Pinelli](https://www.linkedin.com/in/clarayoudale/) es Ingeniera Front End
* [Sean McGregor](https://seanbmcgregor.com/) es director en DSRI

**Editores de Incidentes:** Personas que resuelven envíos de incidentes a la base de datos y los mantienen.

* [Daniel Atherton](https://www.linkedin.com/in/daniel-atherton-167819251/)
* [Sean McGregor](https://seanbmcgregor.com/)

Además, [Zachary Arnold](https://cset.georgetown.edu/staff/zachary-arnold/) hizo contribuciones significativas a los [criterios de incidentes](/research/1-criteria).

**Editores de Taxonomía:** Organizaciones o personas que han contribuido con [taxonomías](https://incidentdatabase.ai/taxonomies) a la base de datos.

* [Centro para la Seguridad y la Tecnología Emergente](https://cset.georgetown.edu/) (CSET)
* [Nikiforos Pittaras](https://npit.github.io/) (GMF)

**Contribuidores de Código Abierto:** Personas que han contribuido con más de una solicitud de extracción, gráficos, copia del sitio o informe de errores a la Base de Datos de Incidentes de IA.

* [Neama Dadkhahnikoo](https://www.linkedin.com/in/neama/): Neama sirvió como directora ejecutiva voluntaria y observadora de la junta para la Colaboración de IA Responsable
* [Jingying Yang](https://www.linkedin.com/in/jingyingyang/) y [Dr. Christine Custis](https://www.su.edu/symposium/business-symposium-speakers/christine-custis/) contribuyeron significativamente a las primeras etapas del AIID a través de sus roles con Partnership on AI.
* [Khoa Lam](https://www.linkedin.com/in/khoalklam/): Ha servido como editor de datos
* [Kate Perkins](https://www.linkedin.com/in/kateeperkins/): Ha servido como editora de datos
* [Scott Allen Cambo](https://www.scottallencambo.com/): Scott anteriormente sirvió como Director Ejecutivo para la Colaboración de IA Responsable
* [Janet Boutilier Schwartz](https://www.linkedin.com/in/janet-boutilier-schwartz/): Janet anteriormente consultó sobre operaciones y estrategia con la Colaboración de IA Responsable.
* [Kit Harris](https://www.linkedin.com/in/kitharris/): Kit sirvió como observador de la junta y proporcionó asesoramiento estratégico desde su posición como asesor de subvenciones.
* [Alex Muscă](https://github.com/alexmcode)
* [Chloe Kam](http://kamchy.com) Desarrolló el logo de AIID
* [JT McHorse](https://github.com/jt-mchorse)
* Seth Reid

**Contribuidores de Incidentes:** Personas que han contribuido con un gran número de incidentes a la base de datos.

* [Roman Lutz (Instituto Max Planck para Sistemas Inteligentes, anteriormente Microsoft)](/apps/discover?display=details&lang=en&page=1&submitters=Roman%20Lutz)
* [Patrick Hall (Burt and Hall LLP)](/apps/discover?display=details&lang=en&page=1&submitters=Patrick%20Hall%20%28BNH.ai%29)
* [Catherine Olsson (Google)](/apps/discover?display=details&lang=en&page=1&submitters=Catherine%20Olsson)
* [Roman Yampolskiy (Universidad de Louisville)](/apps/discover?display=details&lang=en&page=1&submitters=Roman%20Yampolskiy)
* Sam Yoon (como contratista de PAI, luego con Deloitte Consulting, luego con la Escuela Kennedy de Gobierno)

Las siguientes personas han recopilado un gran número de incidentes que están pendientes de ingesta.

* Zachary Arnold, Helen Toner, Ingrid Dickinson, Thomas Giallella, y Nicolina Demakos (Centro para la Seguridad y la Tecnología Emergente, Georgetown)
* Lawrence Lee, Darlena Phuong Quyen Nguyen, Iftekhar Ahmed (UC Irvine)

Existe una comunidad creciente de personas preocupadas por la recopilación y caracterización de incidentes de IA, y alentamos a todos a contribuir al desarrollo de este sistema.

<Leaderboards />
<br />

<Sponsors />
