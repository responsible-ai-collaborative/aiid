---
title: 'Resumen de incidentes de IA: 22 de noviembre'
metaTitle: 'Resumen de incidentes de IA: 22 de noviembre'
metaDescription: 'RecopilaciÃ³n de incidentes, desarrollos e ingestiÃ³n de IA en noviembre de 2022, que proporciona un resumen digerible de los Ãºltimos incidentes e informes de AIID.'
date: '2022-12-15'
image: './images/aiid-november.webp'
author: 'Janet Schwartz & Khoa Lam'
slug: '/blog/incident-report-2022-november'
---

Bienvenido a la ediciÃ³n de este mes de The Monthly Roundup, un boletÃ­n informativo diseÃ±ado para brindarle un resumen digerible de los Ãºltimos incidentes e informes de la base de datos de incidentes de AI.

Tiempo estimado de lectura: 3 minutos

## ğŸ—ï¸ Nuevos Incidentes

Incidentes emergentes que ocurrieron el mes pasado:

- Incidente n.Â° 399: [Se informa que el generador de artÃ­culos cientÃ­ficos de Meta AI produjo contenido inexacto y daÃ±ino](/cite/399)

   -   Â¿QuÃ© pasÃ³? Meta AI entrenÃ³ y alojÃ³ un generador de artÃ­culos cientÃ­ficos que a veces producÃ­a mala ciencia y prohibÃ­a consultas sobre temas y grupos que probablemente produzcan contenido ofensivo o daÃ±ino.
   -   Â¿Quien estaba involucrado? Meta AI, Meta y Facebook desarrollaron e implementaron un sistema de IA que daÃ±Ã³ a los grupos minoritarios, Meta AI, Meta y Facebook.

- Incidente n.Â° 410: [KFC enviÃ³ una promociÃ³n insensible de la Noche de los cristales rotos a travÃ©s del sistema de detecciÃ³n de dÃ­as festivos](/cite/410)

   -   Â¿QuÃ© pasÃ³? KFC citÃ³ un error en un sistema automatizado de detecciÃ³n de festividades que identificÃ³ el aniversario de la Kristallnacht y provocÃ³ una notificaciÃ³n automÃ¡tica insensible que promocionaba su pollo.
   -   Â¿Quien estaba involucrado? KFC desarrollÃ³ e implementÃ³ un sistema de inteligencia artificial que perjudicÃ³ al pueblo judÃ­o.

- Incidente n.Â° 411: [Cuentas chinas presuntamente enviaron spam a Twitter para ocultar noticias de protestas](/cite/411)

   -   Â¿QuÃ© pasÃ³? El algoritmo de alimentaciÃ³n de Twitter se vio inundado por contenido de cuentas en chino que supuestamente tenÃ­an como objetivo manipular y reducir la cobertura de las redes sociales sobre las protestas generalizadas contra las restricciones del coronavirus en China.
   -   Â¿Quien estaba involucrado? Twitter desarrollÃ³ e implementÃ³ un sistema de inteligencia artificial que perjudicÃ³ a los usuarios de Twitter y a Twitter.

- Incidente n.Â° 413: [Miles de respuestas incorrectas producidas por ChatGPT publicadas en Stack Overflow](/cite/413)

   -   Â¿QuÃ© pasÃ³? Miles de respuestas incorrectas producidas por ChatGPT de OpenAI se enviaron a Stack Overflow, lo que inundÃ³ el proceso de curaciÃ³n de calidad basado en voluntarios del sitio y perjudicÃ³ a los usuarios que buscaban respuestas correctas.
   -   Â¿Quien estaba involucrado? OpenAI desarrollÃ³ e implementÃ³ un sistema de inteligencia artificial que perjudicÃ³ a los usuarios de Stack Overflow y Stack Overflow.

## ğŸ“ Nuevos Desarrollos

Incidentes mÃ¡s antiguos que tienen nuevos informes o actualizaciones.

<table>
 <tr>
  <th align="center">Incidente original</th>
  <th align="center">Nuevo(s) reporte(s)</th>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incidente #240</strong>: <a href="/cite/240">GitHub Copilot, infracciÃ³n de derechos de autor y licencias de cÃ³digo abierto</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>Litigio de GitHub Copilot â€“ <a href="https://githubcopilotlitigation.com">githubcopilotlitigation.com</a>, <em>Nov 3, 2022</em></li>
   </ul>
  </td>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incidente #376</strong>: <a href="/cite/376">El algoritmo de RealPage elevÃ³ los precios de alquiler, supuestamente de manera artificial</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>El Departamento de Justicia ha abierto una investigaciÃ³n sobre RealPage - <a href="https://www.propublica.org/article/yieldstar-realpage-rent-doj-investigation-antitrust">ProPublica</a>, <em>Nov 23, 2022</em>
    </li>
   </ul>
  </td>
 </tr>
</table>

## ğŸ—„ De los archivos

En cada ediciÃ³n, presentamos uno o mÃ¡s incidentes histÃ³ricos que encontramos estimulantes.

Dado que ha habido mucha cobertura de noticias y discurso en las redes sociales sobre ChatGPT de OpenAI, echemos un vistazo a algunos de los incidentes anteriores relacionados con los chatbots. AquÃ­ hay algunos:

[Microsoftâ€™s Tay](/cite/6) se lanzÃ³ el 23 de marzo de 2016 y se eliminÃ³ en 24 horas debido a mÃºltiples tuits racistas, sexistas y antisemitas generados por el bot.

[Yandexâ€™s Alice](/cite/58), un chatbot producido por una empresa de tecnologÃ­a rusa, lanzado en octubre de 2017, comenzÃ³ a responder preguntas con respuestas racistas, pro-stalinistas y pro-violencia.

Se demostrÃ³ que [Korean Chatbot Luda](/cite/106) utilizÃ³ un lenguaje despectivo e intolerante cuando se le preguntÃ³ acerca de las lesbianas, los negros y las personas con discapacidades.

La demostraciÃ³n del chatbot de [Metaâ€™s BlenderBot 3](/cite/278) hizo comentarios antisemitas ofensivos.

Aunque la tecnologÃ­a de IA generativa se ha vuelto mucho mÃ¡s avanzada y muy popular en solo unos pocos aÃ±os, los problemas relacionados con el sesgo, la discriminaciÃ³n y el uso Ã©tico han sido problemas persistentes.

## ğŸ‘‡ Indagando mÃ¡s profundamente

- Todos los nuevos incidentes agregados a la base de datos en el Ãºltimo mes, agrupados por tema:

- Privacidad y vigilancia: [#386](/cite/386), [#387](/cite/387), [#395](/cite/395)
- Reconocimiento facial: [#388](/cite/388), [#391](/cite/391), [#409](/cite/409)
- Sesgo y discriminaciÃ³n: [#396](/cite/396), [#400](/cite/400), [#401](/cite/401), [#405](/cite/405), [ #407](/citar/407), [#410](/citar/410)
- Redes sociales: [#392](/cite/392), [#393](/cite/393), [#394](/cite/394), [#397](/cite/397), [# 399](/cite/399), [#406](/cite/406), [#408](/cite/408), [#411](/cite/411)
- GPT-3: [#402](/cite/402), [#413](/cite/413)
- Errores impactantes: [#403](/cite/403), [#404](/cite/404)
- VehÃ­culos autÃ³nomos: [#389](/cite/389), [#398](/cite/398)
- Falsificaciones profundas: [#390](/cite/390)

- Explore grupos de incidentes similares en [VisualizaciÃ³n espacial](/summaries/spatial)
- Consulte [Vista de tabla](/apps/incidents) para obtener una vista completa de todos los incidentes
- Obtenga informaciÃ³n sobre presuntos desarrolladores, implementadores y partes perjudicadas en [PÃ¡gina de entidades](/entidades)

* * *

## ğŸ¦¾ Apoya nuestros esfuerzos

Â¿Sigues leyendo? Â¡AyÃºdanos a cambiar el mundo para mejor!

1. Comparta este boletÃ­n en [LinkedIn](https://www.linkedin.com/company/responsible-ai-collaborative), [Twitter](https://twitter.com/IncidentsDB) y [Facebook](https ://www.facebook.com/IncidentsDB)
2. [Enviar](/apps/enviar) incidentes a la base de datos
3. [Contribuir](https://github.com/responsible-ai-collaborative/aiid) a la funcionalidad de la base de datos

