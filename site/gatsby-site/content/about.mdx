---
title: "About"
metaTitle: "The details about who and why for database"
metaDescription: "Who are the people and organizations developing the AIID and why are we developing it?"
---

# Why "AI Incidents"?

Intelligent systems are currently prone to unforeseen and often dangerous failures when they are deployed to the real world. Much like the transportation sector before it (e.g., [FAA](https://www.faa.gov/data_research/accident_incident/) and [FARS](https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars)) and more recently [computer systems](https://cve.mitre.org/cve/), intelligent systems require a repository of problems experienced in the real world so that future researchers and developers may mitigate or avoid repeated bad outcomes.

# What is an Incident?

The initial set of more than 1,000 incident reports have been intentionally broad in nature. Current examples include,

* An *autonomous car* [kills a pedestrian](/cite/4)
* A *trading algorithm* causes a market "[flash crash](/cite/28)" where billions of dollars transfer between parties
* A *facial recognition system* [causes an innocent person to be arrested](/cite/74)

You are invited to [explore the incidents collected to date](/apps/discover), [view the complete listing](/summaries/incidents), and [submit](/apps/submit) additional incident reports. Researchers are invited to review our [working definition of AI incidents](/research/1-criteria).

# Current and Future Users

The database is a [constantly evolving](/research/2-roadmap) [data product](/develop) and [collection of applications](/apps).

* **Current Users** include system architects, industrial product developers, public relations managers, [researchers](/research), and public policy researchers. These users are invited to use the [Discover](/apps/discover) application to proactively discover how recently deployed intelligent systems have produced unexpected outcomes in the real world. In so doing, they may avoid making similar mistakes in their development.
* **Future Uses** will [evolve](/research/2-roadmap) through the code contributions of the [open source](https://github.com/PartnershipOnAI/aiid) community, including additional database [summaries](/summaries) and [taxonomies](/research/2-roadmap).

# When Should You Report an Incident?

When in doubt of whether an event qualifies as an incident, please [submit it](/apps/submit)! This project is intended to converge on a [shared definition](/research/1-criteria) of "AI Incident" through exploration of the candidate incidents submitted by the broader community.

# Governance

The incident database is managed in a participatory manner by persons and organizations contributing code, research, and broader impacts. A board of directors is being convened from contributors to the project. If you would like to participate in the governance of the project, please [contact](/contact) us and include your intended contribution to the AI Incident Database.

**Organizational Contributors**

* [Neama Dadkhahnikoo](https://www.linkedin.com/in/neama/)

Partnership on AI staff members [Jingying Yang](https://www.linkedin.com/in/jingyingyang/) and [Dr. Christine Custis](https://www.su.edu/symposium/business-symposium-speakers/christine-custis/) contributed significantly to the early stages of the AIID.

**Open Source Contributors**

People that have contributed more than one pull request, graphics, site copy, or bug report to the AI Incident Database.

* César Varela
* Alex Muscă
* [Chloe Kam](http://kamchy.com) (AIID Logos)
* JT McHorse
* Seth Reid (AI Forum of New Zealand)

**Incident Editors**

People that resolve incident submissions to the database.

* [Sean McGregor](https://seanbmcgregor.com/)

**Taxonomy Editors**

Organizations or people that have contributed [taxonomies](https://incidentdatabase.ai/taxonomies) to the database.

* [Center for Security and Emerging Technology](https://cset.georgetown.edu/) (CSET)

**Incident Contributors**

People that have contributed a large numbers of incidents to the database.

* Kate Perkins (Intel)
* Roman Lutz (Max Planck Institute for Intelligent Systems, formerly Microsoft)
* Patrick Hall (Burt and Hall LLP)
* Sam Yoon (as contractor to PAI, now with Deloitte Consulting)
* Catherine Olsson (Google)
* Roman Yampolskiy (University of Louisville)

The following people have collected a large number of incidents that are pending ingestion.

* Zachary Arnold, Helen Toner, Ingrid Dickinson, Thomas Giallella, and Nicolina Demakos (Center for Security and Emerging Technology, Georgetown)
* Charlie Pownall via AI, algorithmic and automation incident and controversy repository [(AIAAIC)](https://www.aiaaic.org/)
* Lawrence Lee, Darlena Phuong Quyen Nguyen, Iftekhar Ahmed (UC Irvine)

There is a growing community of people concerned with the collection and characterization of AI incidents, and we encourage everyone to contribute to the development of this system.

<a href="https://xprize.org/aiforgood">
<img
     src="/images/AI4G-Logo-Inline-White.png"
     alt="XPRIZE AI for Good Logo"
     style="background-color:black;padding:20px;width: 160px;" />
</a>

<a href="https://aiforum.org.nz/">
<img
     src="/images/AI-Forum-Logo_MAORI_HOR_RGB_100high.jpg"
     alt="AI Forum New Zealand"
     style="background-color:white;padding:20px;width: 160px;" />
</a>
