---
title: 'AI Incident Roundup ‚Äì November ‚Äò22'
metaTitle: 'AI Incident Roundup ‚Äì November ‚Äò22'
metaDescription: 'Collection of AI incidents, developments, and ingestion in November of 2022, providing a digestible recap on the latest incidents and reports of the AIID.'
date: '2022-12-15'
image: './images/aiid-november.webp'
author: 'Janet Schwartz & Khoa Lam'
slug: '/blog/incident-report-2022-november'
---

Welcome to this month‚Äôs edition of The Monthly Roundup, a newsletter designed to give you a digestible recap on the latest incidents and reports of the AI Incident Database.

Estimated reading time: 3 minutes

## üóûÔ∏è New Incidents

Emerging incidents that occurred last month:

- Incident #399: [Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content](/cite/399)

  -   What happened? Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.
  -   Who was involved? Meta AI, Meta, and Facebook developed and deployed an AI system which harmed minority groups, Meta AI, Meta, and Facebook.

  Incident #410: [KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System](/cite/410)

  -   What happened? KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.
  -   Who was involved? KFC developed and deployed an AI system, which harmed Jewish people.

- Incident #411: [Chinese Accounts Allegedly Spammed Twitter Feed to Obscure News of Protests](/cite/411)

  -   What happened? Twitter‚Äôs feed algorithm was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.
  -   Who was involved? Twitter developed and deployed an AI system, which harmed Twitter users and Twitter.

  Incident #413: [Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow](/cite/413)

  -   What happened? Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.
  -   Who was involved? OpenAI developed and deployed an AI system, which harmed Stack Overflow users and Stack Overflow.

## üìé New Developments

Older incidents that have new reports or updates.

<table>
 <tr>
  <th align="center">Original incident</th>
  <th align="center">New report(s)</th>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #240</strong>: <a href="/cite/240">GitHub Copilot, Copyright Infringement and Open Source Licensing</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>GitHub Copilot litigation ‚Äì <a href="https://githubcopilotlitigation.com">githubcopilotlitigation.com</a>, <em>Nov 3, 2022</em></li>
   </ul>
  </td>
 </tr>
 <tr>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
    <strong>Incident #376</strong>: <a href="/cite/376">RealPage's Algorithm Pushed Rent Prices High, Allegedly Artificially</a>
  </td>
  <td className="align-top border-1 border-gray-200 px-4 py-2">
   <ul>
    <li>The DOJ Has Opened an Investigation Into RealPage - <a href="https://www.propublica.org/article/yieldstar-realpage-rent-doj-investigation-antitrust">ProPublica</a>, <em>Nob 23, 2022</em>
    </li>
   </ul>
  </td>
 </tr>
</table>

## üóÑ From the Archives

Every edition, we feature one or more historical incidents that we find thought-provoking.

Given that there has been a lot of ¬†news coverage and social media discourse about OpenAI‚Äôs ChatGPT, let‚Äôs take a look back at some of the earlier incidents related to chatbots. Here are just a few:

[Microsoft‚Äôs Tay](/cite/6) was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anti-semetic tweets generated by the bot.

[Yandex‚Äôs Alice](/cite/58), a chatbot produced by a Russian technology company, released in October 2017 began to reply to questions with racist, pro-Stalin, and pro-violence responses.

[Korean Chatbot Luda](/cite/106) was shown to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.

[Meta‚Äôs BlenderBot 3](/cite/278) chatbot demo made offensive anti-semitic comments.

Although generative AI technology has become vastly more advanced ¬†and wildly popular in only a few years, issues related to bias, discrimination, and ethical use have been persistent problems.

## üëá Diving Deeper

-   All new incidents added to the database in the last month, grouped by topic:

-   Privacy & surveillance: [#386](/cite/386), [#387](/cite/387), [#395](/cite/395)
-   Facial recognition: [#388](/cite/388), [#391](/cite/391), [#409](/cite/409)
-   Bias & discrimination: [#396](/cite/396), [#400](/cite/400), [#401](/cite/401), [#405](/cite/405), [#407](/cite/407), [#410](/cite/410)
-   Social media: [#392](/cite/392), [#393](/cite/393), [#394](/cite/394), [#397](/cite/397), [#399](/cite/399), [#406](/cite/406), [#408](/cite/408), [#411](/cite/411)
-   GPT-3: [#402](/cite/402), [#413](/cite/413)
-   Impactful Errors: [#403](/cite/403), [#404](/cite/404)
-   Autonomous vehicles: [#389](/cite/389), [#398](/cite/398)
-   Deepfakes: [#390](/cite/390) 

-   Explore clusters of similar incidents in [Spatial Visualization](/summaries/spatial)
-   Check out [Table View](/apps/incidents) for a complete view of all incidents
-   Learn about alleged developers, deployers, and harmed parties in [Entities Page](/entities)

* * *

## ü¶æ Support our Efforts

Still reading? Help us change the world for the better!

1.  Share this newsletter on [LinkedIn](https://www.linkedin.com/company/responsible-ai-collaborative), [Twitter](https://twitter.com/IncidentsDB), and [Facebook](https://www.facebook.com/IncidentsDB)
2.  [Submit](/apps/submit) incidents to the database
3.  [Contribute](https://github.com/responsible-ai-collaborative/aiid) to the database‚Äôs functionality

